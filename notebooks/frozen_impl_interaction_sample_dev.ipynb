{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ece3567-e4b1-4c3f-a264-20625abb6ad7",
   "metadata": {},
   "source": [
    "# validate results\n",
    "\n",
    "## TODO\n",
    "what happened to tracing when I fixed probability calcs - it seems like all trip ids are attached when I add one by\n",
    "hand below - why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd74ba44-0dfb-439a-a6ab-7ceedfc5f523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:17:57.385153Z",
     "iopub.status.busy": "2022-05-01T10:17:57.384881Z",
     "iopub.status.idle": "2022-05-01T10:17:57.534433Z",
     "shell.execute_reply": "2022-05-01T10:17:57.533096Z",
     "shell.execute_reply.started": "2022-05-01T10:17:57.385047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dba451-1e10-403e-8614-35d57e6577f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:17:57.536623Z",
     "iopub.status.busy": "2022-05-01T10:17:57.536012Z",
     "iopub.status.idle": "2022-05-01T10:17:57.542755Z",
     "shell.execute_reply": "2022-05-01T10:17:57.541685Z",
     "shell.execute_reply.started": "2022-05-01T10:17:57.536567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73deaac4-e7ac-4aff-b086-4980dc6dd903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:00.350944Z",
     "iopub.status.busy": "2022-05-01T10:18:00.350730Z",
     "iopub.status.idle": "2022-05-01T10:18:12.760977Z",
     "shell.execute_reply": "2022-05-01T10:18:12.760013Z",
     "shell.execute_reply.started": "2022-05-01T10:18:00.350919Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from activitysim.cli import run\n",
    "from activitysim.core import inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e553abd-fe0d-4cdc-aeb1-9dc80cb2757f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:16.944537Z",
     "iopub.status.busy": "2022-05-01T10:18:16.944291Z",
     "iopub.status.idle": "2022-05-01T10:18:17.124764Z",
     "shell.execute_reply": "2022-05-01T10:18:17.123725Z",
     "shell.execute_reply.started": "2022-05-01T10:18:16.944501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 2)\n",
      "[[2 2]\n",
      " [2 1]\n",
      " [1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([2, 2, 1, 2, 1, 0])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = np.array([[1,2,3,4,5,6],[4,6,5,9,9,6],[7,8,9,1,2,3]]).reshape((3,3,2))\n",
    "print(utils.shape)\n",
    "print(np.argmax(utils, axis=1))\n",
    "np.argmax(utils, axis=1).flatten(order=\"F\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2, 2],\n       [2, 1],\n       [1, 0]])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_array = np.argmax(utils, axis=1)\n",
    "ch_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.1 , 0.7 , 0.1 , 0.1 ],\n       [0.  , 0.5 , 0.25, 0.25],\n       [0.3 , 0.3 , 0.2 , 0.2 ]])"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = np.array([[0.1,0.7,0.1,0.1], [0.0,0.5,0.25,0.25], [0.3,0.3,0.2,0.2]])\n",
    "print(probs.shape)\n",
    "probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 4, 3)"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(probs[:,:,None], 3, axis=2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 1, 1, 2, 2])"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(np.arange(0,probs.shape[0]), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 0, 1, 2, 0, 1, 2])"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.arange(0,probs.shape[0]), 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fec4e8-a174-4e66-87d2-1e8c7979de90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:17.839947Z",
     "iopub.status.busy": "2022-05-01T10:18:17.839070Z",
     "iopub.status.idle": "2022-05-01T10:18:18.019676Z",
     "shell.execute_reply": "2022-05-01T10:18:18.018689Z",
     "shell.execute_reply.started": "2022-05-01T10:18:17.839911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/mnt/c/Users/jan.zill/code/activitysim\"\n",
    "example_dir = os.path.join(root_dir, \"test_example_mtc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de710a2-d292-42f9-9d4a-4dcef1365506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:18.894533Z",
     "iopub.status.busy": "2022-05-01T10:18:18.894303Z",
     "iopub.status.idle": "2022-05-01T10:18:19.078807Z",
     "shell.execute_reply": "2022-05-01T10:18:19.077951Z",
     "shell.execute_reply.started": "2022-05-01T10:18:18.894508Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(example_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730be239-8704-4483-bbb8-ffae0f17c5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:22.111723Z",
     "iopub.status.busy": "2022-05-01T10:18:22.111490Z",
     "iopub.status.idle": "2022-05-01T10:18:22.297437Z",
     "shell.execute_reply": "2022-05-01T10:18:22.296501Z",
     "shell.execute_reply.started": "2022-05-01T10:18:22.111697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "run.add_run_args(parser)\n",
    "args = parser.parse_args(['-c', 'configs', '-o', 'output', '-d', 'data'])\n",
    "#run.run(args)  # 2mins full example run\n",
    "if not inject.is_injectable('preload_injectables'):\n",
    "    from activitysim import abm  # register abm steps and other abm-specific injectables\n",
    "run.handle_standard_args(args)  # possibly update injectables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from activitysim.core import inject\n",
    "from activitysim.core import pipeline\n",
    "from activitysim.core import config\n",
    "from activitysim.core import simulate\n",
    "from activitysim.abm.models.util import estimation\n",
    "from activitysim.abm.tables import shadow_pricing\n",
    "from activitysim.core import interaction_simulate\n",
    "from activitysim.core import logit\n",
    "from activitysim.core.simulate import set_skim_wrapper_targets\n",
    "from activitysim.core import chunk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "from activitysim.core.logit import inverse_ev1_cdf\n",
    "\n",
    "def hack_make_sample_choices(\n",
    "    choosers, probs,\n",
    "    alternatives,\n",
    "    sample_size, alternative_count, alt_col_name,\n",
    "    allow_zero_probs,\n",
    "    trace_label,\n",
    "    utilities=None,\n",
    "    choose_individual_max_utility=False\n",
    "):\n",
    "    assert isinstance(probs, pd.DataFrame)\n",
    "    assert probs.shape == (len(choosers), alternative_count)\n",
    "    assert isinstance(alternatives, pd.DataFrame)\n",
    "    assert len(alternatives) == alternative_count\n",
    "\n",
    "    if allow_zero_probs:\n",
    "        zero_probs = (probs.sum(axis=1) == 0)\n",
    "        if zero_probs.all():\n",
    "            return pd.DataFrame(columns=[alt_col_name, 'rand', 'prob', choosers.index.name])\n",
    "        if zero_probs.any():\n",
    "            # remove from sample\n",
    "            probs = probs[~zero_probs]\n",
    "            choosers = choosers[~zero_probs]\n",
    "            # TODO [janzill Jun2022]: do we want this for consistency?\n",
    "            #  might need this in other places too?\n",
    "            if utilities is not None:\n",
    "                utilities = utilities[~zero_probs]\n",
    "\n",
    "    if choose_individual_max_utility:\n",
    "        assert isinstance(utilities, pd.DataFrame)\n",
    "        #print(utilities.head(3))\n",
    "        assert utilities.shape == (len(choosers), alternative_count)\n",
    "        #print(utilities.shape)\n",
    "\n",
    "        choice_dimension = (len(choosers), alternative_count, sample_size)\n",
    "        rands = pipeline.get_rn_generator().random_for_df(utilities, n=alternative_count*sample_size)\n",
    "        #print(f\"after generation rands shape = {rands.shape}\", flush=True)\n",
    "        rands = rands.reshape(choice_dimension)\n",
    "        #print(f\"before inverse_ev1 rands shape = {rands.shape}\", flush=True)\n",
    "        rands = inverse_ev1_cdf(rands)\n",
    "        #print(f\"after inverse_ev1 rands shape = {rands.shape}\", flush=True)\n",
    "        utilities = utilities.to_numpy()  # this should be much cleaner once xarray changes are implemented\n",
    "        utilities = np.repeat(utilities[:,:,None], sample_size, axis=2)\n",
    "        #print(f\"after utils reshape: {utilities.shape}\", flush=True)\n",
    "        utilities += rands\n",
    "        # this gives us len(choosers), sample_size dimensions, with values the chosen alternative\n",
    "        choices_array = np.argmax(utilities, axis=1)\n",
    "        print(choices_array.shape)\n",
    "\n",
    "        choosers_index_rep = np.tile(np.arange(0,choices_array.shape[0]), sample_size)\n",
    "        #np.repeat(np.arange(0,choices_array.shape[0]), sample_size)\n",
    "        choices_flattened = choices_array.flatten(order='F')\n",
    "        #print(f\"choices flattened shape = {choices_flattened.shape}\")\n",
    "\n",
    "        print(choosers_index_rep.shape, flush=True)\n",
    "        print(probs.shape, flush=True)\n",
    "        print(probs.head(3), flush=True)\n",
    "        probs_look_up = probs.to_numpy()[choosers_index_rep, choices_flattened]\n",
    "        #print(f\"probs_look_up shape = {probs_look_up.shape}\", flush=True)\n",
    "\n",
    "        # choices_flattened are 0-based index into alternatives, need to map to alternative values given by\n",
    "        #  alternatives.index.values (they are in this order by construction)\n",
    "        # explode to one row per chooser.index, alt_zone_id\n",
    "        choices_df = pd.DataFrame({\n",
    "            alt_col_name: alternatives.index.values[choices_flattened],\n",
    "            #'rand': rands.flatten(order='F'),\n",
    "            'rand': np.zeros_like(choosers_index_rep), # TODO: zero out for now\n",
    "            'prob': probs_look_up.flatten(order='F'),\n",
    "            # repeat is wrong here - we do not want 1,1,2,2,3,3, etc, but 1,2,3,1,2,3 by construction\n",
    "            #choosers.index.name: np.repeat(np.asanyarray(choosers.index), sample_size)\n",
    "            choosers.index.name: np.tile(choosers.index.values, sample_size)\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        cum_probs_array = probs.values.cumsum(axis=1)\n",
    "        # alt probs in convenient layout to return prob of chose alternative\n",
    "        # (same layout as cum_probs_arr)\n",
    "        alt_probs_array = probs.values.flatten()\n",
    "        # get sample_size rands for each chooser\n",
    "        rands = pipeline.get_rn_generator().random_for_df(probs, n=sample_size)\n",
    "        # transform as we iterate over alternatives\n",
    "        # reshape so rands[i] is in broadcastable (2-D) shape for cum_probs_arr\n",
    "        # i.e rands[i] is a 2-D array of one alt choice rand for each chooser\n",
    "        rands = rands.T.reshape(sample_size, -1, 1)\n",
    "        # the alternative value chosen\n",
    "        choices_array = np.empty([sample_size, len(choosers)]).astype(alternatives.index.dtype)\n",
    "        # chunk log these later after we populate them...\n",
    "        # the probability of the chosen alternative\n",
    "        choice_probs_array = np.empty([sample_size, len(choosers)])\n",
    "        # chunk log these later after we populate them...\n",
    "        alts = np.tile(alternatives.index.values, len(choosers))\n",
    "        # FIXME - do this all at once rather than iterate?\n",
    "        for i in range(sample_size):\n",
    "            # FIXME - do this in numpy, not pandas?\n",
    "            # rands for this alt in broadcastable shape\n",
    "            r = rands[i]\n",
    "\n",
    "            # position of first occurrence of positive value\n",
    "            positions = np.argmax(cum_probs_array > r, axis=1)\n",
    "\n",
    "            # FIXME - leave positions as numpy array, not pandas series?\n",
    "            # positions is series with the chosen alternative represented as a column index in probs\n",
    "            # which is an integer between zero and num alternatives in the alternative sample\n",
    "            positions = pd.Series(positions, index=probs.index)\n",
    "\n",
    "            # need to get from an integer offset into the alternative sample to the alternative index\n",
    "            # that is, we want the index value of the row that is offset by <position> rows into the\n",
    "            # tranche of this choosers alternatives created by cross join of alternatives and choosers\n",
    "\n",
    "            # offsets is the offset into model_design df of first row of chooser alternatives\n",
    "            offsets = np.arange(len(positions)) * alternative_count\n",
    "\n",
    "            # choices and choice_probs have one element per chooser and is in same order as choosers\n",
    "            choices_array[i] = np.take(alts, positions + offsets)\n",
    "            choice_probs_array[i] = np.take(alt_probs_array, positions + offsets)\n",
    "            del positions\n",
    "            del offsets\n",
    "\n",
    "        del alts\n",
    "        del cum_probs_array\n",
    "        del alt_probs_array\n",
    "\n",
    "        # explode to one row per chooser.index, alt_zone_id\n",
    "        choices_df = pd.DataFrame(\n",
    "            {alt_col_name: choices_array.flatten(order='F'),\n",
    "             'rand': rands.flatten(order='F'),\n",
    "             'prob': choice_probs_array.flatten(order='F'),\n",
    "             choosers.index.name: np.repeat(np.asanyarray(choosers.index), sample_size)\n",
    "             })\n",
    "\n",
    "    return choices_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimation bundle school_location not in settings file estimation.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running university, 3\n",
      "dropping 19 of 25 rows where size_term is zero\n",
      "Running school_location with 17 persons\n",
      "(17, 6)\n",
      "(102,)\n",
      "(17, 6)\n",
      "                  0         1         2         3         4         5\n",
      "person_id                                                            \n",
      "325623     0.001874  0.005184  0.002695  0.299427  0.508256  0.182563\n",
      "386007     0.001584  0.724879  0.145533  0.080880  0.041571  0.005553\n",
      "1774265    0.019349  0.146800  0.038209  0.486232  0.273819  0.035591\n",
      "running highschool, 2\n",
      "dropping 23 of 25 rows where size_term is zero\n",
      "Running school_location with 5 persons\n",
      "(5, 2)\n",
      "(10,)\n",
      "(5, 2)\n",
      "                  0         1\n",
      "person_id                    \n",
      "386062     0.176063  0.823937\n",
      "595685     0.057237  0.942763\n",
      "2877285    0.126995  0.873005\n",
      "running gradeschool, 1\n",
      "dropping 0 of 25 rows where size_term is zero\n",
      "Running school_location with 17 persons\n",
      "(17, 10)\n",
      "(170,)\n",
      "(17, 25)\n",
      "                 0         1         2         3         4         5   \\\n",
      "person_id                                                               \n",
      "386008     0.000504  0.001303  0.002645  0.001534  0.007081  0.023018   \n",
      "418442     0.000554  0.001434  0.002911  0.001678  0.007704  0.020100   \n",
      "595686     0.000877  0.002269  0.004605  0.003020  0.014986  0.025318   \n",
      "\n",
      "                 6         7         8         9         10        11  \\\n",
      "person_id                                                               \n",
      "386008     0.056174  0.157982  0.336708  0.205884  0.069858  0.001223   \n",
      "418442     0.042219  0.120700  0.229318  0.288773  0.101255  0.001526   \n",
      "595686     0.058311  0.166706  0.116761  0.110817  0.133127  0.003827   \n",
      "\n",
      "                 12        13        14        15        16        17  \\\n",
      "person_id                                                               \n",
      "386008     0.000206  0.000548  0.000380  0.015291  0.009346  0.008790   \n",
      "418442     0.000257  0.000683  0.000474  0.019075  0.011592  0.010965   \n",
      "595686     0.000525  0.001116  0.000750  0.053224  0.025697  0.033011   \n",
      "\n",
      "                 18        19        20        21        22        23  \\\n",
      "person_id                                                               \n",
      "386008     0.008610  0.032788  0.028567  0.002079  0.000817  0.002728   \n",
      "418442     0.012703  0.052444  0.039245  0.002288  0.000899  0.002985   \n",
      "595686     0.014173  0.033481  0.147571  0.003620  0.001422  0.004723   \n",
      "\n",
      "                 24  \n",
      "person_id            \n",
      "386008     0.025936  \n",
      "418442     0.028217  \n",
      "595686     0.040062  \n",
      "CPU times: user 281 ms, sys: 31.2 ms, total: 312 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "choose_individual_max_utility = True\n",
    "\n",
    "resume_after = \"compute_accessibility\"\n",
    "model_name = \"school_location\"\n",
    "chunk_size = 0  # test_mtc means no chunking\n",
    "\n",
    "pipeline.open_pipeline(resume_after)\n",
    "# preload any bulky injectables (e.g. skims) not in pipeline\n",
    "inject.get_injectable('preload_injectables', None)\n",
    "pipeline._PIPELINE.rng().begin_step(model_name)\n",
    "#step_name = model_name\n",
    "args = {}\n",
    "#checkpoint = pipeline.intermediate_checkpoint(model_name)\n",
    "inject.set_step_args(args)\n",
    "\n",
    "\n",
    "persons_merged = inject.get_table('persons_merged')\n",
    "network_los = inject.get_injectable('network_los')\n",
    "households = inject.get_table('households')\n",
    "persons = inject.get_table('persons')\n",
    "locutor = inject.get_injectable('locutor')\n",
    "\n",
    "trace_label = model_name #'school_location'\n",
    "model_settings_file_name = f\"{model_name}.yaml\" #'school_location.yaml'\n",
    "model_settings = config.read_model_settings(model_settings_file_name)\n",
    "estimator = estimation.manager.begin_estimation(model_name)\n",
    "# iterate_location_choice()\n",
    "chunk_tag = trace_label\n",
    "\n",
    "# boolean to filter out persons not needing location modeling (e.g. is_worker, is_student)\n",
    "chooser_filter_column = model_settings['CHOOSER_FILTER_COLUMN_NAME']\n",
    "dest_choice_column_name = model_settings['DEST_CHOICE_COLUMN_NAME']\n",
    "logsum_column_name = model_settings.get('DEST_CHOICE_LOGSUM_COLUMN_NAME')\n",
    "sample_table_name = model_settings.get('DEST_CHOICE_SAMPLE_TABLE_NAME')\n",
    "want_sample_table = config.setting('want_dest_choice_sample_tables') and sample_table_name is not None\n",
    "persons_merged_df = persons_merged.to_frame()\n",
    "persons_merged_df = persons_merged_df[persons_merged_df[chooser_filter_column]]\n",
    "persons_merged_df.sort_index(inplace=True)  # interaction_sample expects chooser index to be monotonic increasing\n",
    "\n",
    "# chooser segmentation allows different sets coefficients for e.g. different income_segments or tour_types\n",
    "chooser_segment_column = model_settings['CHOOSER_SEGMENT_COLUMN_NAME']\n",
    "assert chooser_segment_column in persons_merged_df, f\"CHOOSER_SEGMENT_COLUMN '{chooser_segment_column}' not in \" \\\n",
    "                                                    f\"persons_merged table.\"\n",
    "shadow_price_calculator = shadow_pricing.load_shadow_price_calculator(model_settings)\n",
    "chooser_segment_column = model_settings['CHOOSER_SEGMENT_COLUMN_NAME']\n",
    "# maps segment names to compact (integer) ids\n",
    "segment_ids = model_settings['SEGMENT_IDS']\n",
    "\n",
    "sample_list = []\n",
    "for segment_name, segment_id in segment_ids.items():\n",
    "    print(f\"running {segment_name}, {segment_id}\")\n",
    "    choosers = persons_merged_df[persons_merged_df[chooser_segment_column] == segment_id]\n",
    "    # size_term and shadow price adjustment - one row per zone\n",
    "    dest_size_terms = shadow_price_calculator.dest_size_terms(segment_name)\n",
    "    assert dest_size_terms.index.is_monotonic_increasing, f\"shadow_price_calculator.dest_size_terms({segment_name}) \" \\\n",
    "                                                         f\"not monotonic_increasing\"\n",
    "    if choosers.shape[0] == 0:\n",
    "        print(f\"{trace_label} skipping segment {segment_name}: no choosers\")\n",
    "        continue\n",
    "    print(f\"dropping {(~(dest_size_terms.size_term > 0)).sum()} \"\n",
    "          f\"of {len(dest_size_terms)} rows where size_term is zero\")\n",
    "    dest_size_terms = dest_size_terms[dest_size_terms.size_term > 0]\n",
    "    chooser_columns = model_settings['SIMULATE_CHOOSER_COLUMNS']\n",
    "    choosers_location_sample = choosers[chooser_columns]\n",
    "    skim_dict = network_los.get_default_skim_dict()\n",
    "    skims = skim_dict.wrap('home_zone_id', 'zone_id')\n",
    "    alt_dest_col_name = model_settings['ALT_DEST_COL_NAME']\n",
    "    assert not choosers_location_sample.empty\n",
    "    print(\"Running %s with %d persons\" % (trace_label, len(choosers_location_sample.index)))\n",
    "    sample_size = model_settings[\"SAMPLE_SIZE\"]\n",
    "    locals_d = {\n",
    "        'skims': skims,\n",
    "        'segment_size': segment_name\n",
    "    }\n",
    "    constants = config.get_model_constants(model_settings)\n",
    "    locals_d.update(constants)\n",
    "    spec = simulate.spec_for_segment(model_settings, spec_id='SAMPLE_SPEC',\n",
    "                                     segment_name=segment_name, estimator=estimator)\n",
    "    ### choices = interaction_sample()\n",
    "    alt_col_name=alt_dest_col_name\n",
    "    allow_zero_probs=False\n",
    "    log_alt_losers=False\n",
    "    # we return alternatives ordered in (index, alt_col_name)\n",
    "    # if choosers index is not ordered, it is probably a mistake, since the alts wont line up\n",
    "    assert alt_col_name is not None\n",
    "    assert choosers.index.is_monotonic_increasing\n",
    "\n",
    "    # FIXME - legacy logic - not sure this is needed or even correct?\n",
    "    sample_size = min(sample_size, len(dest_size_terms.index))\n",
    "\n",
    "    result_list = []\n",
    "    for i, chooser_chunk, chunk_trace_label in chunk.adaptive_chunked_choosers(choosers_location_sample, chunk_size, trace_label,\n",
    "                                                                               chunk_tag):\n",
    "\n",
    "        ### choices = hack_interaction_sample\n",
    "        # chooser = chooser_chunk\n",
    "        #alternatives = dest_size_terms\n",
    "        #trace_label=chunk_trace_label\n",
    "\n",
    "        num_choosers = len(chooser_chunk.index)\n",
    "        assert num_choosers > 0\n",
    "        if len(spec.columns) > 1:\n",
    "            raise RuntimeError('spec must have only one column')\n",
    "        # if using skims, copy index into the dataframe, so it will be\n",
    "        # available as the \"destination\" for set_skim_wrapper_targets\n",
    "        if skims is not None and dest_size_terms.index.name not in dest_size_terms:\n",
    "            dest_size_terms = dest_size_terms.copy()\n",
    "            dest_size_terms[dest_size_terms.index.name] = dest_size_terms.index\n",
    "\n",
    "        chooser_index_id = interaction_simulate.ALT_CHOOSER_ID if log_alt_losers else None\n",
    "\n",
    "        # - cross join choosers and alternatives (cartesian product)\n",
    "        # for every chooser, there will be a row for each alternative\n",
    "        # index values (non-unique) are from alternatives df\n",
    "        alternative_count = dest_size_terms.shape[0]\n",
    "        interaction_df =\\\n",
    "            logit.interaction_dataset(chooser_chunk, dest_size_terms, sample_size=alternative_count,\n",
    "                                      chooser_index_id=chooser_index_id)\n",
    "\n",
    "        assert alternative_count == len(interaction_df.index) / len(chooser_chunk.index)\n",
    "\n",
    "        if skims is not None:\n",
    "            set_skim_wrapper_targets(interaction_df, skims)\n",
    "\n",
    "        # evaluate expressions from the spec multiply by coefficients and sum\n",
    "        # spec is df with one row per spec expression and one col with utility coefficient\n",
    "        # column names of interaction_df match spec index values\n",
    "        # utilities has utility value for element in the cross product of choosers and alternatives\n",
    "        # interaction_utilities is a df with one utility column and one row per row in interaction_df\n",
    "        trace_rows = trace_ids = None\n",
    "\n",
    "        # interaction_utilities is a df with one utility column and one row per interaction_df row\n",
    "        interaction_utilities, trace_eval_results = interaction_simulate.eval_interaction_utilities(\n",
    "            spec, interaction_df, locals_d, chunk_trace_label, trace_rows, estimator=None,\n",
    "            log_alt_losers=log_alt_losers\n",
    "        )\n",
    "        # ########### HWM - high water mark (point of max observed memory usage)\n",
    "        #del interaction_df\n",
    "\n",
    "        # reshape utilities (one utility column and one row per row in interaction_utilities)\n",
    "        # to a dataframe with one row per chooser and one column per alternative\n",
    "        utilities = pd.DataFrame(\n",
    "            interaction_utilities.values.reshape(len(chooser_chunk), alternative_count),\n",
    "            index=chooser_chunk.index)\n",
    "        #del interaction_utilities\n",
    "\n",
    "        # convert to probabilities (utilities exponentiated and normalized to probs)\n",
    "        # probs is same shape as utilities, one row per chooser and one column for alternative\n",
    "        probs = logit.utils_to_probs(utilities, allow_zero_probs=allow_zero_probs,\n",
    "                                     trace_label=chunk_trace_label, trace_choosers=chooser_chunk)\n",
    "        #del utilities\n",
    "\n",
    "        temp_choices = hack_make_sample_choices(\n",
    "            chooser_chunk, probs, dest_size_terms,\n",
    "            sample_size, alternative_count, alt_col_name,\n",
    "            allow_zero_probs=allow_zero_probs,\n",
    "            trace_label=chunk_trace_label,\n",
    "            utilities=utilities,\n",
    "            choose_individual_max_utility=choose_individual_max_utility\n",
    "        )\n",
    "\n",
    "        choices_df = temp_choices.copy()\n",
    "\n",
    "        # pick_count and pick_dup\n",
    "        # pick_count is number of duplicate picks\n",
    "        # pick_dup flag is True for all but first of duplicates\n",
    "        pick_group = choices_df.groupby([choosers.index.name, alt_col_name])\n",
    "        # number each item in each group from 0 to the length of that group - 1.\n",
    "        choices_df['pick_count'] = pick_group.cumcount(ascending=True)\n",
    "        # flag duplicate rows after first\n",
    "        choices_df['pick_dup'] = choices_df['pick_count'] > 0\n",
    "        # add reverse cumcount to get total pick_count (conveniently faster than groupby.count + merge)\n",
    "        choices_df['pick_count'] += pick_group.cumcount(ascending=False) + 1\n",
    "        # drop the duplicates\n",
    "        choices_df = choices_df[~choices_df['pick_dup']]\n",
    "        del choices_df['pick_dup']\n",
    "        # set index after groupby so we can trace on it\n",
    "        choices_df.set_index(choosers.index.name, inplace=True)\n",
    "        # don't need this after tracing\n",
    "        del choices_df['rand']\n",
    "        # - NARROW\n",
    "        choices_df['prob'] = choices_df['prob'].astype(np.float32)\n",
    "        assert (choices_df['pick_count'].max() < 4294967295) or (choices_df.empty)\n",
    "        choices_df['pick_count'] = choices_df['pick_count'].astype(np.uint32)\n",
    "\n",
    "\n",
    "        if choices_df.shape[0] > 0:\n",
    "            result_list.append(choices_df)\n",
    "\n",
    "    if len(result_list) > 1:\n",
    "        choices_df = pd.concat(result_list)\n",
    "    assert allow_zero_probs or (len(choosers_location_sample.index) == len(np.unique(choices_df.index.values))), \\\n",
    "        \"what is this\"\n",
    "    # keep alts in canonical order so choices based on their probs are stable across runs\n",
    "    choices_df = choices_df.sort_values(by=alt_col_name).sort_index(kind='mergesort')\n",
    "\n",
    "    sample_list.append(choices_df)\n",
    "\n",
    "finalise = True\n",
    "if finalise:\n",
    "    inject.set_step_args(None)\n",
    "    #\n",
    "    pipeline._PIPELINE.rng().end_step(model_name)\n",
    "    pipeline.add_checkpoint(model_name)\n",
    "    if not pipeline.intermediate_checkpoint():\n",
    "        pipeline.add_checkpoint(pipeline.FINAL_CHECKPOINT_NAME)\n",
    "\n",
    "    pipeline.close_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "     alt_dest  rand      prob  person_id\n0           9     0  0.336708     386008\n51          7     0  0.056174     386008\n85          9     0  0.336708     386008\n102         9     0  0.336708     386008\n34          8     0  0.157982     386008\n..        ...   ...       ...        ...\n50         16     0  0.182639    4171620\n33          6     0  0.032124    4171620\n16          9     0  0.111409    4171620\n152        10     0  0.097048    4171620\n169         7     0  0.062739    4171620\n\n[170 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alt_dest</th>\n      <th>rand</th>\n      <th>prob</th>\n      <th>person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0.056174</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0.157982</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>16</td>\n      <td>0</td>\n      <td>0.182639</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0.032124</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0.111409</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>10</td>\n      <td>0</td>\n      <td>0.097048</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0.062739</td>\n      <td>4171620</td>\n    </tr>\n  </tbody>\n</table>\n<p>170 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_choices.sort_values(by=[\"person_id\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "data": {
      "text/plain": "     alt_dest      rand      prob  person_id\n0           8  0.222922  0.157982     386008\n1           9  0.404176  0.336708     386008\n2           8  0.223154  0.157982     386008\n3           9  0.457402  0.336708     386008\n4          11  0.812506  0.069858     386008\n..        ...       ...       ...        ...\n165         7  0.107363  0.062739    4171620\n166        11  0.517573  0.070848    4171620\n167        10  0.375828  0.097048    4171620\n168         9  0.279810  0.111409    4171620\n169        20  0.848968  0.026642    4171620\n\n[170 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alt_dest</th>\n      <th>rand</th>\n      <th>prob</th>\n      <th>person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>0.222922</td>\n      <td>0.157982</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0.404176</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>0.223154</td>\n      <td>0.157982</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0.457402</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0.812506</td>\n      <td>0.069858</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>7</td>\n      <td>0.107363</td>\n      <td>0.062739</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>11</td>\n      <td>0.517573</td>\n      <td>0.070848</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>10</td>\n      <td>0.375828</td>\n      <td>0.097048</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>9</td>\n      <td>0.279810</td>\n      <td>0.111409</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>20</td>\n      <td>0.848968</td>\n      <td>0.026642</td>\n      <td>4171620</td>\n    </tr>\n  </tbody>\n</table>\n<p>170 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temp_choices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "choices_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "           alt_dest      prob  pick_count\nperson_id                                \n386008            8  0.157982           2\n386008            9  0.336708           5\n386008           10  0.205884           1\n386008           11  0.069858           1\n386008           17  0.009346           1\n...             ...       ...         ...\n4171620           9  0.111409           1\n4171620          10  0.097048           1\n4171620          11  0.070848           1\n4171620          20  0.026642           1\n4171620          25  0.062053           1\n\n[105 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alt_dest</th>\n      <th>prob</th>\n      <th>pick_count</th>\n    </tr>\n    <tr>\n      <th>person_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>386008</th>\n      <td>8</td>\n      <td>0.157982</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>9</td>\n      <td>0.336708</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>10</td>\n      <td>0.205884</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>11</td>\n      <td>0.069858</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>17</td>\n      <td>0.009346</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>9</td>\n      <td>0.111409</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>10</td>\n      <td>0.097048</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>11</td>\n      <td>0.070848</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>20</td>\n      <td>0.026642</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>25</td>\n      <td>0.062053</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>105 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choices_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 3, 4, 5])"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_size_terms.index.values[[0,1,2,3,4]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(sample_size)\n",
    "sample_list[2].groupby('person_id').pick_count.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}