{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ece3567-e4b1-4c3f-a264-20625abb6ad7",
   "metadata": {},
   "source": [
    "# validate results\n",
    "\n",
    "## TODO\n",
    "what happened to tracing when I fixed probability calcs - it seems like all trip ids are attached when I add one by\n",
    "hand below - why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd74ba44-0dfb-439a-a6ab-7ceedfc5f523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:17:57.385153Z",
     "iopub.status.busy": "2022-05-01T10:17:57.384881Z",
     "iopub.status.idle": "2022-05-01T10:17:57.534433Z",
     "shell.execute_reply": "2022-05-01T10:17:57.533096Z",
     "shell.execute_reply.started": "2022-05-01T10:17:57.385047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dba451-1e10-403e-8614-35d57e6577f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:17:57.536623Z",
     "iopub.status.busy": "2022-05-01T10:17:57.536012Z",
     "iopub.status.idle": "2022-05-01T10:17:57.542755Z",
     "shell.execute_reply": "2022-05-01T10:17:57.541685Z",
     "shell.execute_reply.started": "2022-05-01T10:17:57.536567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73deaac4-e7ac-4aff-b086-4980dc6dd903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:00.350944Z",
     "iopub.status.busy": "2022-05-01T10:18:00.350730Z",
     "iopub.status.idle": "2022-05-01T10:18:12.760977Z",
     "shell.execute_reply": "2022-05-01T10:18:12.760013Z",
     "shell.execute_reply.started": "2022-05-01T10:18:00.350919Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from activitysim.cli import run\n",
    "from activitysim.core import inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e553abd-fe0d-4cdc-aeb1-9dc80cb2757f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:16.944537Z",
     "iopub.status.busy": "2022-05-01T10:18:16.944291Z",
     "iopub.status.idle": "2022-05-01T10:18:17.124764Z",
     "shell.execute_reply": "2022-05-01T10:18:17.123725Z",
     "shell.execute_reply.started": "2022-05-01T10:18:16.944501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 1, 2])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array([[1,2,3],[4,6,5],[7,8,9]]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "   a  b  c\n0  1  2  3\n1  4  6  5\n2  7  8  9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0    c\n1    b\n2    c\ndtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ = pd.DataFrame([[1,2,3],[4,6,5],[7,8,9]], columns=[\"a\", \"b\", \"c\"])\n",
    "display(df_)\n",
    "ch_ = df_.idxmax(1)\n",
    "display(ch_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "   a  b  c\n0  1  2  3\n1  4  6  5\n2  7  8  9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ = pd.DataFrame([[1,2,3],[4,6,5],[7,8,9]], columns=[\"a\", \"b\", \"c\"])\n",
    "display(df_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a': 0, 'b': 1, 'c': 2}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{v: k for k,v in enumerate(df_.columns)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fec4e8-a174-4e66-87d2-1e8c7979de90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:17.839947Z",
     "iopub.status.busy": "2022-05-01T10:18:17.839070Z",
     "iopub.status.idle": "2022-05-01T10:18:18.019676Z",
     "shell.execute_reply": "2022-05-01T10:18:18.018689Z",
     "shell.execute_reply.started": "2022-05-01T10:18:17.839911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/mnt/c/Users/jan.zill/code/activitysim\"\n",
    "example_dir = os.path.join(root_dir, \"test_example_mtc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de710a2-d292-42f9-9d4a-4dcef1365506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:18.894533Z",
     "iopub.status.busy": "2022-05-01T10:18:18.894303Z",
     "iopub.status.idle": "2022-05-01T10:18:19.078807Z",
     "shell.execute_reply": "2022-05-01T10:18:19.077951Z",
     "shell.execute_reply.started": "2022-05-01T10:18:18.894508Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(example_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730be239-8704-4483-bbb8-ffae0f17c5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:22.111723Z",
     "iopub.status.busy": "2022-05-01T10:18:22.111490Z",
     "iopub.status.idle": "2022-05-01T10:18:22.297437Z",
     "shell.execute_reply": "2022-05-01T10:18:22.296501Z",
     "shell.execute_reply.started": "2022-05-01T10:18:22.111697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "run.add_run_args(parser)\n",
    "args = parser.parse_args(['-c', 'configs', '-o', 'output', '-d', 'data'])\n",
    "#run.run(args)  # 2mins full example run\n",
    "if not inject.is_injectable('preload_injectables'):\n",
    "    from activitysim import abm  # register abm steps and other abm-specific injectables\n",
    "run.handle_standard_args(args)  # possibly update injectables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from activitysim.core import inject\n",
    "from activitysim.core import pipeline\n",
    "from activitysim.core import config\n",
    "from activitysim.core import simulate\n",
    "from activitysim.abm.models.util import estimation\n",
    "from activitysim.abm.tables import shadow_pricing\n",
    "from activitysim.core import interaction_simulate\n",
    "from activitysim.core import logit\n",
    "from activitysim.core.simulate import set_skim_wrapper_targets\n",
    "from activitysim.core import chunk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def hack_make_sample_choices(\n",
    "        choosers, probs,\n",
    "        alternatives,\n",
    "        sample_size, alternative_count, alt_col_name,\n",
    "        allow_zero_probs,\n",
    "        trace_label):\n",
    "    assert isinstance(probs, pd.DataFrame)\n",
    "    assert probs.shape == (len(choosers), alternative_count)\n",
    "\n",
    "    assert isinstance(alternatives, pd.DataFrame)\n",
    "    assert len(alternatives) == alternative_count\n",
    "\n",
    "    if allow_zero_probs:\n",
    "        zero_probs = (probs.sum(axis=1) == 0)\n",
    "        if zero_probs.all():\n",
    "            return pd.DataFrame(columns=[alt_col_name, 'rand', 'prob', choosers.index.name])\n",
    "        if zero_probs.any():\n",
    "            # remove from sample\n",
    "            probs = probs[~zero_probs]\n",
    "            choosers = choosers[~zero_probs]\n",
    "\n",
    "    cum_probs_array = probs.values.cumsum(axis=1)\n",
    "\n",
    "    # alt probs in convenient layout to return prob of chose alternative\n",
    "    # (same layout as cum_probs_arr)\n",
    "    alt_probs_array = probs.values.flatten()\n",
    "\n",
    "    # get sample_size rands for each chooser\n",
    "    rands = pipeline.get_rn_generator().random_for_df(probs, n=sample_size)\n",
    "\n",
    "    # transform as we iterate over alternatives\n",
    "    # reshape so rands[i] is in broadcastable (2-D) shape for cum_probs_arr\n",
    "    # i.e rands[i] is a 2-D array of one alt choice rand for each chooser\n",
    "    rands = rands.T.reshape(sample_size, -1, 1)\n",
    "\n",
    "    # the alternative value chosen\n",
    "    choices_array = np.empty([sample_size, len(choosers)]).astype(alternatives.index.dtype)\n",
    "    # chunk log these later after we populate them...\n",
    "    # the probability of the chosen alternative\n",
    "    choice_probs_array = np.empty([sample_size, len(choosers)])\n",
    "    # chunk log these later after we populate them...\n",
    "    alts = np.tile(alternatives.index.values, len(choosers))\n",
    "\n",
    "    # FIXME - do this all at once rather than iterate?\n",
    "    for i in range(sample_size):\n",
    "        # FIXME - do this in numpy, not pandas?\n",
    "        # rands for this alt in broadcastable shape\n",
    "        r = rands[i]\n",
    "\n",
    "        # position of first occurrence of positive value\n",
    "        positions = np.argmax(cum_probs_array > r, axis=1)\n",
    "\n",
    "        # FIXME - leave positions as numpy array, not pandas series?\n",
    "        # positions is series with the chosen alternative represented as a column index in probs\n",
    "        # which is an integer between zero and num alternatives in the alternative sample\n",
    "        positions = pd.Series(positions, index=probs.index)\n",
    "\n",
    "        # need to get from an integer offset into the alternative sample to the alternative index\n",
    "        # that is, we want the index value of the row that is offset by <position> rows into the\n",
    "        # tranche of this choosers alternatives created by cross join of alternatives and choosers\n",
    "\n",
    "        # offsets is the offset into model_design df of first row of chooser alternatives\n",
    "        offsets = np.arange(len(positions)) * alternative_count\n",
    "\n",
    "        # choices and choice_probs have one element per chooser and is in same order as choosers\n",
    "        choices_array[i] = np.take(alts, positions + offsets)\n",
    "        choice_probs_array[i] = np.take(alt_probs_array, positions + offsets)\n",
    "\n",
    "        del positions\n",
    "        del offsets\n",
    "\n",
    "    del alts\n",
    "    del cum_probs_array\n",
    "    del alt_probs_array\n",
    "\n",
    "    # explode to one row per chooser.index, alt_zone_id\n",
    "    choices_df = pd.DataFrame(\n",
    "        {alt_col_name: choices_array.flatten(order='F'),\n",
    "         'rand': rands.flatten(order='F'),\n",
    "         'prob': choice_probs_array.flatten(order='F'),\n",
    "         choosers.index.name: np.repeat(np.asanyarray(choosers.index), sample_size)\n",
    "         })\n",
    "\n",
    "    del choices_array\n",
    "    del rands\n",
    "    del choice_probs_array\n",
    "    return choices_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimation bundle school_location not in settings file estimation.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running university, 3\n",
      "dropping 19 of 25 rows where size_term is zero\n",
      "Running school_location with 17 persons\n",
      "running highschool, 2\n",
      "dropping 23 of 25 rows where size_term is zero\n",
      "Running school_location with 5 persons\n",
      "running gradeschool, 1\n",
      "dropping 0 of 25 rows where size_term is zero\n",
      "Running school_location with 17 persons\n",
      "CPU times: user 188 ms, sys: 31.2 ms, total: 219 ms\n",
      "Wall time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resume_after = \"compute_accessibility\"\n",
    "model_name = \"school_location\"\n",
    "chunk_size = 0  # test_mtc means no chunking\n",
    "\n",
    "pipeline.open_pipeline(resume_after)\n",
    "# preload any bulky injectables (e.g. skims) not in pipeline\n",
    "inject.get_injectable('preload_injectables', None)\n",
    "pipeline._PIPELINE.rng().begin_step(model_name)\n",
    "#step_name = model_name\n",
    "args = {}\n",
    "#checkpoint = pipeline.intermediate_checkpoint(model_name)\n",
    "inject.set_step_args(args)\n",
    "\n",
    "\n",
    "persons_merged = inject.get_table('persons_merged')\n",
    "network_los = inject.get_injectable('network_los')\n",
    "households = inject.get_table('households')\n",
    "persons = inject.get_table('persons')\n",
    "locutor = inject.get_injectable('locutor')\n",
    "\n",
    "trace_label = model_name #'school_location'\n",
    "model_settings_file_name = f\"{model_name}.yaml\" #'school_location.yaml'\n",
    "model_settings = config.read_model_settings(model_settings_file_name)\n",
    "\n",
    "estimator = estimation.manager.begin_estimation(model_name)\n",
    "\n",
    "# iterate_location_choice(\n",
    "#     model_settings,\n",
    "#     persons_merged, persons, households,\n",
    "#     network_los,\n",
    "#     estimator,\n",
    "#     chunk_size, trace_hh_id, locutor, trace_label\n",
    "# )\n",
    "\n",
    "chunk_tag = trace_label\n",
    "\n",
    "# boolean to filter out persons not needing location modeling (e.g. is_worker, is_student)\n",
    "chooser_filter_column = model_settings['CHOOSER_FILTER_COLUMN_NAME']\n",
    "\n",
    "dest_choice_column_name = model_settings['DEST_CHOICE_COLUMN_NAME']\n",
    "logsum_column_name = model_settings.get('DEST_CHOICE_LOGSUM_COLUMN_NAME')\n",
    "\n",
    "sample_table_name = model_settings.get('DEST_CHOICE_SAMPLE_TABLE_NAME')\n",
    "want_sample_table = config.setting('want_dest_choice_sample_tables') and sample_table_name is not None\n",
    "\n",
    "persons_merged_df = persons_merged.to_frame()\n",
    "\n",
    "persons_merged_df = persons_merged_df[persons_merged_df[chooser_filter_column]]\n",
    "\n",
    "persons_merged_df.sort_index(inplace=True)  # interaction_sample expects chooser index to be monotonic increasing\n",
    "\n",
    "# chooser segmentation allows different sets coefficients for e.g. different income_segments or tour_types\n",
    "chooser_segment_column = model_settings['CHOOSER_SEGMENT_COLUMN_NAME']\n",
    "\n",
    "assert chooser_segment_column in persons_merged_df, f\"CHOOSER_SEGMENT_COLUMN '{chooser_segment_column}' not in \" \\\n",
    "                                                    f\"persons_merged table.\"\n",
    "\n",
    "shadow_price_calculator = shadow_pricing.load_shadow_price_calculator(model_settings)\n",
    "\n",
    "chooser_segment_column = model_settings['CHOOSER_SEGMENT_COLUMN_NAME']\n",
    "\n",
    "# maps segment names to compact (integer) ids\n",
    "segment_ids = model_settings['SEGMENT_IDS']\n",
    "\n",
    "#choices_list = []\n",
    "sample_list = []\n",
    "for segment_name, segment_id in segment_ids.items():\n",
    "    print(f\"running {segment_name}, {segment_id}\")\n",
    "    choosers = persons_merged_df[persons_merged_df[chooser_segment_column] == segment_id]\n",
    "\n",
    "    # size_term and shadow price adjustment - one row per zone\n",
    "    dest_size_terms = shadow_price_calculator.dest_size_terms(segment_name)\n",
    "\n",
    "    assert dest_size_terms.index.is_monotonic_increasing, f\"shadow_price_calculator.dest_size_terms({segment_name}) \" \\\n",
    "                                                         f\"not monotonic_increasing\"\n",
    "    if choosers.shape[0] == 0:\n",
    "        print(f\"{trace_label} skipping segment {segment_name}: no choosers\")\n",
    "        continue\n",
    "\n",
    "    print(f\"dropping {(~(dest_size_terms.size_term > 0)).sum()} \"\n",
    "          f\"of {len(dest_size_terms)} rows where size_term is zero\")\n",
    "    dest_size_terms = dest_size_terms[dest_size_terms.size_term > 0]\n",
    "\n",
    "    chooser_columns = model_settings['SIMULATE_CHOOSER_COLUMNS']\n",
    "    choosers_location_sample = choosers[chooser_columns]\n",
    "    skim_dict = network_los.get_default_skim_dict()\n",
    "    skims = skim_dict.wrap('home_zone_id', 'zone_id')\n",
    "    alt_dest_col_name = model_settings['ALT_DEST_COL_NAME']\n",
    "\n",
    "    assert not choosers_location_sample.empty\n",
    "    print(\"Running %s with %d persons\" % (trace_label, len(choosers_location_sample.index)))\n",
    "    sample_size = model_settings[\"SAMPLE_SIZE\"]\n",
    "    locals_d = {\n",
    "        'skims': skims,\n",
    "        'segment_size': segment_name\n",
    "    }\n",
    "    constants = config.get_model_constants(model_settings)\n",
    "    locals_d.update(constants)\n",
    "    spec = simulate.spec_for_segment(model_settings, spec_id='SAMPLE_SPEC',\n",
    "                                     segment_name=segment_name, estimator=estimator)\n",
    "    ### choices = interaction_sample(\n",
    "    alt_col_name=alt_dest_col_name\n",
    "    allow_zero_probs=False\n",
    "    log_alt_losers=False\n",
    "\n",
    "    # we return alternatives ordered in (index, alt_col_name)\n",
    "    # if choosers index is not ordered, it is probably a mistake, since the alts wont line up\n",
    "    assert alt_col_name is not None\n",
    "    assert choosers.index.is_monotonic_increasing\n",
    "\n",
    "    # FIXME - legacy logic - not sure this is needed or even correct?\n",
    "    sample_size = min(sample_size, len(dest_size_terms.index))\n",
    "\n",
    "    result_list = []\n",
    "    for i, chooser_chunk, chunk_trace_label in chunk.adaptive_chunked_choosers(choosers_location_sample, chunk_size, trace_label,\n",
    "                                                                               chunk_tag):\n",
    "\n",
    "        ### choices = hack_interaction_sample\n",
    "        # chooser = chooser_chunk\n",
    "        #alternatives = dest_size_terms\n",
    "        #trace_label=chunk_trace_label\n",
    "\n",
    "        num_choosers = len(chooser_chunk.index)\n",
    "        assert num_choosers > 0\n",
    "        if len(spec.columns) > 1:\n",
    "            raise RuntimeError('spec must have only one column')\n",
    "        # if using skims, copy index into the dataframe, so it will be\n",
    "        # available as the \"destination\" for set_skim_wrapper_targets\n",
    "        if skims is not None and dest_size_terms.index.name not in dest_size_terms:\n",
    "            dest_size_terms = dest_size_terms.copy()\n",
    "            dest_size_terms[dest_size_terms.index.name] = dest_size_terms.index\n",
    "\n",
    "        chooser_index_id = interaction_simulate.ALT_CHOOSER_ID if log_alt_losers else None\n",
    "\n",
    "        # - cross join choosers and alternatives (cartesian product)\n",
    "        # for every chooser, there will be a row for each alternative\n",
    "        # index values (non-unique) are from alternatives df\n",
    "        alternative_count = dest_size_terms.shape[0]\n",
    "        interaction_df =\\\n",
    "            logit.interaction_dataset(chooser_chunk, dest_size_terms, sample_size=alternative_count,\n",
    "                                      chooser_index_id=chooser_index_id)\n",
    "\n",
    "        assert alternative_count == len(interaction_df.index) / len(chooser_chunk.index)\n",
    "\n",
    "        if skims is not None:\n",
    "            set_skim_wrapper_targets(interaction_df, skims)\n",
    "\n",
    "        # evaluate expressions from the spec multiply by coefficients and sum\n",
    "        # spec is df with one row per spec expression and one col with utility coefficient\n",
    "        # column names of interaction_df match spec index values\n",
    "        # utilities has utility value for element in the cross product of choosers and alternatives\n",
    "        # interaction_utilities is a df with one utility column and one row per row in interaction_df\n",
    "        trace_rows = trace_ids = None\n",
    "\n",
    "        # interaction_utilities is a df with one utility column and one row per interaction_df row\n",
    "        interaction_utilities, trace_eval_results = interaction_simulate.eval_interaction_utilities(\n",
    "            spec, interaction_df, locals_d, chunk_trace_label, trace_rows, estimator=None,\n",
    "            log_alt_losers=log_alt_losers\n",
    "        )\n",
    "        # ########### HWM - high water mark (point of max observed memory usage)\n",
    "        #del interaction_df\n",
    "\n",
    "        # reshape utilities (one utility column and one row per row in interaction_utilities)\n",
    "        # to a dataframe with one row per chooser and one column per alternative\n",
    "        utilities = pd.DataFrame(\n",
    "            interaction_utilities.values.reshape(len(chooser_chunk), alternative_count),\n",
    "            index=chooser_chunk.index)\n",
    "        #del interaction_utilities\n",
    "\n",
    "        # convert to probabilities (utilities exponentiated and normalized to probs)\n",
    "        # probs is same shape as utilities, one row per chooser and one column for alternative\n",
    "        probs = logit.utils_to_probs(utilities, allow_zero_probs=allow_zero_probs,\n",
    "                                     trace_label=chunk_trace_label, trace_choosers=chooser_chunk)\n",
    "        #del utilities\n",
    "\n",
    "        temp_choices = hack_make_sample_choices(\n",
    "            chooser_chunk, probs, dest_size_terms,\n",
    "            sample_size, alternative_count, alt_col_name,\n",
    "            allow_zero_probs=allow_zero_probs,\n",
    "            trace_label=chunk_trace_label)\n",
    "\n",
    "        choices_df = temp_choices.copy()\n",
    "\n",
    "        # pick_count and pick_dup\n",
    "        # pick_count is number of duplicate picks\n",
    "        # pick_dup flag is True for all but first of duplicates\n",
    "        pick_group = choices_df.groupby([choosers.index.name, alt_col_name])\n",
    "        # number each item in each group from 0 to the length of that group - 1.\n",
    "        choices_df['pick_count'] = pick_group.cumcount(ascending=True)\n",
    "        # flag duplicate rows after first\n",
    "        choices_df['pick_dup'] = choices_df['pick_count'] > 0\n",
    "        # add reverse cumcount to get total pick_count (conveniently faster than groupby.count + merge)\n",
    "        choices_df['pick_count'] += pick_group.cumcount(ascending=False) + 1\n",
    "        # drop the duplicates\n",
    "        choices_df = choices_df[~choices_df['pick_dup']]\n",
    "        del choices_df['pick_dup']\n",
    "        # set index after groupby so we can trace on it\n",
    "        choices_df.set_index(choosers.index.name, inplace=True)\n",
    "        # don't need this after tracing\n",
    "        del choices_df['rand']\n",
    "        # - NARROW\n",
    "        choices_df['prob'] = choices_df['prob'].astype(np.float32)\n",
    "        assert (choices_df['pick_count'].max() < 4294967295) or (choices_df.empty)\n",
    "        choices_df['pick_count'] = choices_df['pick_count'].astype(np.uint32)\n",
    "\n",
    "\n",
    "        if choices_df.shape[0] > 0:\n",
    "            result_list.append(choices_df)\n",
    "\n",
    "    if len(result_list) > 1:\n",
    "        choices_df = pd.concat(result_list)\n",
    "    assert allow_zero_probs or (len(choosers_location_sample.index) == len(np.unique(choices_df.index.values))), \\\n",
    "        \"what is this\"\n",
    "    # keep alts in canonical order so choices based on their probs are stable across runs\n",
    "    choices_df = choices_df.sort_values(by=alt_col_name).sort_index(kind='mergesort')\n",
    "\n",
    "    sample_list.append(choices_df)\n",
    "\n",
    "finalise = True\n",
    "if finalise:\n",
    "    inject.set_step_args(None)\n",
    "    #\n",
    "    pipeline._PIPELINE.rng().end_step(model_name)\n",
    "    pipeline.add_checkpoint(model_name)\n",
    "    if not pipeline.intermediate_checkpoint():\n",
    "        pipeline.add_checkpoint(pipeline.FINAL_CHECKPOINT_NAME)\n",
    "\n",
    "    pipeline.close_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "     alt_dest      rand      prob  person_id\n0           8  0.222922  0.157982     386008\n1           9  0.404176  0.336708     386008\n2           8  0.223154  0.157982     386008\n3           9  0.457402  0.336708     386008\n4          11  0.812506  0.069858     386008\n..        ...       ...       ...        ...\n165         7  0.107363  0.062739    4171620\n166        11  0.517573  0.070848    4171620\n167        10  0.375828  0.097048    4171620\n168         9  0.279810  0.111409    4171620\n169        20  0.848968  0.026642    4171620\n\n[170 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alt_dest</th>\n      <th>rand</th>\n      <th>prob</th>\n      <th>person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>0.222922</td>\n      <td>0.157982</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0.404176</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>0.223154</td>\n      <td>0.157982</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0.457402</td>\n      <td>0.336708</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0.812506</td>\n      <td>0.069858</td>\n      <td>386008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>7</td>\n      <td>0.107363</td>\n      <td>0.062739</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>11</td>\n      <td>0.517573</td>\n      <td>0.070848</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>10</td>\n      <td>0.375828</td>\n      <td>0.097048</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>9</td>\n      <td>0.279810</td>\n      <td>0.111409</td>\n      <td>4171620</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>20</td>\n      <td>0.848968</td>\n      <td>0.026642</td>\n      <td>4171620</td>\n    </tr>\n  </tbody>\n</table>\n<p>170 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_choices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "           alt_dest      prob  pick_count\nperson_id                                \n386008            8  0.157982           2\n386008            9  0.336708           5\n386008           10  0.205884           1\n386008           11  0.069858           1\n386008           17  0.009346           1\n...             ...       ...         ...\n4171620           9  0.111409           1\n4171620          10  0.097048           1\n4171620          11  0.070848           1\n4171620          20  0.026642           1\n4171620          25  0.062053           1\n\n[105 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alt_dest</th>\n      <th>prob</th>\n      <th>pick_count</th>\n    </tr>\n    <tr>\n      <th>person_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>386008</th>\n      <td>8</td>\n      <td>0.157982</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>9</td>\n      <td>0.336708</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>10</td>\n      <td>0.205884</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>11</td>\n      <td>0.069858</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>386008</th>\n      <td>17</td>\n      <td>0.009346</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>9</td>\n      <td>0.111409</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>10</td>\n      <td>0.097048</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>11</td>\n      <td>0.070848</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>20</td>\n      <td>0.026642</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4171620</th>\n      <td>25</td>\n      <td>0.062053</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>105 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "person_id\n386008     10\n418442     10\n595686     10\n644292     10\n644478     10\n1958678    10\n2159059    10\n2219998    10\n2458502    10\n2458503    10\n2566700    10\n2566701    10\n2566702    10\n2877287    10\n3596365    10\n3891104    10\n4171620    10\nName: pick_count, dtype: uint32"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(sample_size)\n",
    "sample_list[2].groupby('person_id').pick_count.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10980/63825533.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;31m# interaction_utilities is a df with one utility column and one row per interaction_df row\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m interaction_utilities, trace_eval_results = interaction_simulate.eval_interaction_utilities(\n\u001B[0m\u001B[1;32m     46\u001B[0m     \u001B[0mspec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minteraction_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocals_d\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrace_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrace_rows\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0mlog_alt_losers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog_alt_losers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/c/Users/jan.zill/code/activitysim/activitysim/core/interaction_simulate.py\u001B[0m in \u001B[0;36meval_interaction_utilities\u001B[0;34m(spec, df, locals_d, trace_label, trace_rows, estimator, log_alt_losers)\u001B[0m\n\u001B[1;32m     66\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Running eval_interaction_utilities on %s rows\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_log\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrace_label\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0;32massert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/contextlib.py\u001B[0m in \u001B[0;36m__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    111\u001B[0m         \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    114\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"generator didn't yield\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/c/Users/jan.zill/code/activitysim/activitysim/core/chunk.py\u001B[0m in \u001B[0;36mchunk_log\u001B[0;34m(trace_label, chunk_tag, base)\u001B[0m\n\u001B[1;32m    927\u001B[0m     \u001B[0;31m# avoids breaking the assertion below.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 929\u001B[0;31m     \u001B[0;32massert\u001B[0m \u001B[0mbase\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCHUNK_SIZERS\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    930\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    931\u001B[0m     \u001B[0mtrace_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"{trace_label}.chunk_log\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}