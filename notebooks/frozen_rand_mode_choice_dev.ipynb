{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ece3567-e4b1-4c3f-a264-20625abb6ad7",
   "metadata": {},
   "source": [
    "# Start work here, clean up as you go\n",
    "\n",
    "Problem below: scale of error term on lower levels needs to be given by nest, not the case atm\n",
    "\n",
    "Do I remember this correctly and probabilities are calculated as products of marginal and conditional probabilities?\n",
    "if so, the corresponding utilities at leaf and node levels would need to be calculated, and I would be able to use\n",
    "these directly, right? CHECK, would make it much easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd74ba44-0dfb-439a-a6ab-7ceedfc5f523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:17:57.385153Z",
     "iopub.status.busy": "2022-05-01T10:17:57.384881Z",
     "iopub.status.idle": "2022-05-01T10:17:57.534433Z",
     "shell.execute_reply": "2022-05-01T10:17:57.533096Z",
     "shell.execute_reply.started": "2022-05-01T10:17:57.385047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dba451-1e10-403e-8614-35d57e6577f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:17:57.536623Z",
     "iopub.status.busy": "2022-05-01T10:17:57.536012Z",
     "iopub.status.idle": "2022-05-01T10:17:57.542755Z",
     "shell.execute_reply": "2022-05-01T10:17:57.541685Z",
     "shell.execute_reply.started": "2022-05-01T10:17:57.536567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73deaac4-e7ac-4aff-b086-4980dc6dd903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:00.350944Z",
     "iopub.status.busy": "2022-05-01T10:18:00.350730Z",
     "iopub.status.idle": "2022-05-01T10:18:12.760977Z",
     "shell.execute_reply": "2022-05-01T10:18:12.760013Z",
     "shell.execute_reply.started": "2022-05-01T10:18:00.350919Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "from activitysim.cli import run\n",
    "from activitysim.core import inject\n",
    "from activitysim.core import tracing\n",
    "from activitysim.core import config\n",
    "from activitysim.core import pipeline\n",
    "from activitysim.core import mem\n",
    "from activitysim.core import chunk\n",
    "from activitysim.core import simulate\n",
    "from activitysim.core import logit\n",
    "from activitysim.abm.models.util.mode import mode_choice_simulate\n",
    "from activitysim.abm.models.util import estimation\n",
    "from activitysim.core import expressions\n",
    "from activitysim.core.util import assign_in_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e553abd-fe0d-4cdc-aeb1-9dc80cb2757f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:16.944537Z",
     "iopub.status.busy": "2022-05-01T10:18:16.944291Z",
     "iopub.status.idle": "2022-05-01T10:18:17.124764Z",
     "shell.execute_reply": "2022-05-01T10:18:17.123725Z",
     "shell.execute_reply.started": "2022-05-01T10:18:16.944501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fec4e8-a174-4e66-87d2-1e8c7979de90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:17.839947Z",
     "iopub.status.busy": "2022-05-01T10:18:17.839070Z",
     "iopub.status.idle": "2022-05-01T10:18:18.019676Z",
     "shell.execute_reply": "2022-05-01T10:18:18.018689Z",
     "shell.execute_reply.started": "2022-05-01T10:18:17.839911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/mnt/c/Users/jan.zill/code/activitysim\"\n",
    "example_dir = os.path.join(root_dir, \"test_example_mtc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de710a2-d292-42f9-9d4a-4dcef1365506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:18.894533Z",
     "iopub.status.busy": "2022-05-01T10:18:18.894303Z",
     "iopub.status.idle": "2022-05-01T10:18:19.078807Z",
     "shell.execute_reply": "2022-05-01T10:18:19.077951Z",
     "shell.execute_reply.started": "2022-05-01T10:18:18.894508Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(example_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730be239-8704-4483-bbb8-ffae0f17c5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:22.111723Z",
     "iopub.status.busy": "2022-05-01T10:18:22.111490Z",
     "iopub.status.idle": "2022-05-01T10:18:22.297437Z",
     "shell.execute_reply": "2022-05-01T10:18:22.296501Z",
     "shell.execute_reply.started": "2022-05-01T10:18:22.111697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "run.add_run_args(parser)\n",
    "# args = parser.parse_args()\n",
    "# parser.parse_args(['--sum', '7', '-1', '42'])\n",
    "args = parser.parse_args(['-c', 'configs', '-o', 'output', '-d', 'data'])\n",
    "#run.run(args)  # 2mins full example run\n",
    "\n",
    "\n",
    "if not inject.is_injectable('preload_injectables'):\n",
    "    from activitysim import abm  # register abm steps and other abm-specific injectables\n",
    "run.handle_standard_args(args)  # possibly update injectables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045438f-d1eb-4b5c-9737-185798b7f97f",
   "metadata": {},
   "source": [
    "## trip mode choice by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600ae244-3e6c-4b66-8d39-aa9f6f60b378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:18:26.399145Z",
     "iopub.status.busy": "2022-05-01T10:18:26.398687Z",
     "iopub.status.idle": "2022-05-01T10:18:26.583256Z",
     "shell.execute_reply": "2022-05-01T10:18:26.582233Z",
     "shell.execute_reply.started": "2022-05-01T10:18:26.399105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inject.get_table('trips').to_frame()  #pipeline.orca.get_raw_table('trips').to_frame()\n",
    "#inject.get_table('tours_merged').to_frame()  #pipeline.orca.get_raw_table('tours_merged').to_frame()\n",
    "#inject.get_injectable('network_los')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def run_trip_mode_choice(do_these_purposes=None, simulate_function=simulate.simple_simulate):\n",
    "    #do_these_purposes=['escort']\n",
    "    \"\"\"open pipeline and load stuff for mode choice dev assuming model has been run and pipeline.h5 exists\"\"\"\n",
    "    resume_after = \"trip_scheduling\"\n",
    "    model_name = \"trip_mode_choice\"\n",
    "    chunk_size = 0  # test_mtc means no chunking\n",
    "\n",
    "    pipeline.open_pipeline(resume_after)\n",
    "    # preload any bulky injectables (e.g. skims) not in pipeline\n",
    "    inject.get_injectable('preload_injectables', None)\n",
    "    pipeline._PIPELINE.rng().begin_step(model_name)\n",
    "    step_name = model_name\n",
    "    args = {}\n",
    "    checkpoint = pipeline.intermediate_checkpoint(model_name)\n",
    "    inject.set_step_args(args)\n",
    "\n",
    "    trips = inject.get_table('trips')\n",
    "    tours_merged = inject.get_table('tours_merged')\n",
    "    network_los = inject.get_injectable('network_los')\n",
    "\n",
    "    trace_label = 'trip_mode_choice'\n",
    "    model_settings_file_name = 'trip_mode_choice.yaml'\n",
    "    model_settings = config.read_model_settings(model_settings_file_name)\n",
    "\n",
    "    logsum_column_name = model_settings.get('MODE_CHOICE_LOGSUM_COLUMN_NAME')\n",
    "    mode_column_name = 'trip_mode'\n",
    "\n",
    "    trips_df = trips.to_frame()\n",
    "    print(\"Running with %d trips\", trips_df.shape[0])\n",
    "\n",
    "    tours_merged = tours_merged.to_frame()\n",
    "    tours_merged = tours_merged[model_settings['TOURS_MERGED_CHOOSER_COLUMNS']]\n",
    "\n",
    "    # - trips_merged - merge trips and tours_merged\n",
    "    trips_merged = pd.merge(\n",
    "        trips_df,\n",
    "        tours_merged,\n",
    "        left_on='tour_id',\n",
    "        right_index=True,\n",
    "        how=\"left\")\n",
    "    assert trips_merged.index.equals(trips.index)\n",
    "\n",
    "    # setup skim keys\n",
    "    assert ('trip_period' not in trips_merged)\n",
    "    trips_merged['trip_period'] = network_los.skim_time_period_label(trips_merged.depart)\n",
    "\n",
    "    orig_col = 'origin'\n",
    "    dest_col = 'destination'\n",
    "\n",
    "    constants = {}\n",
    "    constants.update(config.get_model_constants(model_settings))\n",
    "    constants.update({\n",
    "        'ORIGIN': orig_col,\n",
    "        'DESTINATION': dest_col\n",
    "    })\n",
    "\n",
    "    skim_dict = network_los.get_default_skim_dict()\n",
    "\n",
    "    odt_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=orig_col, dest_key=dest_col,\n",
    "                                               dim3_key='trip_period')\n",
    "    dot_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=dest_col, dest_key=orig_col,\n",
    "                                               dim3_key='trip_period')\n",
    "    od_skim_wrapper = skim_dict.wrap('origin', 'destination')\n",
    "\n",
    "    skims = {\n",
    "        \"odt_skims\": odt_skim_stack_wrapper,\n",
    "        \"dot_skims\": dot_skim_stack_wrapper,\n",
    "        \"od_skims\": od_skim_wrapper,\n",
    "    }\n",
    "\n",
    "    model_spec = simulate.read_model_spec(file_name=model_settings['SPEC'])\n",
    "    nest_specs = config.get_logit_model_settings(model_settings)\n",
    "\n",
    "    estimator = estimation.manager.begin_estimation('trip_mode_choice')\n",
    "\n",
    "    choices_list = []\n",
    "    for primary_purpose, trips_segment in trips_merged.groupby('primary_purpose'):\n",
    "\n",
    "        if (do_these_purposes is not None) and (primary_purpose not in do_these_purposes):\n",
    "            continue\n",
    "\n",
    "        print(\"trip_mode_choice tour_type '%s' (%s trips)\" %\n",
    "              (primary_purpose, len(trips_segment.index), ))\n",
    "\n",
    "        # name index so tracing knows how to slice\n",
    "        assert trips_segment.index.name == 'trip_id'\n",
    "\n",
    "        coefficients = simulate.get_segment_coefficients(model_settings, primary_purpose)\n",
    "\n",
    "        locals_dict = {}\n",
    "        locals_dict.update(constants)\n",
    "        locals_dict.update(coefficients)\n",
    "\n",
    "        segment_trace_label = tracing.extend_trace_label(trace_label, primary_purpose)\n",
    "\n",
    "        expressions.annotate_preprocessors(\n",
    "            trips_segment, locals_dict, skims,\n",
    "            model_settings, segment_trace_label)\n",
    "\n",
    "        locals_dict.update(skims)\n",
    "\n",
    "        ################ Replace wrapper function\n",
    "        #     choices = mode_choice_simulate(...)\n",
    "        spec=simulate.eval_coefficients(model_spec, coefficients, estimator)\n",
    "        nest_spec = simulate.eval_nest_coefficients(nest_specs, coefficients, segment_trace_label)\n",
    "        choices = simulate_function(\n",
    "            choosers=trips_segment,\n",
    "            spec=spec,\n",
    "            nest_spec=nest_spec,\n",
    "            skims=skims,\n",
    "            locals_d=locals_dict,\n",
    "            chunk_size=chunk_size,\n",
    "            want_logsums=logsum_column_name is not None,\n",
    "            trace_label=segment_trace_label,\n",
    "            trace_choice_name='trip_mode_choice',\n",
    "            estimator=estimator,\n",
    "            trace_column_names=None)\n",
    "        # for consistency, always return dataframe, whether or not logsums were requested\n",
    "        if isinstance(choices, pd.Series):\n",
    "            choices = choices.to_frame('choice')\n",
    "        choices.rename(columns={'logsum': logsum_column_name,\n",
    "                                'choice': mode_column_name},\n",
    "                       inplace=True)\n",
    "        alts = spec.columns\n",
    "        choices[mode_column_name] = choices[mode_column_name].map(dict(list(zip(list(range(len(alts))), alts))))\n",
    "        ################\n",
    "        choices_list.append(choices)\n",
    "    choices_df_asim = pd.concat(choices_list)\n",
    "\n",
    "    # update trips table with choices (and potionally logssums)\n",
    "    trips_df = trips.to_frame()\n",
    "\n",
    "    if (do_these_purposes is not None):\n",
    "        trips_df  = trips_df.loc[trips_df.primary_purpose.isin(do_these_purposes)]\n",
    "\n",
    "    assign_in_place(trips_df, choices_df_asim)\n",
    "    assert not trips_df[mode_column_name].isnull().any()\n",
    "\n",
    "    finalise = True\n",
    "    if finalise:\n",
    "        inject.set_step_args(None)\n",
    "        #\n",
    "        pipeline._PIPELINE.rng().end_step(model_name)\n",
    "        pipeline.add_checkpoint(model_name)\n",
    "        if not pipeline.intermediate_checkpoint():\n",
    "            pipeline.add_checkpoint(pipeline.FINAL_CHECKPOINT_NAME)\n",
    "\n",
    "        pipeline.close_pipeline()\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "    return trips_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed520e9-75ef-4eec-ab86-6aaf1fe453fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:28:53.643404Z",
     "iopub.status.busy": "2021-09-01T02:28:53.643055Z",
     "iopub.status.idle": "2021-09-01T02:29:01.223951Z",
     "shell.execute_reply": "2021-09-01T02:29:01.222865Z",
     "shell.execute_reply.started": "2021-09-01T02:28:53.643367Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "register joint_tour_participants: no rows with household_id in [982875].\n",
      "estimation bundle trip_mode_choice not in settings file estimation.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with %d trips 482\n",
      "trip_mode_choice tour_type 'atwork' (27 trips)\n",
      "trip_mode_choice tour_type 'eatout' (33 trips)\n",
      "trip_mode_choice tour_type 'escort' (6 trips)\n",
      "trip_mode_choice tour_type 'othdiscr' (43 trips)\n",
      "trip_mode_choice tour_type 'othmaint' (46 trips)\n",
      "trip_mode_choice tour_type 'school' (37 trips)\n",
      "trip_mode_choice tour_type 'shopping' (77 trips)\n",
      "trip_mode_choice tour_type 'social' (19 trips)\n",
      "trip_mode_choice tour_type 'univ' (26 trips)\n",
      "trip_mode_choice tour_type 'work' (168 trips)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "trips_df = run_trip_mode_choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eae2854-38bd-4da0-a161-3a15bbd17177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T10:30:57.562848Z",
     "iopub.status.busy": "2021-08-31T10:30:57.562615Z",
     "iopub.status.idle": "2021-08-31T10:30:57.806655Z",
     "shell.execute_reply": "2021-08-31T10:30:57.805135Z",
     "shell.execute_reply.started": "2021-08-31T10:30:57.562824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            person_id  household_id primary_purpose  trip_num  outbound  \\\ntrip_id                                                                   \n8684833         26478         26478          eatout         1      True   \n8684837         26478         26478          eatout         1     False   \n8685009         26478         26478        othmaint         1      True   \n8685013         26478         26478        othmaint         1     False   \n8753057         26686         26686          eatout         1      True   \n...               ...           ...             ...       ...       ...   \n2472945113    7539466       2848131        shopping         1      True   \n2472945117    7539466       2848131        shopping         1     False   \n2472945118    7539466       2848131        shopping         2     False   \n2473024473    7539708       2848373            univ         1      True   \n2473024477    7539708       2848373            univ         1     False   \n\n            trip_count  destination  origin    tour_id   purpose  \\\ntrip_id                                                            \n8684833              1           13       8    1085604    eatout   \n8684837              1            8      13    1085604      home   \n8685009              1           10       8    1085626  othmaint   \n8685013              1            8      10    1085626      home   \n8753057              1            5       8    1094132    eatout   \n...                ...          ...     ...        ...       ...   \n2472945113           1            8       3  309118139  shopping   \n2472945117           2           25       8  309118139  shopping   \n2472945118           2            3      25  309118139      home   \n2473024473           1           13      18  309128059      univ   \n2473024477           1           18      13  309128059      home   \n\n            destination_logsum  depart trip_mode  mode_choice_logsum  \ntrip_id                                                               \n8684833                    NaN    11.0      WALK           -1.171760  \n8684837                    NaN    11.0      WALK           -1.238719  \n8685009                    NaN    12.0      BIKE            6.198626  \n8685013                    NaN    13.0      BIKE            6.175681  \n8753057                    NaN    19.0      WALK            4.457539  \n...                        ...     ...       ...                 ...  \n2472945113                 NaN    18.0  WALK_LOC           12.537675  \n2472945117           56.842247    21.0  WALK_LOC           11.880804  \n2472945118                 NaN    22.0      WALK           13.710030  \n2473024473                 NaN    16.0  WALK_LOC           -0.530696  \n2473024477                 NaN    23.0  WALK_LRF            0.624304  \n\n[482 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_id</th>\n      <th>household_id</th>\n      <th>primary_purpose</th>\n      <th>trip_num</th>\n      <th>outbound</th>\n      <th>trip_count</th>\n      <th>destination</th>\n      <th>origin</th>\n      <th>tour_id</th>\n      <th>purpose</th>\n      <th>destination_logsum</th>\n      <th>depart</th>\n      <th>trip_mode</th>\n      <th>mode_choice_logsum</th>\n    </tr>\n    <tr>\n      <th>trip_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8684833</th>\n      <td>26478</td>\n      <td>26478</td>\n      <td>eatout</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>13</td>\n      <td>8</td>\n      <td>1085604</td>\n      <td>eatout</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>WALK</td>\n      <td>-1.171760</td>\n    </tr>\n    <tr>\n      <th>8684837</th>\n      <td>26478</td>\n      <td>26478</td>\n      <td>eatout</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>8</td>\n      <td>13</td>\n      <td>1085604</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>WALK</td>\n      <td>-1.238719</td>\n    </tr>\n    <tr>\n      <th>8685009</th>\n      <td>26478</td>\n      <td>26478</td>\n      <td>othmaint</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>10</td>\n      <td>8</td>\n      <td>1085626</td>\n      <td>othmaint</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>BIKE</td>\n      <td>6.198626</td>\n    </tr>\n    <tr>\n      <th>8685013</th>\n      <td>26478</td>\n      <td>26478</td>\n      <td>othmaint</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>8</td>\n      <td>10</td>\n      <td>1085626</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>BIKE</td>\n      <td>6.175681</td>\n    </tr>\n    <tr>\n      <th>8753057</th>\n      <td>26686</td>\n      <td>26686</td>\n      <td>eatout</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1094132</td>\n      <td>eatout</td>\n      <td>NaN</td>\n      <td>19.0</td>\n      <td>WALK</td>\n      <td>4.457539</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2472945113</th>\n      <td>7539466</td>\n      <td>2848131</td>\n      <td>shopping</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>8</td>\n      <td>3</td>\n      <td>309118139</td>\n      <td>shopping</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>WALK_LOC</td>\n      <td>12.537675</td>\n    </tr>\n    <tr>\n      <th>2472945117</th>\n      <td>7539466</td>\n      <td>2848131</td>\n      <td>shopping</td>\n      <td>1</td>\n      <td>False</td>\n      <td>2</td>\n      <td>25</td>\n      <td>8</td>\n      <td>309118139</td>\n      <td>shopping</td>\n      <td>56.842247</td>\n      <td>21.0</td>\n      <td>WALK_LOC</td>\n      <td>11.880804</td>\n    </tr>\n    <tr>\n      <th>2472945118</th>\n      <td>7539466</td>\n      <td>2848131</td>\n      <td>shopping</td>\n      <td>2</td>\n      <td>False</td>\n      <td>2</td>\n      <td>3</td>\n      <td>25</td>\n      <td>309118139</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>WALK</td>\n      <td>13.710030</td>\n    </tr>\n    <tr>\n      <th>2473024473</th>\n      <td>7539708</td>\n      <td>2848373</td>\n      <td>univ</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>13</td>\n      <td>18</td>\n      <td>309128059</td>\n      <td>univ</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>WALK_LOC</td>\n      <td>-0.530696</td>\n    </tr>\n    <tr>\n      <th>2473024477</th>\n      <td>7539708</td>\n      <td>2848373</td>\n      <td>univ</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>18</td>\n      <td>13</td>\n      <td>309128059</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>WALK_LRF</td>\n      <td>0.624304</td>\n    </tr>\n  </tbody>\n</table>\n<p>482 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebea31-499c-41ca-8411-883a88ca800a",
   "metadata": {},
   "source": [
    "## nested dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e2513e9-c03f-4891-9a1c-4053a4440a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T10:31:01.113060Z",
     "iopub.status.busy": "2021-08-31T10:31:01.112829Z",
     "iopub.status.idle": "2021-08-31T10:31:01.359912Z",
     "shell.execute_reply": "2021-08-31T10:31:01.358948Z",
     "shell.execute_reply.started": "2021-08-31T10:31:01.113034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see fct above - return if necessary\n",
    "#spec = simulate.eval_coefficients(model_spec, coefficients, estimator)\n",
    "#nest_spec = simulate.eval_nest_coefficients(nest_spec, coefficients, segment_trace_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c100b3-3e39-4950-a586-4d42be695eaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T10:31:01.775068Z",
     "iopub.status.busy": "2021-08-31T10:31:01.774846Z",
     "iopub.status.idle": "2021-08-31T10:31:01.975816Z",
     "shell.execute_reply": "2021-08-31T10:31:01.974499Z",
     "shell.execute_reply.started": "2021-08-31T10:31:01.775044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(nest_spec)\n",
    "#for nest in logit.each_nest(nest_spec):\n",
    "#    nest.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d11f6a-f82a-40bd-8eef-fc28bcca8252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:59:35.109079Z",
     "iopub.status.busy": "2021-09-01T01:59:35.108781Z",
     "iopub.status.idle": "2021-09-01T01:59:35.319301Z",
     "shell.execute_reply": "2021-09-01T01:59:35.318402Z",
     "shell.execute_reply.started": "2021-09-01T01:59:35.109050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_nl_dev(choosers, spec, nest_spec, locals_d, custom_chooser, estimator,\n",
    "                log_alt_losers=False,\n",
    "                want_logsums=False, trace_label=None,\n",
    "                trace_choice_name=None, trace_column_names=None):\n",
    "\n",
    "    trace_label = tracing.extend_trace_label(trace_label, 'eval_nl')\n",
    "    assert trace_label\n",
    "    have_trace_targets = tracing.has_trace_targets(choosers)\n",
    "\n",
    "    logit.validate_nest_spec(nest_spec, trace_label)\n",
    "\n",
    "    if have_trace_targets:\n",
    "        tracing.trace_df(choosers, '%s.choosers' % trace_label)\n",
    "\n",
    "    raw_utilities = simulate.eval_utilities(spec, choosers, locals_d,\n",
    "                                            log_alt_losers=log_alt_losers,\n",
    "                                            trace_label=trace_label, have_trace_targets=have_trace_targets,\n",
    "                                            estimator=estimator, trace_column_names=trace_column_names)\n",
    "    chunk.log_df(trace_label, \"raw_utilities\", raw_utilities)\n",
    "\n",
    "    if have_trace_targets:\n",
    "        tracing.trace_df(raw_utilities, '%s.raw_utilities' % trace_label,\n",
    "                         column_labels=['alternative', 'utility'])\n",
    "\n",
    "    # exponentiated utilities of leaves and nests\n",
    "    nested_exp_utilities = simulate.compute_nested_exp_utilities(raw_utilities, nest_spec)\n",
    "    chunk.log_df(trace_label, \"nested_exp_utilities\", nested_exp_utilities)\n",
    "\n",
    "    del raw_utilities\n",
    "    chunk.log_df(trace_label, 'raw_utilities', None)\n",
    "\n",
    "    if have_trace_targets:\n",
    "        tracing.trace_df(nested_exp_utilities, '%s.nested_exp_utilities' % trace_label,\n",
    "                         column_labels=['alternative', 'utility'])\n",
    "\n",
    "    # probabilities of alternatives relative to siblings sharing the same nest\n",
    "    nested_probabilities = simulate.compute_nested_probabilities(nested_exp_utilities, nest_spec,\n",
    "                                                                 trace_label=trace_label)\n",
    "    chunk.log_df(trace_label, \"nested_probabilities\", nested_probabilities)\n",
    "\n",
    "    if want_logsums:\n",
    "        # logsum of nest root\n",
    "        logsums = pd.Series(np.log(nested_exp_utilities.root), index=choosers.index)\n",
    "        chunk.log_df(trace_label, \"logsums\", logsums)\n",
    "\n",
    "    del nested_exp_utilities\n",
    "    chunk.log_df(trace_label, 'nested_exp_utilities', None)\n",
    "\n",
    "    if have_trace_targets:\n",
    "        tracing.trace_df(nested_probabilities, '%s.nested_probabilities' % trace_label,\n",
    "                         column_labels=['alternative', 'probability'])\n",
    "\n",
    "    # global (flattened) leaf probabilities based on relative nest coefficients (in spec order)\n",
    "    base_probabilities = simulate.compute_base_probabilities(nested_probabilities, nest_spec, spec)\n",
    "    chunk.log_df(trace_label, \"base_probabilities\", base_probabilities)\n",
    "\n",
    "    del nested_probabilities\n",
    "    chunk.log_df(trace_label, 'nested_probabilities', None)\n",
    "\n",
    "    if have_trace_targets:\n",
    "        tracing.trace_df(base_probabilities, '%s.base_probabilities' % trace_label,\n",
    "                         column_labels=['alternative', 'probability'])\n",
    "\n",
    "    # note base_probabilities could all be zero since we allowed all probs for nests to be zero\n",
    "    # check here to print a clear message but make_choices will raise error if probs don't sum to 1\n",
    "    BAD_PROB_THRESHOLD = 0.001\n",
    "    no_choices = (base_probabilities.sum(axis=1) - 1).abs() > BAD_PROB_THRESHOLD\n",
    "\n",
    "    if no_choices.any():\n",
    "\n",
    "        logit.report_bad_choices(\n",
    "            no_choices, base_probabilities,\n",
    "            trace_label=tracing.extend_trace_label(trace_label, 'bad_probs'),\n",
    "            trace_choosers=choosers,\n",
    "            msg=\"base_probabilities do not sum to one\")\n",
    "\n",
    "    if custom_chooser:\n",
    "        choices, rands = custom_chooser(probs=base_probabilities, choosers=choosers, spec=spec,\n",
    "                                        trace_label=trace_label)\n",
    "    else:\n",
    "        choices, rands = logit.make_choices(base_probabilities, trace_label=trace_label)\n",
    "\n",
    "    del base_probabilities\n",
    "    chunk.log_df(trace_label, 'base_probabilities', None)\n",
    "\n",
    "    if have_trace_targets:\n",
    "        tracing.trace_df(choices, '%s.choices' % trace_label,\n",
    "                         columns=[None, trace_choice_name])\n",
    "        tracing.trace_df(rands, '%s.rands' % trace_label,\n",
    "                         columns=[None, 'rand'])\n",
    "        if want_logsums:\n",
    "            tracing.trace_df(logsums, '%s.logsums' % trace_label,\n",
    "                             columns=[None, 'logsum'])\n",
    "\n",
    "    if want_logsums:\n",
    "        choices = choices.to_frame('choice')\n",
    "        choices['logsum'] = logsums\n",
    "\n",
    "    return choices\n",
    "\n",
    "\n",
    "def simple_simulate_dev(choosers, spec, nest_spec,\n",
    "                    skims=None, locals_d=None,\n",
    "                    chunk_size=0, custom_chooser=None,\n",
    "                    log_alt_losers=False,\n",
    "                    want_logsums=False,\n",
    "                    estimator=None,\n",
    "                    trace_label=None, trace_choice_name=None, trace_column_names=None):\n",
    "    trace_label = tracing.extend_trace_label(trace_label, 'simple_simulate')\n",
    "    assert len(choosers) > 0\n",
    "    result_list = []\n",
    "    # segment by person type and pick the right spec for each person type\n",
    "    for i, chooser_chunk, chunk_trace_label \\\n",
    "            in chunk.adaptive_chunked_choosers(choosers, chunk_size, trace_label):\n",
    "        # the following replaces choices = _simple_simulate(...)\n",
    "        if skims is not None:\n",
    "            simulate.set_skim_wrapper_targets(choosers, skims)\n",
    "\n",
    "        # only do this for nested, logit is straight forward\n",
    "        assert nest_spec is not None\n",
    "        choices = eval_nl_dev(choosers, spec, nest_spec, locals_d,  custom_chooser,\n",
    "                          log_alt_losers=log_alt_losers,\n",
    "                          want_logsums=want_logsums,\n",
    "                          estimator=estimator,\n",
    "                          trace_label=trace_label,\n",
    "                          trace_choice_name=trace_choice_name, trace_column_names=trace_column_names)\n",
    "\n",
    "\n",
    "        result_list.append(choices)\n",
    "        chunk.log_df(trace_label, f'result_list', result_list)\n",
    "\n",
    "    if len(result_list) > 1:\n",
    "        choices = pd.concat(result_list)\n",
    "    assert len(choices.index == len(choosers.index))\n",
    "    return choices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec4eb1ff-2f35-4919-96b4-5acffa01f597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "register joint_tour_participants: no rows with household_id in [982875].\n",
      "estimation bundle trip_mode_choice not in settings file estimation.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with %d trips 482\n",
      "trip_mode_choice tour_type 'escort' (6 trips)\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": "           person_id  household_id primary_purpose  trip_num  outbound  \\\ntrip_id                                                                  \n137248721     418441        304036          escort         1      True   \n137248725     418441        304036          escort         1     False   \n211388201     644476        386761          escort         1      True   \n211388205     644476        386761          escort         1     False   \n806388401    2458501       1173905          escort         1      True   \n806388405    2458501       1173905          escort         1     False   \n\n           trip_count  destination  origin    tour_id purpose  \\\ntrip_id                                                         \n137248721           1            7      10   17156090  escort   \n137248725           1           10       7   17156090    home   \n211388201           1           11      16   26423525  escort   \n211388205           1           16      11   26423525    home   \n806388401           1           16       8  100798550  escort   \n806388405           1            8      16  100798550    home   \n\n           destination_logsum  depart trip_mode  mode_choice_logsum  \ntrip_id                                                              \n137248721                 NaN     7.0      WALK           11.435800  \n137248725                 NaN     7.0      WALK           11.480440  \n211388201                 NaN     5.0  WALK_LOC            4.789158  \n211388205                 NaN     6.0  WALK_LOC            5.050171  \n806388401                 NaN    15.0  WALK_LOC            6.451457  \n806388405                 NaN    16.0  WALK_LOC            6.446188  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_id</th>\n      <th>household_id</th>\n      <th>primary_purpose</th>\n      <th>trip_num</th>\n      <th>outbound</th>\n      <th>trip_count</th>\n      <th>destination</th>\n      <th>origin</th>\n      <th>tour_id</th>\n      <th>purpose</th>\n      <th>destination_logsum</th>\n      <th>depart</th>\n      <th>trip_mode</th>\n      <th>mode_choice_logsum</th>\n    </tr>\n    <tr>\n      <th>trip_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>137248721</th>\n      <td>418441</td>\n      <td>304036</td>\n      <td>escort</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>7</td>\n      <td>10</td>\n      <td>17156090</td>\n      <td>escort</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>WALK</td>\n      <td>11.435800</td>\n    </tr>\n    <tr>\n      <th>137248725</th>\n      <td>418441</td>\n      <td>304036</td>\n      <td>escort</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>17156090</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>WALK</td>\n      <td>11.480440</td>\n    </tr>\n    <tr>\n      <th>211388201</th>\n      <td>644476</td>\n      <td>386761</td>\n      <td>escort</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>11</td>\n      <td>16</td>\n      <td>26423525</td>\n      <td>escort</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>WALK_LOC</td>\n      <td>4.789158</td>\n    </tr>\n    <tr>\n      <th>211388205</th>\n      <td>644476</td>\n      <td>386761</td>\n      <td>escort</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>16</td>\n      <td>11</td>\n      <td>26423525</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>WALK_LOC</td>\n      <td>5.050171</td>\n    </tr>\n    <tr>\n      <th>806388401</th>\n      <td>2458501</td>\n      <td>1173905</td>\n      <td>escort</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>16</td>\n      <td>8</td>\n      <td>100798550</td>\n      <td>escort</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>WALK_LOC</td>\n      <td>6.451457</td>\n    </tr>\n    <tr>\n      <th>806388405</th>\n      <td>2458501</td>\n      <td>1173905</td>\n      <td>escort</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>8</td>\n      <td>16</td>\n      <td>100798550</td>\n      <td>home</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>WALK_LOC</td>\n      <td>6.446188</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trips = run_trip_mode_choice(do_these_purposes=[\"escort\"], simulate_function=simple_simulate_dev)\n",
    "test_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get raw utilities, etc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def eval_nl_dev(choosers, spec, nest_spec, locals_d, custom_chooser, estimator,\n",
    "                log_alt_losers=False,\n",
    "                want_logsums=False, trace_label=None,\n",
    "                trace_choice_name=None, trace_column_names=None):\n",
    "\n",
    "    trace_label = tracing.extend_trace_label(trace_label, 'eval_nl')\n",
    "    assert trace_label\n",
    "    have_trace_targets = tracing.has_trace_targets(choosers)\n",
    "\n",
    "    logit.validate_nest_spec(nest_spec, trace_label)\n",
    "    raw_utilities = simulate.eval_utilities(spec, choosers, locals_d,\n",
    "                                            log_alt_losers=log_alt_losers,\n",
    "                                            trace_label=trace_label, have_trace_targets=have_trace_targets,\n",
    "                                            estimator=estimator, trace_column_names=trace_column_names)\n",
    "    # exponentiated utilities of leaves and nests\n",
    "    nested_exp_utilities = simulate.compute_nested_exp_utilities(raw_utilities, nest_spec)\n",
    "    nested_utils = simulate.compute_nested_utilities(raw_utilities, nest_spec)\n",
    "    # probabilities of alternatives relative to siblings sharing the same nest\n",
    "    nested_probabilities = simulate.compute_nested_probabilities(nested_exp_utilities, nest_spec,\n",
    "                                                                 trace_label=trace_label)\n",
    "    if want_logsums:\n",
    "        # logsum of nest root\n",
    "        logsums = pd.Series(np.log(nested_exp_utilities.root), index=choosers.index)\n",
    "    # global (flattened) leaf probabilities based on relative nest coefficients (in spec order)\n",
    "    base_probabilities = simulate.compute_base_probabilities(nested_probabilities, nest_spec, spec)\n",
    "    # note base_probabilities could all be zero since we allowed all probs for nests to be zero\n",
    "    # check here to print a clear message but make_choices will raise error if probs don't sum to 1\n",
    "    BAD_PROB_THRESHOLD = 0.001\n",
    "    no_choices = (base_probabilities.sum(axis=1) - 1).abs() > BAD_PROB_THRESHOLD\n",
    "    if no_choices.any():\n",
    "        print(\"BAD\")\n",
    "    choices, rands = logit.make_choices(base_probabilities, trace_label=trace_label)\n",
    "    if want_logsums:\n",
    "        choices = choices.to_frame('choice')\n",
    "        choices['logsum'] = logsums\n",
    "    return choices, raw_utilities, nested_exp_utilities, nested_utils\n",
    "\n",
    "\n",
    "def simple_simulate_dev(choosers, spec, nest_spec,\n",
    "                        skims=None, locals_d=None,\n",
    "                        chunk_size=0, custom_chooser=None,\n",
    "                        log_alt_losers=False,\n",
    "                        want_logsums=False,\n",
    "                        estimator=None,\n",
    "                        trace_label=None, trace_choice_name=None, trace_column_names=None):\n",
    "    trace_label = tracing.extend_trace_label(trace_label, 'simple_simulate')\n",
    "    assert len(choosers) > 0\n",
    "    result_list = []\n",
    "    # segment by person type and pick the right spec for each person type\n",
    "    for i, chooser_chunk, chunk_trace_label in chunk.adaptive_chunked_choosers(choosers, chunk_size, trace_label):\n",
    "        # the following replaces choices = _simple_simulate(...)\n",
    "        if skims is not None:\n",
    "            simulate.set_skim_wrapper_targets(choosers, skims)\n",
    "\n",
    "        # only do this for nested, logit is straight forward\n",
    "        assert nest_spec is not None\n",
    "        choices, raw_utilities, nested_exp_utilities, nested_utils = eval_nl_dev(choosers, spec, nest_spec, locals_d,\n",
    "                                                                    custom_chooser,\n",
    "                              log_alt_losers=log_alt_losers,\n",
    "                              want_logsums=want_logsums,\n",
    "                              estimator=estimator,\n",
    "                              trace_label=trace_label,\n",
    "                              trace_choice_name=trace_choice_name, trace_column_names=trace_column_names)\n",
    "\n",
    "\n",
    "        result_list.append(choices)\n",
    "        chunk.log_df(trace_label, f'result_list', result_list)\n",
    "\n",
    "    if len(result_list) > 1:\n",
    "        choices = pd.concat(result_list)\n",
    "    assert len(choices.index == len(choosers.index))\n",
    "    return choices, raw_utilities, nested_exp_utilities, nested_utils\n",
    "\n",
    "\n",
    "def get_stuff(do_these_purposes=None):\n",
    "    #do_these_purposes=['escort']\n",
    "    \"\"\"open pipeline and load stuff for mode choice dev assuming model has been run and pipeline.h5 exists\"\"\"\n",
    "    resume_after = \"trip_scheduling\"\n",
    "    model_name = \"trip_mode_choice\"\n",
    "    chunk_size = 0  # test_mtc means no chunking\n",
    "\n",
    "    pipeline.open_pipeline(resume_after)\n",
    "    # preload any bulky injectables (e.g. skims) not in pipeline\n",
    "    inject.get_injectable('preload_injectables', None)\n",
    "    pipeline._PIPELINE.rng().begin_step(model_name)\n",
    "    step_name = model_name\n",
    "    args = {}\n",
    "    checkpoint = pipeline.intermediate_checkpoint(model_name)\n",
    "    inject.set_step_args(args)\n",
    "\n",
    "    trips = inject.get_table('trips')\n",
    "    tours_merged = inject.get_table('tours_merged')\n",
    "    network_los = inject.get_injectable('network_los')\n",
    "\n",
    "    trace_label = 'trip_mode_choice'\n",
    "    model_settings_file_name = 'trip_mode_choice.yaml'\n",
    "    model_settings = config.read_model_settings(model_settings_file_name)\n",
    "\n",
    "    logsum_column_name = model_settings.get('MODE_CHOICE_LOGSUM_COLUMN_NAME')\n",
    "    mode_column_name = 'trip_mode'\n",
    "\n",
    "    trips_df = trips.to_frame()\n",
    "    print(\"Running with %d trips\", trips_df.shape[0])\n",
    "\n",
    "    tours_merged = tours_merged.to_frame()\n",
    "    tours_merged = tours_merged[model_settings['TOURS_MERGED_CHOOSER_COLUMNS']]\n",
    "\n",
    "    # - trips_merged - merge trips and tours_merged\n",
    "    trips_merged = pd.merge(\n",
    "        trips_df,\n",
    "        tours_merged,\n",
    "        left_on='tour_id',\n",
    "        right_index=True,\n",
    "        how=\"left\")\n",
    "    assert trips_merged.index.equals(trips.index)\n",
    "\n",
    "    # setup skim keys\n",
    "    assert ('trip_period' not in trips_merged)\n",
    "    trips_merged['trip_period'] = network_los.skim_time_period_label(trips_merged.depart)\n",
    "\n",
    "    orig_col = 'origin'\n",
    "    dest_col = 'destination'\n",
    "\n",
    "    constants = {}\n",
    "    constants.update(config.get_model_constants(model_settings))\n",
    "    constants.update({\n",
    "        'ORIGIN': orig_col,\n",
    "        'DESTINATION': dest_col\n",
    "    })\n",
    "\n",
    "    skim_dict = network_los.get_default_skim_dict()\n",
    "\n",
    "    odt_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=orig_col, dest_key=dest_col,\n",
    "                                               dim3_key='trip_period')\n",
    "    dot_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=dest_col, dest_key=orig_col,\n",
    "                                               dim3_key='trip_period')\n",
    "    od_skim_wrapper = skim_dict.wrap('origin', 'destination')\n",
    "\n",
    "    skims = {\n",
    "        \"odt_skims\": odt_skim_stack_wrapper,\n",
    "        \"dot_skims\": dot_skim_stack_wrapper,\n",
    "        \"od_skims\": od_skim_wrapper,\n",
    "    }\n",
    "\n",
    "    model_spec = simulate.read_model_spec(file_name=model_settings['SPEC'])\n",
    "    nest_specs = config.get_logit_model_settings(model_settings)\n",
    "\n",
    "    estimator = estimation.manager.begin_estimation('trip_mode_choice')\n",
    "\n",
    "    choices_list = []\n",
    "    raw_util_list = []\n",
    "    nest_list = []\n",
    "    nu_list = []\n",
    "    nest_spec_list = []\n",
    "\n",
    "    for primary_purpose, trips_segment in trips_merged.groupby('primary_purpose'):\n",
    "\n",
    "        if (do_these_purposes is not None) and (primary_purpose not in do_these_purposes):\n",
    "            continue\n",
    "\n",
    "        print(\"trip_mode_choice tour_type '%s' (%s trips)\" %\n",
    "              (primary_purpose, len(trips_segment.index), ))\n",
    "\n",
    "        # name index so tracing knows how to slice\n",
    "        assert trips_segment.index.name == 'trip_id'\n",
    "\n",
    "        coefficients = simulate.get_segment_coefficients(model_settings, primary_purpose)\n",
    "\n",
    "        locals_dict = {}\n",
    "        locals_dict.update(constants)\n",
    "        locals_dict.update(coefficients)\n",
    "\n",
    "        segment_trace_label = tracing.extend_trace_label(trace_label, primary_purpose)\n",
    "\n",
    "        expressions.annotate_preprocessors(\n",
    "            trips_segment, locals_dict, skims,\n",
    "            model_settings, segment_trace_label)\n",
    "\n",
    "        locals_dict.update(skims)\n",
    "\n",
    "        ################ Replace wrapper function\n",
    "        #     choices = mode_choice_simulate(...)\n",
    "        spec=simulate.eval_coefficients(model_spec, coefficients, estimator)\n",
    "        nest_spec = simulate.eval_nest_coefficients(nest_specs, coefficients, segment_trace_label)\n",
    "        choices, raw_utilities, nested_exp_utilities, nested_utils = simple_simulate_dev(\n",
    "            choosers=trips_segment,\n",
    "            spec=spec,\n",
    "            nest_spec=nest_spec,\n",
    "            skims=skims,\n",
    "            locals_d=locals_dict,\n",
    "            chunk_size=chunk_size,\n",
    "            want_logsums=logsum_column_name is not None,\n",
    "            trace_label=segment_trace_label,\n",
    "            trace_choice_name='trip_mode_choice',\n",
    "            estimator=estimator,\n",
    "            trace_column_names=None)\n",
    "        # for consistency, always return dataframe, whether or not logsums were requested\n",
    "        if isinstance(choices, pd.Series):\n",
    "            choices = choices.to_frame('choice')\n",
    "        choices.rename(columns={'logsum': logsum_column_name,\n",
    "                                'choice': mode_column_name},\n",
    "                       inplace=True)\n",
    "        alts = spec.columns\n",
    "        choices[mode_column_name] = choices[mode_column_name].map(dict(list(zip(list(range(len(alts))), alts))))\n",
    "        ################\n",
    "        choices_list.append(choices)\n",
    "        raw_util_list.append(raw_utilities)\n",
    "        nest_list.append(nested_exp_utilities)\n",
    "        nu_list.append(nested_utils)\n",
    "        nest_spec_list.append(nest_spec)\n",
    "\n",
    "    choices_df_asim = pd.concat(choices_list)\n",
    "\n",
    "    # update trips table with choices (and potionally logssums)\n",
    "    trips_df = trips.to_frame()\n",
    "\n",
    "    if (do_these_purposes is not None):\n",
    "        trips_df  = trips_df.loc[trips_df.primary_purpose.isin(do_these_purposes)]\n",
    "\n",
    "    assign_in_place(trips_df, choices_df_asim)\n",
    "    assert not trips_df[mode_column_name].isnull().any()\n",
    "\n",
    "    finalise = True\n",
    "    if finalise:\n",
    "        inject.set_step_args(None)\n",
    "        #\n",
    "        pipeline._PIPELINE.rng().end_step(model_name)\n",
    "        pipeline.add_checkpoint(model_name)\n",
    "        if not pipeline.intermediate_checkpoint():\n",
    "            pipeline.add_checkpoint(pipeline.FINAL_CHECKPOINT_NAME)\n",
    "\n",
    "        pipeline.close_pipeline()\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "    return trips_df, raw_util_list, nest_list, nu_list, nest_spec_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "register joint_tour_participants: no rows with household_id in [982875].\n",
      "estimation bundle trip_mode_choice not in settings file estimation.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with %d trips 482\n",
      "trip_mode_choice tour_type 'escort' (6 trips)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "t, ru, neu, nu, ns = get_stuff(do_these_purposes=[\"escort\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "           DRIVEALONEFREE  DRIVEALONEPAY  DRIVEALONE  SHARED2FREE  \\\ntrip_id                                                             \n137248721       -1.294906   -2855.580620   -0.453217    -0.280520   \n137248725       -1.247739   -2855.533453   -0.436709    -0.233697   \n211388201    -2855.520162   -5709.805876        -inf   -17.366498   \n211388205    -2856.810200   -5711.095914        -inf   -18.093309   \n806388401    -2855.874866   -5710.160580        -inf    -9.085232   \n806388405    -2858.281791   -5712.567505        -inf   -10.451460   \n\n            SHARED2PAY  SHAREDRIDE2  SHARED3FREE   SHARED3PAY  SHAREDRIDE3  \\\ntrip_id                                                                      \n137248721 -2854.566235    -0.098182 -2855.573680 -5709.859395         -inf   \n137248725 -2854.519411    -0.081794 -2855.526994 -5709.812708         -inf   \n211388201 -2871.652212    -6.078274   -21.226117 -2875.511831    -7.429141   \n211388205 -2872.379023    -6.332658   -21.727638 -2876.013352    -7.604673   \n806388401 -2863.370946    -3.179831   -10.734064 -2865.019778    -3.756922   \n806388405 -2864.737174    -3.658011   -11.684013 -2865.969727    -4.089405   \n\n               AUTO       WALK         BIKE  NONMOTORIZED     WALK_LOC  \\\ntrip_id                                                                  \n137248721  0.311848  15.883036 -1368.200102     11.435786 -1970.783011   \n137248725  0.323683  15.945036 -1368.169103     11.480426 -1970.850529   \n211388201 -4.210520  -4.216264 -1381.397292     -3.035710     9.572919   \n211388205 -4.381625  -4.216264 -1381.397292     -3.035710    10.096155   \n806388401 -1.968599   6.192499 -1378.480723      4.458599    12.609633   \n806388405 -2.273383   5.998749 -1378.519473      4.319099    12.638426   \n\n              WALK_LRF     WALK_EXP     WALK_HVY     WALK_COM  WALKACCESS  \\\ntrip_id                                                                     \n137248721 -3968.783011 -3968.783011 -3968.783011 -3968.783011        -inf   \n137248725 -3968.850529 -3968.850529 -3968.850529 -3968.850529        -inf   \n211388201 -1988.028653 -1988.028653 -1988.028653 -1988.028653    4.786459   \n211388205 -1987.903845 -1987.903845 -1987.903845 -1987.903845    5.048078   \n806388401 -1984.209027 -1983.750027 -1984.124827 -1984.171027    6.304817   \n806388405 -1984.311174 -1983.852174 -1984.226974 -1984.273174    6.319213   \n\n             DRIVE_LOC    DRIVE_LRF    DRIVE_EXP    DRIVE_HVY    DRIVE_COM  \\\ntrip_id                                                                      \n137248721 -1970.903118 -3973.401006 -3973.401006 -3974.669500 -3975.688637   \n137248725 -1971.203369 -3975.938495 -3975.938495 -3971.574832 -3978.057757   \n211388201 -1988.387109 -3990.994654 -3990.994654 -1994.178373 -1997.184706   \n211388205 -1988.132266 -3993.215462 -3993.215462 -1990.677481 -1997.375747   \n806388401 -1985.442854 -3989.293913 -3989.293913 -3990.843560 -3993.682148   \n806388405 -1985.451447 -3990.724818 -3990.724818 -3987.215444 -3994.211225   \n\n           DRIVEACCESS   TRANSIT       TAXI  TNC_SINGLE  TNC_SHARED  RIDEHAIL  \\\ntrip_id                                                                         \n137248721         -inf      -inf -24.503675  -25.143041  -24.249471 -8.448473   \n137248725         -inf      -inf -24.341318  -25.104291  -24.140831 -8.406870   \n211388201         -inf  3.446251 -15.861515   -3.864497   -5.068360 -1.296757   \n211388205         -inf  3.634616 -15.776424   -3.845077   -5.005482 -1.286094   \n806388401         -inf  4.539468 -19.143696  -19.495908  -16.361074 -5.853917   \n806388405         -inf  4.549833 -18.886576  -19.495133  -16.300395 -5.828540   \n\n                root  \ntrip_id               \n137248721  11.435801  \n137248725  11.480441  \n211388201   3.456910  \n211388205   3.643469  \n806388401   5.193789  \n806388405   5.134877  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DRIVEALONEFREE</th>\n      <th>DRIVEALONEPAY</th>\n      <th>DRIVEALONE</th>\n      <th>SHARED2FREE</th>\n      <th>SHARED2PAY</th>\n      <th>SHAREDRIDE2</th>\n      <th>SHARED3FREE</th>\n      <th>SHARED3PAY</th>\n      <th>SHAREDRIDE3</th>\n      <th>AUTO</th>\n      <th>WALK</th>\n      <th>BIKE</th>\n      <th>NONMOTORIZED</th>\n      <th>WALK_LOC</th>\n      <th>WALK_LRF</th>\n      <th>WALK_EXP</th>\n      <th>WALK_HVY</th>\n      <th>WALK_COM</th>\n      <th>WALKACCESS</th>\n      <th>DRIVE_LOC</th>\n      <th>DRIVE_LRF</th>\n      <th>DRIVE_EXP</th>\n      <th>DRIVE_HVY</th>\n      <th>DRIVE_COM</th>\n      <th>DRIVEACCESS</th>\n      <th>TRANSIT</th>\n      <th>TAXI</th>\n      <th>TNC_SINGLE</th>\n      <th>TNC_SHARED</th>\n      <th>RIDEHAIL</th>\n      <th>root</th>\n    </tr>\n    <tr>\n      <th>trip_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>137248721</th>\n      <td>-1.294906</td>\n      <td>-2855.580620</td>\n      <td>-0.453217</td>\n      <td>-0.280520</td>\n      <td>-2854.566235</td>\n      <td>-0.098182</td>\n      <td>-2855.573680</td>\n      <td>-5709.859395</td>\n      <td>-inf</td>\n      <td>0.311848</td>\n      <td>15.883036</td>\n      <td>-1368.200102</td>\n      <td>11.435786</td>\n      <td>-1970.783011</td>\n      <td>-3968.783011</td>\n      <td>-3968.783011</td>\n      <td>-3968.783011</td>\n      <td>-3968.783011</td>\n      <td>-inf</td>\n      <td>-1970.903118</td>\n      <td>-3973.401006</td>\n      <td>-3973.401006</td>\n      <td>-3974.669500</td>\n      <td>-3975.688637</td>\n      <td>-inf</td>\n      <td>-inf</td>\n      <td>-24.503675</td>\n      <td>-25.143041</td>\n      <td>-24.249471</td>\n      <td>-8.448473</td>\n      <td>11.435801</td>\n    </tr>\n    <tr>\n      <th>137248725</th>\n      <td>-1.247739</td>\n      <td>-2855.533453</td>\n      <td>-0.436709</td>\n      <td>-0.233697</td>\n      <td>-2854.519411</td>\n      <td>-0.081794</td>\n      <td>-2855.526994</td>\n      <td>-5709.812708</td>\n      <td>-inf</td>\n      <td>0.323683</td>\n      <td>15.945036</td>\n      <td>-1368.169103</td>\n      <td>11.480426</td>\n      <td>-1970.850529</td>\n      <td>-3968.850529</td>\n      <td>-3968.850529</td>\n      <td>-3968.850529</td>\n      <td>-3968.850529</td>\n      <td>-inf</td>\n      <td>-1971.203369</td>\n      <td>-3975.938495</td>\n      <td>-3975.938495</td>\n      <td>-3971.574832</td>\n      <td>-3978.057757</td>\n      <td>-inf</td>\n      <td>-inf</td>\n      <td>-24.341318</td>\n      <td>-25.104291</td>\n      <td>-24.140831</td>\n      <td>-8.406870</td>\n      <td>11.480441</td>\n    </tr>\n    <tr>\n      <th>211388201</th>\n      <td>-2855.520162</td>\n      <td>-5709.805876</td>\n      <td>-inf</td>\n      <td>-17.366498</td>\n      <td>-2871.652212</td>\n      <td>-6.078274</td>\n      <td>-21.226117</td>\n      <td>-2875.511831</td>\n      <td>-7.429141</td>\n      <td>-4.210520</td>\n      <td>-4.216264</td>\n      <td>-1381.397292</td>\n      <td>-3.035710</td>\n      <td>9.572919</td>\n      <td>-1988.028653</td>\n      <td>-1988.028653</td>\n      <td>-1988.028653</td>\n      <td>-1988.028653</td>\n      <td>4.786459</td>\n      <td>-1988.387109</td>\n      <td>-3990.994654</td>\n      <td>-3990.994654</td>\n      <td>-1994.178373</td>\n      <td>-1997.184706</td>\n      <td>-inf</td>\n      <td>3.446251</td>\n      <td>-15.861515</td>\n      <td>-3.864497</td>\n      <td>-5.068360</td>\n      <td>-1.296757</td>\n      <td>3.456910</td>\n    </tr>\n    <tr>\n      <th>211388205</th>\n      <td>-2856.810200</td>\n      <td>-5711.095914</td>\n      <td>-inf</td>\n      <td>-18.093309</td>\n      <td>-2872.379023</td>\n      <td>-6.332658</td>\n      <td>-21.727638</td>\n      <td>-2876.013352</td>\n      <td>-7.604673</td>\n      <td>-4.381625</td>\n      <td>-4.216264</td>\n      <td>-1381.397292</td>\n      <td>-3.035710</td>\n      <td>10.096155</td>\n      <td>-1987.903845</td>\n      <td>-1987.903845</td>\n      <td>-1987.903845</td>\n      <td>-1987.903845</td>\n      <td>5.048078</td>\n      <td>-1988.132266</td>\n      <td>-3993.215462</td>\n      <td>-3993.215462</td>\n      <td>-1990.677481</td>\n      <td>-1997.375747</td>\n      <td>-inf</td>\n      <td>3.634616</td>\n      <td>-15.776424</td>\n      <td>-3.845077</td>\n      <td>-5.005482</td>\n      <td>-1.286094</td>\n      <td>3.643469</td>\n    </tr>\n    <tr>\n      <th>806388401</th>\n      <td>-2855.874866</td>\n      <td>-5710.160580</td>\n      <td>-inf</td>\n      <td>-9.085232</td>\n      <td>-2863.370946</td>\n      <td>-3.179831</td>\n      <td>-10.734064</td>\n      <td>-2865.019778</td>\n      <td>-3.756922</td>\n      <td>-1.968599</td>\n      <td>6.192499</td>\n      <td>-1378.480723</td>\n      <td>4.458599</td>\n      <td>12.609633</td>\n      <td>-1984.209027</td>\n      <td>-1983.750027</td>\n      <td>-1984.124827</td>\n      <td>-1984.171027</td>\n      <td>6.304817</td>\n      <td>-1985.442854</td>\n      <td>-3989.293913</td>\n      <td>-3989.293913</td>\n      <td>-3990.843560</td>\n      <td>-3993.682148</td>\n      <td>-inf</td>\n      <td>4.539468</td>\n      <td>-19.143696</td>\n      <td>-19.495908</td>\n      <td>-16.361074</td>\n      <td>-5.853917</td>\n      <td>5.193789</td>\n    </tr>\n    <tr>\n      <th>806388405</th>\n      <td>-2858.281791</td>\n      <td>-5712.567505</td>\n      <td>-inf</td>\n      <td>-10.451460</td>\n      <td>-2864.737174</td>\n      <td>-3.658011</td>\n      <td>-11.684013</td>\n      <td>-2865.969727</td>\n      <td>-4.089405</td>\n      <td>-2.273383</td>\n      <td>5.998749</td>\n      <td>-1378.519473</td>\n      <td>4.319099</td>\n      <td>12.638426</td>\n      <td>-1984.311174</td>\n      <td>-1983.852174</td>\n      <td>-1984.226974</td>\n      <td>-1984.273174</td>\n      <td>6.319213</td>\n      <td>-1985.451447</td>\n      <td>-3990.724818</td>\n      <td>-3990.724818</td>\n      <td>-3987.215444</td>\n      <td>-3994.211225</td>\n      <td>-inf</td>\n      <td>4.549833</td>\n      <td>-18.886576</td>\n      <td>-19.495133</td>\n      <td>-16.300395</td>\n      <td>-5.828540</td>\n      <td>5.134877</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(nu[0])#, ns[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# next: add error terms to alternatives and nodes - can be done with this right here by iterating over nests and\n",
    "# adding at each level.\n",
    "# will probably want to vectorise, but that's for later.\n",
    "# add_random returns a random number per row - this seems like the right thing to use while iterating over nest nodes\n",
    "# and leafs (which gives us single columns per alternative)\n",
    "# for destination choice, we might need to rethink this pattern though, but we'll cross that bridge when we come to it\n",
    "\n",
    "def inverse_ev1_cdf(x, location=0.0, scale=1.0):\n",
    "    #quantile function of EV1\n",
    "    # let's follow https://en.wikipedia.org/wiki/Gumbel_distribution where the scale is proportional to variance (not variance^{-1})\n",
    "    # this means nested scales are between 0 and 1\n",
    "    # x can be number or np array or pd df for vecops\n",
    "    return location - scale * np.log(-np.log(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "utils_df = nu[0]\n",
    "nest_spec = ns[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# fake random channel for prototyping as per Asim tests\n",
    "from activitysim.core.random import Random\n",
    "rng = Random()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "nest_utils_for_choice = utils_df.copy()  # we'll add random parts to this such that we can recursively choose from\n",
    "# the top level\n",
    "for n in logit.each_nest(nest_spec):\n",
    "    if n.level == 1:\n",
    "        assert n.name == \"root\"  # TODO get this from where ever const is defined in code\n",
    "        continue\n",
    "    #n.print()\n",
    "    #print(nest_utils_for_choice.loc[:,n.name])\n",
    "    # TODO: check parent nest level scale is what we want this is right\n",
    "    rands = inverse_ev1_cdf(rng.random_for_df(nest_utils_for_choice, n=1), scale=n.parent_nest_scale)\n",
    "    #print(rands)\n",
    "    # this will be cleaner wtith xarrays\n",
    "    nest_utils_for_choice.loc[:,n.name] += rands[:,0]\n",
    "    #print(nest_utils_for_choice.loc[:,n.name])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "# alts = [\"DRIVEALONEFREE\", \"DRIVEALONEPAY\"]\n",
    "# #print(nest_utils_for_choice[alts])\n",
    "# t_ = nest_utils_for_choice[alts].idxmax(1)\n",
    "# t_.apply(is_alternative)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nesting depth is 4\n"
     ]
    }
   ],
   "source": [
    "all_alternatives = list(map(lambda x: x.name, filter(lambda x: x.is_leaf, logit.each_nest(nest_spec))))\n",
    "def is_alternative(name):\n",
    "    return name in all_alternatives\n",
    "\n",
    "def group_nests_by_level(nest_spec):\n",
    "    # group nests by level:\n",
    "    depth = np.max([x.level for x in logit.each_nest(nest_spec)])\n",
    "    print(f\"Nesting depth is {depth}\")\n",
    "    nest_levels = {x: [] for x in range(1, depth+1)}\n",
    "    for n in logit.each_nest(nest_spec):\n",
    "        nest_levels[n.level].append(n.name)\n",
    "    assert len(nest_levels[1]) == 1\n",
    "    assert nest_levels[1][0] == 'root'\n",
    "    return nest_levels\n",
    "\n",
    "nest_utils_for_choice[\"choice\"] = None\n",
    "\n",
    "for level, alts in group_nests_by_level(nest_spec).items():\n",
    "    if level == 1:\n",
    "        continue\n",
    "    no_choices_made_yet = nest_utils_for_choice[\"choice\"].isnull()\n",
    "    choice_this_level = nest_utils_for_choice.loc[no_choices_made_yet][alts].idxmax(1)\n",
    "    nest_utils_for_choice.loc[no_choices_made_yet, \"choice\"] = \\\n",
    "        np.where(choice_this_level.apply(is_alternative), choice_this_level, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "           DRIVEALONEFREE  DRIVEALONEPAY  DRIVEALONE  SHARED2FREE  \\\ntrip_id                                                             \n137248721       -1.116115   -2855.401829   -0.085418    -0.101729   \n137248725       -0.865187   -2855.150902    0.350254     0.148855   \n211388201    -2855.281895   -5709.567609        -inf   -17.128230   \n211388205    -2856.635577   -5710.921291        -inf   -17.918686   \n806388401    -2855.821604   -5710.107318        -inf    -9.031970   \n806388405    -2857.992149   -5712.277863        -inf   -10.161818   \n\n            SHARED2PAY  SHAREDRIDE2  SHARED3FREE   SHARED3PAY  SHAREDRIDE3  \\\ntrip_id                                                                      \n137248721 -2854.387444     0.269616 -2855.394889 -5709.680604         -inf   \n137248725 -2854.136859     0.705169 -2855.144442 -5709.430157         -inf   \n211388201 -2871.413945    -5.588125   -20.987850 -2875.273564    -6.938992   \n211388205 -2872.204400    -5.973433   -21.553014 -2875.838729    -7.245448   \n806388401 -2863.317684    -3.070264   -10.680802 -2864.966516    -3.647355   \n806388405 -2864.447532    -3.062176   -11.394371 -2865.680085    -3.493570   \n\n               AUTO       WALK         BIKE  NONMOTORIZED     WALK_LOC  \\\ntrip_id                                                                  \n137248721  0.822679  16.250835 -1367.832304     11.946618 -1970.527596   \n137248725  1.416687  16.732000 -1367.382139     12.573430 -1970.304027   \n211388201 -3.529757  -3.726114 -1380.907142     -2.354947     9.913300   \n211388205 -3.882701  -3.857039 -1381.038067     -2.536786    10.345617   \n806388401 -1.816422   6.302066 -1378.371156      4.610776    12.685721   \n806388405 -1.445835   6.594584 -1377.923639      5.146648    13.052200   \n\n              WALK_LRF     WALK_EXP     WALK_HVY     WALK_COM  WALKACCESS  \\\ntrip_id                                                                     \n137248721 -3968.527596 -3968.527596 -3968.527596 -3968.527596        -inf   \n137248725 -3968.304027 -3968.304027 -3968.304027 -3968.304027        -inf   \n211388201 -1987.688271 -1987.688271 -1987.688271 -1987.688271    5.276609   \n211388205 -1987.654383 -1987.654383 -1987.654383 -1987.654383    5.407303   \n806388401 -1984.132938 -1983.673938 -1984.048738 -1984.094938    6.414384   \n806388405 -1983.897400 -1983.438400 -1983.813200 -1983.859400    6.915048   \n\n             DRIVE_LOC    DRIVE_LRF    DRIVE_EXP    DRIVE_HVY    DRIVE_COM  \\\ntrip_id                                                                      \n137248721 -1970.647702 -3973.145591 -3973.145591 -3974.414085 -3975.433221   \n137248725 -1970.656867 -3975.391993 -3975.391993 -3971.028330 -3977.511255   \n211388201 -1988.046728 -3990.654273 -3990.654273 -1993.837992 -1996.844325   \n211388205 -1987.882804 -3992.966000 -3992.966000 -1990.428019 -1997.126285   \n806388401 -1985.366765 -3989.217824 -3989.217824 -3990.767471 -3993.606059   \n806388405 -1985.037673 -3990.311044 -3990.311044 -3986.801670 -3993.797451   \n\n           DRIVEACCESS   TRANSIT       TAXI  TNC_SINGLE  TNC_SHARED  RIDEHAIL  \\\ntrip_id                                                                         \n137248721         -inf      -inf -24.319775  -24.959142  -24.065572 -7.937642   \n137248725         -inf      -inf -23.947836  -24.710809  -23.747349 -7.313866   \n211388201         -inf  4.127014 -15.616441   -3.619423   -4.823285 -0.615994   \n211388205         -inf  4.133540 -15.596812   -3.665464   -4.825869 -0.787171   \n806388401         -inf  4.691645 -19.088912  -19.441124  -16.306290 -5.701741   \n806388405         -inf  5.377382 -18.588659  -19.197216  -16.002477 -5.000992   \n\n                root    choice  \ntrip_id                         \n137248721  11.435801      WALK  \n137248725  11.480441      WALK  \n211388201   3.456910  WALK_LOC  \n211388205   3.643469  WALK_LOC  \n806388401   5.193789  WALK_LOC  \n806388405   5.134877  WALK_LOC  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DRIVEALONEFREE</th>\n      <th>DRIVEALONEPAY</th>\n      <th>DRIVEALONE</th>\n      <th>SHARED2FREE</th>\n      <th>SHARED2PAY</th>\n      <th>SHAREDRIDE2</th>\n      <th>SHARED3FREE</th>\n      <th>SHARED3PAY</th>\n      <th>SHAREDRIDE3</th>\n      <th>AUTO</th>\n      <th>WALK</th>\n      <th>BIKE</th>\n      <th>NONMOTORIZED</th>\n      <th>WALK_LOC</th>\n      <th>WALK_LRF</th>\n      <th>WALK_EXP</th>\n      <th>WALK_HVY</th>\n      <th>WALK_COM</th>\n      <th>WALKACCESS</th>\n      <th>DRIVE_LOC</th>\n      <th>DRIVE_LRF</th>\n      <th>DRIVE_EXP</th>\n      <th>DRIVE_HVY</th>\n      <th>DRIVE_COM</th>\n      <th>DRIVEACCESS</th>\n      <th>TRANSIT</th>\n      <th>TAXI</th>\n      <th>TNC_SINGLE</th>\n      <th>TNC_SHARED</th>\n      <th>RIDEHAIL</th>\n      <th>root</th>\n      <th>choice</th>\n    </tr>\n    <tr>\n      <th>trip_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>137248721</th>\n      <td>-1.116115</td>\n      <td>-2855.401829</td>\n      <td>-0.085418</td>\n      <td>-0.101729</td>\n      <td>-2854.387444</td>\n      <td>0.269616</td>\n      <td>-2855.394889</td>\n      <td>-5709.680604</td>\n      <td>-inf</td>\n      <td>0.822679</td>\n      <td>16.250835</td>\n      <td>-1367.832304</td>\n      <td>11.946618</td>\n      <td>-1970.527596</td>\n      <td>-3968.527596</td>\n      <td>-3968.527596</td>\n      <td>-3968.527596</td>\n      <td>-3968.527596</td>\n      <td>-inf</td>\n      <td>-1970.647702</td>\n      <td>-3973.145591</td>\n      <td>-3973.145591</td>\n      <td>-3974.414085</td>\n      <td>-3975.433221</td>\n      <td>-inf</td>\n      <td>-inf</td>\n      <td>-24.319775</td>\n      <td>-24.959142</td>\n      <td>-24.065572</td>\n      <td>-7.937642</td>\n      <td>11.435801</td>\n      <td>WALK</td>\n    </tr>\n    <tr>\n      <th>137248725</th>\n      <td>-0.865187</td>\n      <td>-2855.150902</td>\n      <td>0.350254</td>\n      <td>0.148855</td>\n      <td>-2854.136859</td>\n      <td>0.705169</td>\n      <td>-2855.144442</td>\n      <td>-5709.430157</td>\n      <td>-inf</td>\n      <td>1.416687</td>\n      <td>16.732000</td>\n      <td>-1367.382139</td>\n      <td>12.573430</td>\n      <td>-1970.304027</td>\n      <td>-3968.304027</td>\n      <td>-3968.304027</td>\n      <td>-3968.304027</td>\n      <td>-3968.304027</td>\n      <td>-inf</td>\n      <td>-1970.656867</td>\n      <td>-3975.391993</td>\n      <td>-3975.391993</td>\n      <td>-3971.028330</td>\n      <td>-3977.511255</td>\n      <td>-inf</td>\n      <td>-inf</td>\n      <td>-23.947836</td>\n      <td>-24.710809</td>\n      <td>-23.747349</td>\n      <td>-7.313866</td>\n      <td>11.480441</td>\n      <td>WALK</td>\n    </tr>\n    <tr>\n      <th>211388201</th>\n      <td>-2855.281895</td>\n      <td>-5709.567609</td>\n      <td>-inf</td>\n      <td>-17.128230</td>\n      <td>-2871.413945</td>\n      <td>-5.588125</td>\n      <td>-20.987850</td>\n      <td>-2875.273564</td>\n      <td>-6.938992</td>\n      <td>-3.529757</td>\n      <td>-3.726114</td>\n      <td>-1380.907142</td>\n      <td>-2.354947</td>\n      <td>9.913300</td>\n      <td>-1987.688271</td>\n      <td>-1987.688271</td>\n      <td>-1987.688271</td>\n      <td>-1987.688271</td>\n      <td>5.276609</td>\n      <td>-1988.046728</td>\n      <td>-3990.654273</td>\n      <td>-3990.654273</td>\n      <td>-1993.837992</td>\n      <td>-1996.844325</td>\n      <td>-inf</td>\n      <td>4.127014</td>\n      <td>-15.616441</td>\n      <td>-3.619423</td>\n      <td>-4.823285</td>\n      <td>-0.615994</td>\n      <td>3.456910</td>\n      <td>WALK_LOC</td>\n    </tr>\n    <tr>\n      <th>211388205</th>\n      <td>-2856.635577</td>\n      <td>-5710.921291</td>\n      <td>-inf</td>\n      <td>-17.918686</td>\n      <td>-2872.204400</td>\n      <td>-5.973433</td>\n      <td>-21.553014</td>\n      <td>-2875.838729</td>\n      <td>-7.245448</td>\n      <td>-3.882701</td>\n      <td>-3.857039</td>\n      <td>-1381.038067</td>\n      <td>-2.536786</td>\n      <td>10.345617</td>\n      <td>-1987.654383</td>\n      <td>-1987.654383</td>\n      <td>-1987.654383</td>\n      <td>-1987.654383</td>\n      <td>5.407303</td>\n      <td>-1987.882804</td>\n      <td>-3992.966000</td>\n      <td>-3992.966000</td>\n      <td>-1990.428019</td>\n      <td>-1997.126285</td>\n      <td>-inf</td>\n      <td>4.133540</td>\n      <td>-15.596812</td>\n      <td>-3.665464</td>\n      <td>-4.825869</td>\n      <td>-0.787171</td>\n      <td>3.643469</td>\n      <td>WALK_LOC</td>\n    </tr>\n    <tr>\n      <th>806388401</th>\n      <td>-2855.821604</td>\n      <td>-5710.107318</td>\n      <td>-inf</td>\n      <td>-9.031970</td>\n      <td>-2863.317684</td>\n      <td>-3.070264</td>\n      <td>-10.680802</td>\n      <td>-2864.966516</td>\n      <td>-3.647355</td>\n      <td>-1.816422</td>\n      <td>6.302066</td>\n      <td>-1378.371156</td>\n      <td>4.610776</td>\n      <td>12.685721</td>\n      <td>-1984.132938</td>\n      <td>-1983.673938</td>\n      <td>-1984.048738</td>\n      <td>-1984.094938</td>\n      <td>6.414384</td>\n      <td>-1985.366765</td>\n      <td>-3989.217824</td>\n      <td>-3989.217824</td>\n      <td>-3990.767471</td>\n      <td>-3993.606059</td>\n      <td>-inf</td>\n      <td>4.691645</td>\n      <td>-19.088912</td>\n      <td>-19.441124</td>\n      <td>-16.306290</td>\n      <td>-5.701741</td>\n      <td>5.193789</td>\n      <td>WALK_LOC</td>\n    </tr>\n    <tr>\n      <th>806388405</th>\n      <td>-2857.992149</td>\n      <td>-5712.277863</td>\n      <td>-inf</td>\n      <td>-10.161818</td>\n      <td>-2864.447532</td>\n      <td>-3.062176</td>\n      <td>-11.394371</td>\n      <td>-2865.680085</td>\n      <td>-3.493570</td>\n      <td>-1.445835</td>\n      <td>6.594584</td>\n      <td>-1377.923639</td>\n      <td>5.146648</td>\n      <td>13.052200</td>\n      <td>-1983.897400</td>\n      <td>-1983.438400</td>\n      <td>-1983.813200</td>\n      <td>-1983.859400</td>\n      <td>6.915048</td>\n      <td>-1985.037673</td>\n      <td>-3990.311044</td>\n      <td>-3990.311044</td>\n      <td>-3986.801670</td>\n      <td>-3993.797451</td>\n      <td>-inf</td>\n      <td>5.377382</td>\n      <td>-18.588659</td>\n      <td>-19.197216</td>\n      <td>-16.002477</td>\n      <td>-5.000992</td>\n      <td>5.134877</td>\n      <td>WALK_LOC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_utils_for_choice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OLD\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2f080150-c15a-4059-8a26-42a8c0072606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T23:16:40.014024Z",
     "iopub.status.busy": "2021-08-31T23:16:40.013770Z",
     "iopub.status.idle": "2021-08-31T23:16:40.236326Z",
     "shell.execute_reply": "2021-08-31T23:16:40.235553Z",
     "shell.execute_reply.started": "2021-08-31T23:16:40.013973Z"
    },
    "tags": []
   },
   "source": [
    "### make choice at each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2ed71b54-67e4-4087-957a-75f4fa184144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:11:43.778081Z",
     "iopub.status.busy": "2021-09-01T01:11:43.777757Z",
     "iopub.status.idle": "2021-09-01T01:11:43.975332Z",
     "shell.execute_reply": "2021-09-01T01:11:43.974588Z",
     "shell.execute_reply.started": "2021-09-01T01:11:43.778055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_alternatives(nests, name):\n",
    "    alts = list(filter(lambda x: x.name == name, nests))\n",
    "    assert len(alts) == 1, f\"{len(alts)} not one\"\n",
    "    alts = alts[0].alternatives\n",
    "    return alts\n",
    "\n",
    "def recursive_choice(row, columns, nest_levels, nests):\n",
    "    choices = row[columns].idxmax() #axis=1).values[0]\n",
    "    next_level_columns = get_alternatives(nests, choices)\n",
    "    #print(f\"{choices} leads to columns {next_level_columns}\")\n",
    "    if next_level_columns is None:\n",
    "        return choices    \n",
    "    new_choice = recursive_choice(row, next_level_columns, nest_levels, nests)\n",
    "    return new_choice\n",
    "\n",
    "lower_bound = np.finfo(np.float64).eps  # chance is very small but let's make it zero. could also check and replace if it ever happened\n",
    "\n",
    "def make_choice(utils_df, nests, nest_levels, seed=None):\n",
    "    rng = default_rng(seed=seed)\n",
    "    rands = rng.uniform(low=lower_bound, high=1.0, size=utils_df.shape[1])\n",
    "    probs_arr = utils_df - np.log(-np.log(rands))\n",
    "    choices = probs_arr.apply(lambda x: recursive_choice(x, nest_levels[1], nest_levels, nests), axis=1)\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#rands = pipeline.get_rn_generator().random_for_df(utils_df, n=utils_df.shape[1])\n",
    "seed = 9326543345\n",
    "make_choice(utils_df, nests_, nest_levels, seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "30424562-2627-446b-abd5-7c763c52060e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:11:49.444289Z",
     "iopub.status.busy": "2021-09-01T01:11:49.444002Z",
     "iopub.status.idle": "2021-09-01T01:11:49.664214Z",
     "shell.execute_reply": "2021-09-01T01:11:49.663088Z",
     "shell.execute_reply.started": "2021-09-01T01:11:49.444266Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# group nests by level:\n",
    "depth = np.max([x.level for x in nests_])\n",
    "print(depth)\n",
    "nest_levels = {x: [] for x in range(1, depth+1)}\n",
    "for n in nests_:\n",
    "    nest_levels[n.level].append(n.name)\n",
    "assert len(nest_levels[1]) == 1\n",
    "assert nest_levels[1][0] == 'root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "806ce752-0927-4d5b-a6cc-68d6c9b8a05e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T04:55:59.542669Z",
     "iopub.status.busy": "2021-09-01T04:55:59.542360Z",
     "iopub.status.idle": "2021-09-01T04:55:59.771722Z",
     "shell.execute_reply": "2021-09-01T04:55:59.770801Z",
     "shell.execute_reply.started": "2021-09-01T04:55:59.542615Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_simulate_probabilities(trips_segment, spec, nest_spec, locals_d, estimator, tr_label, log_alt_losers, trace_column_names):\n",
    "    trace_label = tracing.extend_trace_label(tr_label, 'eval_nl')\n",
    "    logit.validate_nest_spec(nest_spec, trace_label)\n",
    "    raw_utilities = simulate.eval_utilities(spec, trips_segment, locals_d,\n",
    "                                   log_alt_losers=log_alt_losers,\n",
    "                                   trace_label=trace_label, have_trace_targets=False,\n",
    "                                   estimator=estimator, trace_column_names=trace_column_names)\n",
    "    nested_exp_utilities = simulate.compute_nested_exp_utilities(raw_utilities, nest_spec)\n",
    "    nested_probabilities = \\\n",
    "        simulate.compute_nested_probabilities(nested_exp_utilities, nest_spec, trace_label=trace_label)\n",
    "    # global (flattened) leaf probabilities based on relative nest coefficients (in spec order)\n",
    "    base_probabilities = simulate.compute_base_probabilities(nested_probabilities, nest_spec, spec)    \n",
    "    return base_probabilities\n",
    "#simple_simulate_probabilities(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "054fd9b1-72fc-49cc-a790-48ef75bcbaed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T04:55:08.260140Z",
     "iopub.status.busy": "2021-09-01T04:55:08.259914Z",
     "iopub.status.idle": "2021-09-01T04:55:09.140095Z",
     "shell.execute_reply": "2021-09-01T04:55:09.139119Z",
     "shell.execute_reply.started": "2021-09-01T04:55:08.260116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_id\n",
       "86627409      WALK_LRF\n",
       "86627413      WALK_LRF\n",
       "86673657      WALK_LOC\n",
       "86673658          WALK\n",
       "86673659          WALK\n",
       "                ...   \n",
       "2464446025        WALK\n",
       "2464446029        WALK\n",
       "2464449633        WALK\n",
       "2464449634        WALK\n",
       "2464449637        WALK\n",
       "Length: 168, dtype: object"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_simulate_rum(trips_segment, spec, nest_spec, locals_d, estimator, tr_label, log_alt_losers, trace_column_names, custom_chooser=None, seed=None):\n",
    "    trace_label = tracing.extend_trace_label(tr_label, 'eval_nl')\n",
    "    logit.validate_nest_spec(nest_spec, trace_label)\n",
    "    raw_utilities = simulate.eval_utilities(spec, trips_segment, locals_d,\n",
    "                                   log_alt_losers=log_alt_losers,\n",
    "                                   trace_label=trace_label, have_trace_targets=False,\n",
    "                                   estimator=estimator, trace_column_names=trace_column_names)\n",
    "\n",
    "    utils_df = compute_nested_utilities(raw_utilities, nest_spec)\n",
    "\n",
    "    nests_ = list(logit.each_nest(nest_spec))\n",
    "    # group nests by level:\n",
    "    depth = np.max([x.level for x in nests_])\n",
    "    nest_levels = {x: [] for x in range(1, depth+1)}\n",
    "    for n in nests_:\n",
    "        nest_levels[n.level].append(n.name)\n",
    "    assert len(nest_levels[1]) == 1\n",
    "    assert nest_levels[1][0] == 'root'\n",
    "    # make choices\n",
    "    choices = make_choice(utils_df, nests_, nest_levels, seed)\n",
    "\n",
    "    return choices\n",
    "\n",
    "simple_simulate_rum(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=1233974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f3c5c1ba-e9c3-4511-98bf-9ac98c987da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:39:52.539983Z",
     "iopub.status.busy": "2021-09-01T02:39:52.539668Z",
     "iopub.status.idle": "2021-09-01T02:39:52.796170Z",
     "shell.execute_reply": "2021-09-01T02:39:52.795498Z",
     "shell.execute_reply.started": "2021-09-01T02:39:52.539944Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stuff(trips_merged, model_settings, constants, skims, model_spec, nest_spec, estimator, logsum_column_name, mode_column_name, \n",
    "          trace_label=None, log_alt_losers=None, trace_column_names=None, seed=None):\n",
    "    choices_list = []\n",
    "    for primary_purpose, trips_segment in trips_merged.groupby('primary_purpose'):\n",
    "        #print(\"trip_mode_choice tour_type '%s' (%s trips)\" %\n",
    "        #            (primary_purpose, len(trips_segment.index), ))\n",
    "        # name index so tracing knows how to slice\n",
    "        assert trips_segment.index.name == 'trip_id'\n",
    "\n",
    "        coefficients = simulate.get_segment_coefficients(model_settings, primary_purpose)\n",
    "\n",
    "        locals_dict = {}\n",
    "        locals_dict.update(constants)\n",
    "        locals_dict.update(coefficients)\n",
    "\n",
    "        segment_trace_label = tracing.extend_trace_label(trace_label, primary_purpose)\n",
    "\n",
    "        expressions.annotate_preprocessors(\n",
    "            trips_segment, locals_dict, skims,\n",
    "            model_settings, segment_trace_label)\n",
    "\n",
    "        locals_dict.update(skims)\n",
    "\n",
    "        spec=simulate.eval_coefficients(model_spec, coefficients, estimator)\n",
    "        nest_spec = simulate.eval_nest_coefficients(nest_spec, coefficients, segment_trace_label)\n",
    "        choices = simple_simulate_rum(trips_segment, spec, nest_spec, locals_dict, estimator, \n",
    "                                      segment_trace_label, log_alt_losers=log_alt_losers, \n",
    "                                      trace_column_names=trace_column_names, seed=seed)\n",
    "\n",
    "        # for consistency, always return dataframe, whether or not logsums were requested\n",
    "        if isinstance(choices, pd.Series):\n",
    "            choices = choices.to_frame('choice')\n",
    "        choices.rename(columns={'logsum': logsum_column_name,\n",
    "                                'choice': mode_column_name},\n",
    "                       inplace=True)\n",
    "        choices_list.append(choices)\n",
    "\n",
    "    choices_df = pd.concat(choices_list)\n",
    "    return choices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "74eeedd3-4ade-4729-8170-79fa9dcf11f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T04:58:52.825042Z",
     "iopub.status.busy": "2021-09-01T04:58:52.824768Z",
     "iopub.status.idle": "2021-09-01T04:58:53.042884Z",
     "shell.execute_reply": "2021-09-01T04:58:53.042061Z",
     "shell.execute_reply.started": "2021-09-01T04:58:52.825004Z"
    }
   },
   "outputs": [],
   "source": [
    "## caculate probabilities with Asim methodology, should be correct\n",
    "def gimme_probabilities(trips_merged, model_settings, constants, skims, model_spec, nest_spec, estimator, logsum_column_name, mode_column_name, \n",
    "          trace_label=None, log_alt_losers=None, trace_column_names=None):\n",
    "    full_probs = []  # analytical probs\n",
    "\n",
    "    for primary_purpose, trips_segment in trips_merged.groupby('primary_purpose'):\n",
    "        #print(\"trip_mode_choice tour_type '%s' (%s trips)\" %\n",
    "        #            (primary_purpose, len(trips_segment.index), ))\n",
    "        # name index so tracing knows how to slice\n",
    "        assert trips_segment.index.name == 'trip_id'\n",
    "\n",
    "        coefficients = simulate.get_segment_coefficients(model_settings, primary_purpose)\n",
    "\n",
    "        locals_dict = {}\n",
    "        locals_dict.update(constants)\n",
    "        locals_dict.update(coefficients)\n",
    "\n",
    "        segment_trace_label = tracing.extend_trace_label(trace_label, primary_purpose)\n",
    "\n",
    "        expressions.annotate_preprocessors(\n",
    "            trips_segment, locals_dict, skims,\n",
    "            model_settings, segment_trace_label)\n",
    "\n",
    "        locals_dict.update(skims)\n",
    "\n",
    "        spec=simulate.eval_coefficients(model_spec, coefficients, estimator)\n",
    "        nest_spec = simulate.eval_nest_coefficients(nest_spec, coefficients, segment_trace_label)\n",
    "        #choices = simple_simulate_rum(trips_segment, spec, nest_spec, locals_dict, estimator, \n",
    "        #                              segment_trace_label, log_alt_losers=log_alt_losers, \n",
    "        #                              trace_column_names=trace_column_names, seed=seed)\n",
    "        probs = simple_simulate_probabilities(trips_segment, spec, nest_spec, locals_dict, \n",
    "                                              estimator, segment_trace_label, log_alt_losers, \n",
    "                                              trace_column_names)\n",
    "        full_probs.append(probs)\n",
    "    probs_df = pd.concat(full_probs)\n",
    "    return probs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "295a4fd1-8e85-47e2-af82-9f1beac31d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T04:59:46.126555Z",
     "iopub.status.busy": "2021-09-01T04:59:46.126262Z",
     "iopub.status.idle": "2021-09-01T04:59:52.979908Z",
     "shell.execute_reply": "2021-09-01T04:59:52.979043Z",
     "shell.execute_reply.started": "2021-09-01T04:59:46.126522Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "register joint_tour_participants: no rows with household_id in [982875].\n",
      "estimation bundle trip_mode_choice not in settings file estimation.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 14:59:46.353007 Start\n",
      "2021-09-01 14:59:52.976736 End\n"
     ]
    }
   ],
   "source": [
    "print(f\"{datetime.now()} Start\")\n",
    "pipeline.open_pipeline(resume_after)\n",
    "inject.get_injectable('preload_injectables', None)\n",
    "model_name = \"trip_mode_choice\"\n",
    "pipeline._PIPELINE.rng().begin_step(model_name)\n",
    "\n",
    "step_name = model_name\n",
    "args = {}\n",
    "checkpoint = pipeline.intermediate_checkpoint(model_name)\n",
    "inject.set_step_args(args)\n",
    "\n",
    "trips = inject.get_table('trips')\n",
    "tours_merged = inject.get_table('tours_merged')\n",
    "network_los = inject.get_injectable('network_los')\n",
    "chunk_size = 0\n",
    "\n",
    "trace_label = 'trip_mode_choice'\n",
    "model_settings_file_name = 'trip_mode_choice.yaml'\n",
    "model_settings = config.read_model_settings(model_settings_file_name)\n",
    "\n",
    "logsum_column_name = model_settings.get('MODE_CHOICE_LOGSUM_COLUMN_NAME')\n",
    "mode_column_name = 'trip_mode'\n",
    "trips_df = trips.to_frame()\n",
    "#print(\"Running with %d trips\", trips_df.shape[0])\n",
    "tours_merged = tours_merged.to_frame()\n",
    "tours_merged = tours_merged[model_settings['TOURS_MERGED_CHOOSER_COLUMNS']]\n",
    "# - trips_merged - merge trips and tours_merged\n",
    "trips_merged = pd.merge(\n",
    "    trips_df,\n",
    "    tours_merged,\n",
    "    left_on='tour_id',\n",
    "    right_index=True,\n",
    "    how=\"left\")\n",
    "assert trips_merged.index.equals(trips.index)\n",
    "\n",
    "# setup skim keys\n",
    "assert ('trip_period' not in trips_merged)\n",
    "trips_merged['trip_period'] = network_los.skim_time_period_label(trips_merged.depart)\n",
    "\n",
    "orig_col = 'origin'\n",
    "dest_col = 'destination'\n",
    "\n",
    "constants = {}\n",
    "constants.update(config.get_model_constants(model_settings))\n",
    "constants.update({\n",
    "    'ORIGIN': orig_col,\n",
    "    'DESTINATION': dest_col\n",
    "})\n",
    "\n",
    "skim_dict = network_los.get_default_skim_dict()\n",
    "\n",
    "odt_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=orig_col, dest_key=dest_col,\n",
    "                                           dim3_key='trip_period')\n",
    "dot_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=dest_col, dest_key=orig_col,\n",
    "                                           dim3_key='trip_period')\n",
    "od_skim_wrapper = skim_dict.wrap('origin', 'destination')\n",
    "\n",
    "skims = {\n",
    "    \"odt_skims\": odt_skim_stack_wrapper,\n",
    "    \"dot_skims\": dot_skim_stack_wrapper,\n",
    "    \"od_skims\": od_skim_wrapper,\n",
    "}\n",
    "\n",
    "model_spec = simulate.read_model_spec(file_name=model_settings['SPEC'])\n",
    "nest_spec = config.get_logit_model_settings(model_settings)\n",
    "\n",
    "estimator = estimation.manager.begin_estimation('trip_mode_choice')\n",
    "\n",
    "\n",
    "all_choices = []\n",
    "for i in range(100):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"{datetime.now()} iteration {i}\")\n",
    "    choices_df = stuff(trips_merged, model_settings, constants, skims, model_spec, nest_spec, estimator, logsum_column_name, mode_column_name, \n",
    "              trace_label=trace_label, log_alt_losers=None, trace_column_names=None, seed=None)\n",
    "    all_choices.append(choices_df)\n",
    "all_choices = pd.concat(all_choices, axis=1)\n",
    "\n",
    "probs_nl = gimme_probabilities(trips_merged, model_settings, constants, skims, model_spec, nest_spec,\n",
    "                               estimator, logsum_column_name, mode_column_name,trace_label=trace_label, \n",
    "                               log_alt_losers=None, trace_column_names=None)\n",
    "\n",
    "# update trips table with choices (and potionally logssums)\n",
    "#trips_df = trips.to_frame()\n",
    "#\n",
    "#assign_in_place(trips_df, choices_df)\n",
    "#assert not trips_df[mode_column_name].isnull().any()\n",
    "\n",
    "\n",
    "finalise = True\n",
    "if finalise:\n",
    "    inject.set_step_args(None)\n",
    "    #\n",
    "    pipeline._PIPELINE.rng().end_step(model_name)\n",
    "    pipeline.add_checkpoint(model_name)\n",
    "    if not pipeline.intermediate_checkpoint():\n",
    "        pipeline.add_checkpoint(pipeline.FINAL_CHECKPOINT_NAME)\n",
    "\n",
    "    pipeline.close_pipeline()\n",
    "\n",
    "print(f\"{datetime.now()} End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "dc87e904-16d1-44d4-81b7-cafbe4e223c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:01:40.901982Z",
     "iopub.status.busy": "2021-09-01T05:01:40.901759Z",
     "iopub.status.idle": "2021-09-01T05:01:41.337758Z",
     "shell.execute_reply": "2021-09-01T05:01:41.336757Z",
     "shell.execute_reply.started": "2021-09-01T05:01:40.901946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_choices.merge(choices_df_asim[['trip_mode']].rename(columns={'trip_mode': 'asim'}), left_index=True, right_index=True)\n",
    "val_counts = all_choices.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "val_counts = val_counts / all_choices.shape[1]\n",
    "#val_counts = val_counts.merge(choices_df_asim[['trip_mode']].rename(columns={'trip_mode': 'asim'}), left_index=True, right_index=True)\n",
    "#val_counts['prob_of_asim_choice'] = val_counts.apply(lambda x: x[x.asim], axis=1)  # this is what our simulation says w.r.t. to asim choice\n",
    "# for 100% and many samples should mostly agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "09bf151c-a39a-4823-acfd-9c8ae747c338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:01:46.119117Z",
     "iopub.status.busy": "2021-09-01T05:01:46.118849Z",
     "iopub.status.idle": "2021-09-01T05:01:46.354114Z",
     "shell.execute_reply": "2021-09-01T05:01:46.353248Z",
     "shell.execute_reply.started": "2021-09-01T05:01:46.119092Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#val_counts['prob_of_asim_choice'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "f3b6ade9-d875-4104-b438-b53ef42e342c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T05:10:08.653227Z",
     "iopub.status.busy": "2021-09-01T05:10:08.652978Z",
     "iopub.status.idle": "2021-09-01T05:10:08.915620Z",
     "shell.execute_reply": "2021-09-01T05:10:08.914513Z",
     "shell.execute_reply.started": "2021-09-01T05:10:08.653189Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIKE</th>\n",
       "      <th>DRIVEALONEFREE</th>\n",
       "      <th>DRIVEALONEPAY</th>\n",
       "      <th>DRIVE_COM</th>\n",
       "      <th>DRIVE_EXP</th>\n",
       "      <th>DRIVE_HVY</th>\n",
       "      <th>DRIVE_LOC</th>\n",
       "      <th>DRIVE_LRF</th>\n",
       "      <th>SHARED2FREE</th>\n",
       "      <th>SHARED2PAY</th>\n",
       "      <th>SHARED3FREE</th>\n",
       "      <th>SHARED3PAY</th>\n",
       "      <th>TAXI</th>\n",
       "      <th>TNC_SHARED</th>\n",
       "      <th>TNC_SINGLE</th>\n",
       "      <th>WALK</th>\n",
       "      <th>WALK_COM</th>\n",
       "      <th>WALK_EXP</th>\n",
       "      <th>WALK_HVY</th>\n",
       "      <th>WALK_LOC</th>\n",
       "      <th>WALK_LRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>analytical</th>\n",
       "      <td>3.152</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1.334</td>\n",
       "      <td>63.708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>18.355</td>\n",
       "      <td>10.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>3.243</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.259</td>\n",
       "      <td>1.434</td>\n",
       "      <td>63.243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394</td>\n",
       "      <td>18.639</td>\n",
       "      <td>10.807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BIKE  DRIVEALONEFREE  DRIVEALONEPAY  DRIVE_COM  DRIVE_EXP  \\\n",
       "analytical  3.152           0.852            0.0        0.0        0.0   \n",
       "experiment  3.243           0.880            0.0        0.0        0.0   \n",
       "\n",
       "            DRIVE_HVY  DRIVE_LOC  DRIVE_LRF  SHARED2FREE  SHARED2PAY  \\\n",
       "analytical        0.0        0.0        0.0        0.685         0.0   \n",
       "experiment        0.0        0.0        0.0        0.772         0.0   \n",
       "\n",
       "            SHARED3FREE  SHARED3PAY   TAXI  TNC_SHARED  TNC_SINGLE    WALK  \\\n",
       "analytical        0.129         0.0  0.182       0.260       1.334  63.708   \n",
       "experiment        0.156         0.0  0.174       0.259       1.434  63.243   \n",
       "\n",
       "            WALK_COM  WALK_EXP  WALK_HVY  WALK_LOC  WALK_LRF  \n",
       "analytical       0.0       0.0     0.455    18.355    10.887  \n",
       "experiment       0.0       0.0     0.394    18.639    10.807  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode_share_analytical = (probs_nl.sum(axis=0) / probs_nl.shape[0]).to_frame('analytical')\n",
    "assert np.allclose(mode_share_analytical.sum(), 1)\n",
    "mode_share_rum = (val_counts.sum(axis=0) / val_counts.shape[0]).to_frame('experiment')\n",
    "assert np.allclose(mode_share_rum.sum(), 1)\n",
    "full_share = mode_share_analytical.join(mode_share_rum, how='outer').fillna(0)\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    display((100.0 * full_share).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48a56e-d613-4dfd-bef6-62bee524f12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50914e1d-750d-440c-9617-f96bd2a46c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d70e0e-520e-49a6-8024-ae31345f6ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e8ef02-1d57-4b21-8aef-25a6e1095c02",
   "metadata": {},
   "source": [
    "### try zenith normalisation of simple_simulate_rum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "db235e90-d2e5-4e90-b41c-6d90a670e41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:37:24.045881Z",
     "iopub.status.busy": "2021-09-01T11:37:24.045637Z",
     "iopub.status.idle": "2021-09-01T11:37:24.276488Z",
     "shell.execute_reply": "2021-09-01T11:37:24.274898Z",
     "shell.execute_reply.started": "2021-09-01T11:37:24.045844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: work out if our formulation and formulation belowi s equivalent.\n",
    "def compute_nested_utilities_zenith(raw_utilities, nest_spec):\n",
    "    nested_utilities = pd.DataFrame(index=raw_utilities.index)\n",
    "    for nest in logit.each_nest(nest_spec, post_order=True):\n",
    "        name = nest.name\n",
    "        if nest.is_leaf:\n",
    "            nested_utilities[name] = \\\n",
    "                raw_utilities[name].astype(float) # / nest.product_of_coefficients  #coefficient\n",
    "        else:\n",
    "            with np.errstate(divide='ignore'):\n",
    "                nested_utilities[name] = \\\n",
    "                    nest.coefficient * np.log(np.exp(nested_utilities[nest.alternatives] / nest.coefficient).sum(axis=1))\n",
    "                \n",
    "    # now go over all leaves and correct for scale\n",
    "    for nest in logit.each_nest(nest_spec, post_order=True):\n",
    "        name = nest.name\n",
    "        if nest.is_leaf:\n",
    "            nested_utilities[name] /= nest.coefficient\n",
    "    \n",
    "    return nested_utilities\n",
    "\n",
    "\n",
    "def simple_simulate_rum_zenith(trips_segment, spec, nest_spec, locals_d, estimator, tr_label, log_alt_losers, trace_column_names, custom_chooser=None, seed=None):\n",
    "    trace_label = tracing.extend_trace_label(tr_label, 'eval_nl')\n",
    "    logit.validate_nest_spec(nest_spec, trace_label)\n",
    "    raw_utilities = simulate.eval_utilities(spec, trips_segment, locals_d,\n",
    "                                   log_alt_losers=log_alt_losers,\n",
    "                                   trace_label=trace_label, have_trace_targets=False,\n",
    "                                   estimator=estimator, trace_column_names=trace_column_names)\n",
    "\n",
    "    utils_df = compute_nested_utilities_zenith(raw_utilities, nest_spec)\n",
    "\n",
    "    nests_ = list(logit.each_nest(nest_spec))\n",
    "    # group nests by level:\n",
    "    depth = np.max([x.level for x in nests_])\n",
    "    nest_levels = {x: [] for x in range(1, depth+1)}\n",
    "    for n in nests_:\n",
    "        nest_levels[n.level].append(n.name)\n",
    "    assert len(nest_levels[1]) == 1\n",
    "    assert nest_levels[1][0] == 'root'\n",
    "    # make choices\n",
    "    choices = make_choice(utils_df, nests_, nest_levels, seed)\n",
    "\n",
    "    return choices\n",
    "\n",
    "#simple_simulate_rum_zenith(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=1233974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "f69bc3dc-84e4-4dd5-9a57-c053cadba4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:37:24.828926Z",
     "iopub.status.busy": "2021-09-01T11:37:24.828707Z",
     "iopub.status.idle": "2021-09-01T11:37:25.046409Z",
     "shell.execute_reply": "2021-09-01T11:37:25.045399Z",
     "shell.execute_reply.started": "2021-09-01T11:37:24.828902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stuff_zenith(trips_merged, model_settings, constants, skims, model_spec, nest_spec, estimator, logsum_column_name, mode_column_name, \n",
    "          trace_label=None, log_alt_losers=None, trace_column_names=None, seed=None):\n",
    "    choices_list = []\n",
    "    for primary_purpose, trips_segment in trips_merged.groupby('primary_purpose'):\n",
    "        #print(\"trip_mode_choice tour_type '%s' (%s trips)\" %\n",
    "        #            (primary_purpose, len(trips_segment.index), ))\n",
    "        # name index so tracing knows how to slice\n",
    "        assert trips_segment.index.name == 'trip_id'\n",
    "\n",
    "        coefficients = simulate.get_segment_coefficients(model_settings, primary_purpose)\n",
    "\n",
    "        locals_dict = {}\n",
    "        locals_dict.update(constants)\n",
    "        locals_dict.update(coefficients)\n",
    "\n",
    "        segment_trace_label = tracing.extend_trace_label(trace_label, primary_purpose)\n",
    "\n",
    "        expressions.annotate_preprocessors(\n",
    "            trips_segment, locals_dict, skims,\n",
    "            model_settings, segment_trace_label)\n",
    "\n",
    "        locals_dict.update(skims)\n",
    "\n",
    "        spec=simulate.eval_coefficients(model_spec, coefficients, estimator)\n",
    "        nest_spec = simulate.eval_nest_coefficients(nest_spec, coefficients, segment_trace_label)\n",
    "        choices = simple_simulate_rum_zenith(trips_segment, spec, nest_spec, locals_dict, estimator, \n",
    "                                      segment_trace_label, log_alt_losers=log_alt_losers, \n",
    "                                      trace_column_names=trace_column_names, seed=seed)\n",
    "\n",
    "        # for consistency, always return dataframe, whether or not logsums were requested\n",
    "        if isinstance(choices, pd.Series):\n",
    "            choices = choices.to_frame('choice')\n",
    "        choices.rename(columns={'logsum': logsum_column_name,\n",
    "                                'choice': mode_column_name},\n",
    "                       inplace=True)\n",
    "        choices_list.append(choices)\n",
    "\n",
    "    choices_df = pd.concat(choices_list)\n",
    "    return choices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "8c4f4fb1-c4fb-4a05-9be4-8b9d7f25d1e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:37:32.250808Z",
     "iopub.status.busy": "2021-09-01T11:37:32.250548Z",
     "iopub.status.idle": "2021-09-01T20:20:35.257463Z",
     "shell.execute_reply": "2021-09-01T20:20:35.255964Z",
     "shell.execute_reply.started": "2021-09-01T11:37:32.250782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "\n",
    "rng_test = default_rng(23423)\n",
    "\n",
    "print(f\"{datetime.now()} Start\")\n",
    "pipeline.open_pipeline(resume_after)\n",
    "inject.get_injectable('preload_injectables', None)\n",
    "model_name = \"trip_mode_choice\"\n",
    "pipeline._PIPELINE.rng().begin_step(model_name)\n",
    "\n",
    "step_name = model_name\n",
    "args = {}\n",
    "checkpoint = pipeline.intermediate_checkpoint(model_name)\n",
    "inject.set_step_args(args)\n",
    "\n",
    "trips = inject.get_table('trips')\n",
    "tours_merged = inject.get_table('tours_merged')\n",
    "network_los = inject.get_injectable('network_los')\n",
    "chunk_size = 0\n",
    "\n",
    "trace_label = 'trip_mode_choice'\n",
    "model_settings_file_name = 'trip_mode_choice.yaml'\n",
    "model_settings = config.read_model_settings(model_settings_file_name)\n",
    "\n",
    "logsum_column_name = model_settings.get('MODE_CHOICE_LOGSUM_COLUMN_NAME')\n",
    "mode_column_name = 'trip_mode'\n",
    "trips_df = trips.to_frame()\n",
    "#print(\"Running with %d trips\", trips_df.shape[0])\n",
    "tours_merged = tours_merged.to_frame()\n",
    "tours_merged = tours_merged[model_settings['TOURS_MERGED_CHOOSER_COLUMNS']]\n",
    "# - trips_merged - merge trips and tours_merged\n",
    "trips_merged = pd.merge(\n",
    "    trips_df,\n",
    "    tours_merged,\n",
    "    left_on='tour_id',\n",
    "    right_index=True,\n",
    "    how=\"left\")\n",
    "assert trips_merged.index.equals(trips.index)\n",
    "\n",
    "# setup skim keys\n",
    "assert ('trip_period' not in trips_merged)\n",
    "trips_merged['trip_period'] = network_los.skim_time_period_label(trips_merged.depart)\n",
    "\n",
    "orig_col = 'origin'\n",
    "dest_col = 'destination'\n",
    "\n",
    "constants = {}\n",
    "constants.update(config.get_model_constants(model_settings))\n",
    "constants.update({\n",
    "    'ORIGIN': orig_col,\n",
    "    'DESTINATION': dest_col\n",
    "})\n",
    "\n",
    "skim_dict = network_los.get_default_skim_dict()\n",
    "odt_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=orig_col, dest_key=dest_col,\n",
    "                                           dim3_key='trip_period')\n",
    "dot_skim_stack_wrapper = skim_dict.wrap_3d(orig_key=dest_col, dest_key=orig_col,\n",
    "                                           dim3_key='trip_period')\n",
    "od_skim_wrapper = skim_dict.wrap('origin', 'destination')\n",
    "skims = {\n",
    "    \"odt_skims\": odt_skim_stack_wrapper,\n",
    "    \"dot_skims\": dot_skim_stack_wrapper,\n",
    "    \"od_skims\": od_skim_wrapper,\n",
    "}\n",
    "model_spec = simulate.read_model_spec(file_name=model_settings['SPEC'])\n",
    "nest_spec = config.get_logit_model_settings(model_settings)\n",
    "estimator = estimation.manager.begin_estimation('trip_mode_choice')\n",
    "\n",
    "all_choices_zenith = []\n",
    "all_choices = []\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    seed = rng_test.integers(0, 100000) #int(9.3 * (i+1)**3)  # why not\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(f\"{datetime.now()} iteration {i}\")\n",
    "    choices_df_zenith = stuff_zenith(trips_merged, model_settings, constants, skims, model_spec, nest_spec, estimator, logsum_column_name, mode_column_name, \n",
    "              trace_label=trace_label, log_alt_losers=None, trace_column_names=None, seed=seed)\n",
    "    all_choices_zenith.append(choices_df_zenith)\n",
    "\n",
    "    choices_df = stuff(trips_merged, model_settings, constants, skims, model_spec, nest_spec, estimator, logsum_column_name, mode_column_name, \n",
    "          trace_label=trace_label, log_alt_losers=None, trace_column_names=None, seed=seed)\n",
    "    all_choices.append(choices_df)\n",
    "    \n",
    "    t_ = choices_df_zenith.merge(choices_df, left_index=True, right_index=True, suffixes=['_zenith', '_asim'])\n",
    "    diffs = t_.loc[t_.trip_mode_zenith != t_.trip_mode_asim]\n",
    "    \n",
    "    #print(f\"seed {seed} leads to {diffs.shape[0]} differences. tripids {diffs.index}\")\n",
    "\n",
    "all_choices_zenith = pd.concat(all_choices_zenith, axis=1)\n",
    "all_choices = pd.concat(all_choices, axis=1)\n",
    "\n",
    "probs_nl = gimme_probabilities(trips_merged, model_settings, constants, skims, model_spec, nest_spec,\n",
    "                               estimator, logsum_column_name, mode_column_name,trace_label=trace_label, \n",
    "                               log_alt_losers=None, trace_column_names=None)\n",
    "\n",
    "finalise = True\n",
    "if finalise:\n",
    "    inject.set_step_args(None)\n",
    "    #\n",
    "    pipeline._PIPELINE.rng().end_step(model_name)\n",
    "    pipeline.add_checkpoint(model_name)\n",
    "    if not pipeline.intermediate_checkpoint():\n",
    "        pipeline.add_checkpoint(pipeline.FINAL_CHECKPOINT_NAME)\n",
    "\n",
    "    pipeline.close_pipeline()\n",
    "\n",
    "print(f\"{datetime.now()} End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "3abd7949-dc9c-469b-845e-26c17741f70e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T20:33:21.533110Z",
     "iopub.status.busy": "2021-09-01T20:33:21.531915Z",
     "iopub.status.idle": "2021-09-01T20:33:21.740946Z",
     "shell.execute_reply": "2021-09-01T20:33:21.739713Z",
     "shell.execute_reply.started": "2021-09-01T20:33:21.533074Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 2038 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Have {all_choices_zenith.shape[1]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "8762bd6d-ac04-458c-869f-be86d8297351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T20:21:27.778803Z",
     "iopub.status.busy": "2021-09-01T20:21:27.778531Z",
     "iopub.status.idle": "2021-09-01T20:21:28.675645Z",
     "shell.execute_reply": "2021-09-01T20:21:28.674734Z",
     "shell.execute_reply.started": "2021-09-01T20:21:27.778754Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_counts_zenith = all_choices_zenith.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "val_counts_zenith = val_counts_zenith / all_choices_zenith.shape[1]\n",
    "\n",
    "val_counts = all_choices.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "val_counts = val_counts / all_choices.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "0f566105-9424-457b-86f5-d60c1d63aac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T20:21:30.954894Z",
     "iopub.status.busy": "2021-09-01T20:21:30.954654Z",
     "iopub.status.idle": "2021-09-01T20:21:31.179689Z",
     "shell.execute_reply": "2021-09-01T20:21:31.178304Z",
     "shell.execute_reply.started": "2021-09-01T20:21:30.954867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIKE</th>\n",
       "      <th>DRIVEALONEFREE</th>\n",
       "      <th>DRIVEALONEPAY</th>\n",
       "      <th>DRIVE_COM</th>\n",
       "      <th>DRIVE_EXP</th>\n",
       "      <th>DRIVE_HVY</th>\n",
       "      <th>DRIVE_LOC</th>\n",
       "      <th>DRIVE_LRF</th>\n",
       "      <th>SHARED2FREE</th>\n",
       "      <th>SHARED2PAY</th>\n",
       "      <th>SHARED3FREE</th>\n",
       "      <th>SHARED3PAY</th>\n",
       "      <th>TAXI</th>\n",
       "      <th>TNC_SHARED</th>\n",
       "      <th>TNC_SINGLE</th>\n",
       "      <th>WALK</th>\n",
       "      <th>WALK_COM</th>\n",
       "      <th>WALK_EXP</th>\n",
       "      <th>WALK_HVY</th>\n",
       "      <th>WALK_LOC</th>\n",
       "      <th>WALK_LRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>analytical</th>\n",
       "      <td>3.152</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1.334</td>\n",
       "      <td>63.708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>18.355</td>\n",
       "      <td>10.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>3.243</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.259</td>\n",
       "      <td>1.434</td>\n",
       "      <td>63.243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394</td>\n",
       "      <td>18.639</td>\n",
       "      <td>10.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_zenith</th>\n",
       "      <td>3.150</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.236</td>\n",
       "      <td>1.285</td>\n",
       "      <td>63.767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>18.824</td>\n",
       "      <td>10.379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BIKE  DRIVEALONEFREE  DRIVEALONEPAY  DRIVE_COM  DRIVE_EXP  \\\n",
       "analytical         3.152           0.852            0.0        0.0        0.0   \n",
       "experiment         3.243           0.880            0.0        0.0        0.0   \n",
       "experiment_zenith  3.150           0.874            0.0        0.0        0.0   \n",
       "\n",
       "                   DRIVE_HVY  DRIVE_LOC  DRIVE_LRF  SHARED2FREE  SHARED2PAY  \\\n",
       "analytical               0.0        0.0        0.0        0.685         0.0   \n",
       "experiment               0.0        0.0        0.0        0.772         0.0   \n",
       "experiment_zenith        0.0        0.0        0.0        0.680         0.0   \n",
       "\n",
       "                   SHARED3FREE  SHARED3PAY   TAXI  TNC_SHARED  TNC_SINGLE  \\\n",
       "analytical               0.129         0.0  0.182       0.260       1.334   \n",
       "experiment               0.156         0.0  0.174       0.259       1.434   \n",
       "experiment_zenith        0.136         0.0  0.154       0.236       1.285   \n",
       "\n",
       "                     WALK  WALK_COM  WALK_EXP  WALK_HVY  WALK_LOC  WALK_LRF  \n",
       "analytical         63.708       0.0       0.0     0.455    18.355    10.887  \n",
       "experiment         63.243       0.0       0.0     0.394    18.639    10.807  \n",
       "experiment_zenith  63.767       0.0       0.0     0.515    18.824    10.379  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode_share_rum_zenith = (val_counts_zenith.sum(axis=0) / val_counts_zenith.shape[0]).to_frame('experiment_zenith')\n",
    "assert np.allclose(mode_share_rum_zenith.sum(), 1)\n",
    "full_share_incl_zenith = full_share.merge(mode_share_rum_zenith, left_index=True, right_index=True, how='outer').fillna(0)\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    display((100.0 * full_share_incl_zenith).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d3081-b45b-4573-9246-e4a9d39591dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612b2f04-45e2-4eb2-b52a-9f753427877f",
   "metadata": {},
   "source": [
    "## investigate diverging seed and look at diff in formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "ac09dc75-a92f-43fb-a0cd-fe7de1f8b66d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:12:02.988141Z",
     "iopub.status.busy": "2021-09-01T11:12:02.987900Z",
     "iopub.status.idle": "2021-09-01T11:12:03.212179Z",
     "shell.execute_reply": "2021-09-01T11:12:03.210993Z",
     "shell.execute_reply.started": "2021-09-01T11:12:02.988102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: work out if our formulation and formulation based on asim probabilities is equivalent\n",
    "def compute_nested_utilities_asim(raw_utilities, nest_spec):\n",
    "    nested_utilities = pd.DataFrame(index=raw_utilities.index)\n",
    "    for nest in logit.each_nest(nest_spec, post_order=True):\n",
    "        name = nest.name\n",
    "        if nest.is_leaf:\n",
    "            nested_utilities[name] = \\\n",
    "                raw_utilities[name].astype(float) / nest.product_of_coefficients\n",
    "        else:\n",
    "            with np.errstate(divide='ignore'):\n",
    "                nested_utilities[name] = \\\n",
    "                    nest.coefficient * np.log(np.exp(nested_utilities[nest.alternatives]).sum(axis=1))\n",
    "    return nested_utilities\n",
    "\n",
    "def compute_nested_utilities_zenith_check(raw_utilities, nest_spec):\n",
    "    nested_utilities = pd.DataFrame(index=raw_utilities.index)\n",
    "    for nest in logit.each_nest(nest_spec, post_order=True):\n",
    "        name = nest.name\n",
    "        if nest.is_leaf:\n",
    "            nested_utilities[name] = \\\n",
    "                raw_utilities[name].astype(float)  # scale correction is below\n",
    "        else:\n",
    "            with np.errstate(divide='ignore'):\n",
    "                nested_utilities[name] = \\\n",
    "                    nest.coefficient * np.log(np.exp(nested_utilities[nest.alternatives] / nest.coefficient).sum(axis=1))\n",
    "                \n",
    "    # now go over all leaves and correct for scale\n",
    "    for nest in logit.each_nest(nest_spec):\n",
    "        name = nest.name\n",
    "        if nest.is_leaf:\n",
    "            nested_utilities[name] /= nest.coefficient\n",
    "    \n",
    "    return nested_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "4b7c6368-21ca-4442-969e-f2f8ff868842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T20:49:56.958862Z",
     "iopub.status.busy": "2021-09-01T20:49:56.958623Z",
     "iopub.status.idle": "2021-09-01T20:49:57.191884Z",
     "shell.execute_reply": "2021-09-01T20:49:57.190975Z",
     "shell.execute_reply.started": "2021-09-01T20:49:56.958827Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_simulate_rum_zenith_check(trips_segment, spec, nest_spec, locals_d, estimator, tr_label, log_alt_losers, trace_column_names, custom_chooser=None, seed=None, use_zenith=True, raw_utilities=None):\n",
    "    trace_label = tracing.extend_trace_label(tr_label, 'eval_nl')\n",
    "    logit.validate_nest_spec(nest_spec, trace_label)\n",
    "    \n",
    "    if raw_utilities is None:\n",
    "        raw_utilities = simulate.eval_utilities(spec, trips_segment, locals_d,\n",
    "                                       log_alt_losers=log_alt_losers,\n",
    "                                       trace_label=trace_label, have_trace_targets=False,\n",
    "                                       estimator=estimator, trace_column_names=trace_column_names)\n",
    "\n",
    "    if use_zenith:\n",
    "        utils_df = compute_nested_utilities_zenith_check(raw_utilities, nest_spec)\n",
    "    else:\n",
    "        utils_df = compute_nested_utilities_asim(raw_utilities, nest_spec)\n",
    "\n",
    "    # test\n",
    "    #return compute_nested_utilities_zenith_check(raw_utilities, nest_spec), compute_nested_utilities_asim(raw_utilities, nest_spec)\n",
    "        \n",
    "    nests_ = list(logit.each_nest(nest_spec))\n",
    "    # group nests by level:\n",
    "    depth = np.max([x.level for x in nests_])\n",
    "    nest_levels = {x: [] for x in range(1, depth+1)}\n",
    "    for n in nests_:\n",
    "        nest_levels[n.level].append(n.name)\n",
    "    assert len(nest_levels[1]) == 1\n",
    "    assert nest_levels[1][0] == 'root'\n",
    "    # make choices\n",
    "    choices = make_choice(utils_df, nests_, nest_levels, seed)\n",
    "\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "bd6cadc3-79f5-4824-b55e-639c39d5ab18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:13:12.077886Z",
     "iopub.status.busy": "2021-09-01T11:13:12.077652Z",
     "iopub.status.idle": "2021-09-01T11:13:12.290222Z",
     "shell.execute_reply": "2021-09-01T11:13:12.288861Z",
     "shell.execute_reply.started": "2021-09-01T11:13:12.077863Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# t_z, t_a = simple_simulate_rum_zenith_check(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=seed)\n",
    "# tr_id = 86673661\n",
    "# display(t_z.loc[t_z.index==tr_id])\n",
    "# display(t_a.loc[t_a.index==tr_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "42e6da62-58e8-4b16-9169-9faa1fc8a162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:13:06.847583Z",
     "iopub.status.busy": "2021-09-01T11:13:06.847204Z",
     "iopub.status.idle": "2021-09-01T11:13:08.401700Z",
     "shell.execute_reply": "2021-09-01T11:13:08.400711Z",
     "shell.execute_reply.started": "2021-09-01T11:13:06.847554Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 51006 leads to 34 differences out of 168. tripids Int64Index([  86673657,   86673661,  106741681,  106741682,  106741685,\n",
      "             106741686,  106741687,  106741688,  211327433,  211327437,\n",
      "             444793574,  484173905,  484173909,  535170694,  535620053,\n",
      "             708171014,  943749470,  943749471, 1060575853, 1091770617,\n",
      "            1146472489, 1146472493, 1276281769, 1276281773, 1658748793,\n",
      "            1658748797, 1767013726, 1767186577, 1767186578, 1768237161,\n",
      "            1768237165, 1768237166, 2463663417, 2463663421],\n",
      "           dtype='int64', name='trip_id')\n"
     ]
    }
   ],
   "source": [
    "seed = 51006\n",
    "x_ = simple_simulate_rum_zenith_check(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=seed, use_zenith=True)\n",
    "y_ = simple_simulate_rum_zenith_check(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=seed, use_zenith=False)\n",
    "t_ = x_.to_frame('trip_mode_zenith').merge(y_.to_frame('trip_mode_asim'), left_index=True, right_index=True)\n",
    "diffs = t_.loc[t_.trip_mode_zenith != t_.trip_mode_asim]\n",
    "print(f\"seed {seed} leads to {diffs.shape[0]} differences out of {t_.shape[0]}. tripids {diffs.index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c0506-a79d-4a31-9d56-71b9966d0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed 51006 leads to 3 differences. tripids Int64Index([86673661, 535170689, 1060575849], dtype='int64', name='trip_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f332a-b1d7-4a80-bb21-d37a1611cf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5e4a1-6142-49d4-8da8-a1e266b3cb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "2098907f-28af-4f53-af74-6aaee8a6c53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T23:04:23.861048Z",
     "iopub.status.busy": "2021-09-01T23:04:23.860748Z",
     "iopub.status.idle": "2021-09-01T23:04:24.069307Z",
     "shell.execute_reply": "2021-09-01T23:04:24.068434Z",
     "shell.execute_reply.started": "2021-09-01T23:04:23.861024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng_ = default_rng(seed=100)\n",
    "new_utils = pd.DataFrame(0.1 * -np.log(-np.log(rng_.uniform(0,1,raw_utilities.shape))), columns=raw_utilities.columns)\n",
    "new_utils.index = raw_utilities.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "da48a178-82b2-44a5-b45a-e9de3bb5e5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T23:17:20.369675Z",
     "iopub.status.busy": "2021-09-01T23:17:20.369424Z",
     "iopub.status.idle": "2021-09-01T23:17:20.666506Z",
     "shell.execute_reply": "2021-09-01T23:17:20.665626Z",
     "shell.execute_reply.started": "2021-09-01T23:17:20.369637Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRIVEALONEFREE</th>\n",
       "      <th>DRIVEALONEPAY</th>\n",
       "      <th>SHARED2FREE</th>\n",
       "      <th>SHARED2PAY</th>\n",
       "      <th>SHARED3FREE</th>\n",
       "      <th>SHARED3PAY</th>\n",
       "      <th>WALK</th>\n",
       "      <th>BIKE</th>\n",
       "      <th>WALK_LOC</th>\n",
       "      <th>WALK_LRF</th>\n",
       "      <th>WALK_EXP</th>\n",
       "      <th>WALK_HVY</th>\n",
       "      <th>WALK_COM</th>\n",
       "      <th>DRIVE_LOC</th>\n",
       "      <th>DRIVE_LRF</th>\n",
       "      <th>DRIVE_EXP</th>\n",
       "      <th>DRIVE_HVY</th>\n",
       "      <th>DRIVE_COM</th>\n",
       "      <th>TAXI</th>\n",
       "      <th>TNC_SINGLE</th>\n",
       "      <th>TNC_SHARED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137248721</th>\n",
       "      <td>0.056642</td>\n",
       "      <td>0.037305</td>\n",
       "      <td>0.042780</td>\n",
       "      <td>0.029576</td>\n",
       "      <td>0.086154</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.088313</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.028021</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>0.021754</td>\n",
       "      <td>0.087126</td>\n",
       "      <td>0.021171</td>\n",
       "      <td>0.036475</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>0.135171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137248725</th>\n",
       "      <td>0.101902</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>0.069990</td>\n",
       "      <td>0.056913</td>\n",
       "      <td>0.046685</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>0.087785</td>\n",
       "      <td>0.025414</td>\n",
       "      <td>0.038162</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.039318</td>\n",
       "      <td>0.020160</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>0.037708</td>\n",
       "      <td>0.099523</td>\n",
       "      <td>0.041213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211388201</th>\n",
       "      <td>0.037562</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.055951</td>\n",
       "      <td>0.040389</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.095974</td>\n",
       "      <td>0.094678</td>\n",
       "      <td>0.094368</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.034953</td>\n",
       "      <td>0.035499</td>\n",
       "      <td>0.028040</td>\n",
       "      <td>0.043650</td>\n",
       "      <td>0.024713</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.025931</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>0.052678</td>\n",
       "      <td>0.051228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211388205</th>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.056256</td>\n",
       "      <td>0.043944</td>\n",
       "      <td>0.048085</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.062221</td>\n",
       "      <td>0.106819</td>\n",
       "      <td>0.087265</td>\n",
       "      <td>0.035117</td>\n",
       "      <td>0.030399</td>\n",
       "      <td>0.035154</td>\n",
       "      <td>0.026469</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.035727</td>\n",
       "      <td>0.024284</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.039427</td>\n",
       "      <td>0.041092</td>\n",
       "      <td>0.054714</td>\n",
       "      <td>0.048459</td>\n",
       "      <td>0.063458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806388401</th>\n",
       "      <td>0.054918</td>\n",
       "      <td>0.040488</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.054294</td>\n",
       "      <td>0.043477</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>0.152465</td>\n",
       "      <td>0.074152</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.059269</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>0.036968</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>0.023522</td>\n",
       "      <td>0.060932</td>\n",
       "      <td>0.023445</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.033773</td>\n",
       "      <td>0.058353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806388405</th>\n",
       "      <td>0.032764</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>0.018437</td>\n",
       "      <td>0.077099</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.089072</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.079610</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.024833</td>\n",
       "      <td>0.024840</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>0.079936</td>\n",
       "      <td>0.040146</td>\n",
       "      <td>0.043022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DRIVEALONEFREE  DRIVEALONEPAY  SHARED2FREE  SHARED2PAY  \\\n",
       "trip_id                                                             \n",
       "137248721        0.056642       0.037305     0.042780    0.029576   \n",
       "137248725        0.101902       0.022876     0.031227    0.069990   \n",
       "211388201        0.037562       0.070033     0.055951    0.040389   \n",
       "211388205        0.035480       0.056256     0.043944    0.048085   \n",
       "806388401        0.054918       0.040488     0.033149    0.054294   \n",
       "806388405        0.032764       0.057301     0.018437    0.077099   \n",
       "\n",
       "           SHARED3FREE  SHARED3PAY      WALK      BIKE  WALK_LOC  WALK_LRF  \\\n",
       "trip_id                                                                      \n",
       "137248721     0.086154    0.026586  0.088313  0.100331  0.028021  0.018516   \n",
       "137248725     0.056913    0.046685  0.088411  0.087785  0.025414  0.038162   \n",
       "211388201     0.020041    0.095974  0.094678  0.094368  0.036014  0.025051   \n",
       "211388205     0.042078    0.062221  0.106819  0.087265  0.035117  0.030399   \n",
       "806388401     0.043477    0.067982  0.152465  0.074152  0.033404  0.028735   \n",
       "806388405     0.046963    0.063521  0.094951  0.089072  0.030826  0.037896   \n",
       "\n",
       "           WALK_EXP  WALK_HVY  WALK_COM  DRIVE_LOC  DRIVE_LRF  DRIVE_EXP  \\\n",
       "trip_id                                                                    \n",
       "137248721  0.064391  0.020009  0.026399   0.022622   0.023007   0.021754   \n",
       "137248725  0.023988  0.028800  0.039318   0.020160   0.048364   0.023003   \n",
       "211388201  0.034860  0.034953  0.035499   0.028040   0.043650   0.024713   \n",
       "211388205  0.035154  0.026469  0.050646   0.035727   0.024284   0.032905   \n",
       "806388401  0.059269  0.024339  0.036968   0.027760   0.023522   0.060932   \n",
       "806388405  0.035752  0.019878  0.049536   0.079610   0.026922   0.024833   \n",
       "\n",
       "           DRIVE_HVY  DRIVE_COM      TAXI  TNC_SINGLE  TNC_SHARED  \n",
       "trip_id                                                            \n",
       "137248721   0.087126   0.021171  0.036475    0.027650    0.135171  \n",
       "137248725   0.033959   0.034597  0.037708    0.099523    0.041213  \n",
       "211388201   0.031388   0.025931  0.066999    0.052678    0.051228  \n",
       "211388205   0.039427   0.041092  0.054714    0.048459    0.063458  \n",
       "806388401   0.023445   0.023931  0.044643    0.033773    0.058353  \n",
       "806388405   0.024840   0.026695  0.079936    0.040146    0.043022  "
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_exp_utilities_cf = simulate.compute_nested_exp_utilities(new_utils, nest_spec)\n",
    "nested_probabilities_cf = simulate.compute_nested_probabilities(nested_exp_utilities_cf, nest_spec, trace_label=None)\n",
    "base_probabilities_cf = simulate.compute_base_probabilities(nested_probabilities_cf, nest_spec, spec)\n",
    "base_probabilities_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "50dfd1ae-10c3-475c-94be-de783c2fa5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T00:15:29.056902Z",
     "iopub.status.busy": "2021-09-02T00:15:29.056683Z",
     "iopub.status.idle": "2021-09-02T00:27:21.965206Z",
     "shell.execute_reply": "2021-09-02T00:27:21.964340Z",
     "shell.execute_reply.started": "2021-09-02T00:15:29.056877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 49s, sys: 766 ms, total: 11min 50s\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_samples = 10000 # 7.5s per 100\n",
    "\n",
    "data_zenith = []\n",
    "data_asim = []\n",
    "for i in range(num_samples):\n",
    "    seed = rng_.integers(0, 100000)\n",
    "    x_ = simple_simulate_rum_zenith_check(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=seed, use_zenith=True, raw_utilities=new_utils)\n",
    "    y_ = simple_simulate_rum_zenith_check(trips_segment, spec, nest_spec, locals_dict, estimator, tr_label, log_alt_losers, trace_column_names, seed=seed, use_zenith=False, raw_utilities=new_utils)\n",
    "    data_zenith.append(x_)\n",
    "    data_asim.append(y_)\n",
    "    \n",
    "data_asim = pd.concat(data_asim, axis=1)\n",
    "data_zenith = pd.concat(data_zenith, axis=1)\n",
    "# counts_zenith = data_zenith.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "# counts_zenith = counts_zenith / data_zenith.shape[1]\n",
    "# counts_asim = data_asim.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "# counts_asim = counts_asim / data_asim.shape[1]\n",
    "\n",
    "# mode_share_zenith = (counts_zenith.sum(axis=0) / counts_zenith.shape[0]).to_frame('zenith')\n",
    "# mode_share_asim = (counts_asim.sum(axis=0) / counts_asim.shape[0]).to_frame('asim')\n",
    "# mode_share_base_prob = (base_probabilities_cf.sum(axis=0) / base_probabilities_cf.shape[0]).to_frame('probs')\n",
    "# assert np.allclose(mode_share_zenith.sum(), 1)\n",
    "# assert np.allclose(mode_share_asim.sum(), 1)\n",
    "# assert np.allclose(mode_share_base_prob.sum(), 1)\n",
    "# mode_share_comp = mode_share_zenith.join(mode_share_asim, how='outer').join(mode_share_base_prob, how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "bb16f9d7-44f5-4316-b981-d65216a5e217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T00:14:11.772592Z",
     "iopub.status.busy": "2021-09-02T00:14:11.772347Z",
     "iopub.status.idle": "2021-09-02T00:14:12.001077Z",
     "shell.execute_reply": "2021-09-02T00:14:12.000166Z",
     "shell.execute_reply.started": "2021-09-02T00:14:11.772556Z"
    }
   },
   "outputs": [],
   "source": [
    "#temp_z = data_zenith.copy()\n",
    "#temp_a = data_asim.copy()\n",
    "#data_asim = data_asim.join(temp_a, lsuffix=\"_o\", rsuffix=\"_n\")\n",
    "#data_zenith = data_zenith.join(temp_z, lsuffix=\"_o\", rsuffix=\"_n\")\n",
    "# counts_zenith = data_zenith.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "# counts_zenith = counts_zenith / data_zenith.shape[1]\n",
    "# counts_asim = data_asim.apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "# counts_asim = counts_asim / data_asim.shape[1]\n",
    "\n",
    "# mode_share_zenith = (counts_zenith.sum(axis=0) / counts_zenith.shape[0]).to_frame('zenith')\n",
    "# mode_share_asim = (counts_asim.sum(axis=0) / counts_asim.shape[0]).to_frame('asim')\n",
    "# mode_share_base_prob = (base_probabilities_cf.sum(axis=0) / base_probabilities_cf.shape[0]).to_frame('probs')\n",
    "# assert np.allclose(mode_share_zenith.sum(), 1)\n",
    "# assert np.allclose(mode_share_asim.sum(), 1)\n",
    "# assert np.allclose(mode_share_base_prob.sum(), 1)\n",
    "# mode_share_comp = mode_share_zenith.join(mode_share_asim, how='outer').join(mode_share_base_prob, how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "031d8340-0af0-4608-8a83-ed2af4aaa3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T00:41:01.948669Z",
     "iopub.status.busy": "2021-09-02T00:41:01.948422Z",
     "iopub.status.idle": "2021-09-02T00:41:02.175972Z",
     "shell.execute_reply": "2021-09-02T00:41:02.174759Z",
     "shell.execute_reply.started": "2021-09-02T00:41:01.948633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIKE</th>\n",
       "      <th>DRIVEALONEFREE</th>\n",
       "      <th>DRIVEALONEPAY</th>\n",
       "      <th>DRIVE_COM</th>\n",
       "      <th>DRIVE_EXP</th>\n",
       "      <th>DRIVE_HVY</th>\n",
       "      <th>DRIVE_LOC</th>\n",
       "      <th>DRIVE_LRF</th>\n",
       "      <th>SHARED2FREE</th>\n",
       "      <th>SHARED2PAY</th>\n",
       "      <th>SHARED3FREE</th>\n",
       "      <th>SHARED3PAY</th>\n",
       "      <th>TAXI</th>\n",
       "      <th>TNC_SHARED</th>\n",
       "      <th>TNC_SINGLE</th>\n",
       "      <th>WALK</th>\n",
       "      <th>WALK_COM</th>\n",
       "      <th>WALK_EXP</th>\n",
       "      <th>WALK_HVY</th>\n",
       "      <th>WALK_LOC</th>\n",
       "      <th>WALK_LRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zenith</th>\n",
       "      <td>8.055</td>\n",
       "      <td>5.167</td>\n",
       "      <td>4.631</td>\n",
       "      <td>3.502</td>\n",
       "      <td>3.606</td>\n",
       "      <td>4.266</td>\n",
       "      <td>3.963</td>\n",
       "      <td>3.498</td>\n",
       "      <td>3.895</td>\n",
       "      <td>5.176</td>\n",
       "      <td>4.799</td>\n",
       "      <td>5.851</td>\n",
       "      <td>4.999</td>\n",
       "      <td>6.121</td>\n",
       "      <td>4.668</td>\n",
       "      <td>9.486</td>\n",
       "      <td>4.228</td>\n",
       "      <td>4.125</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.671</td>\n",
       "      <td>3.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asim</th>\n",
       "      <td>6.096</td>\n",
       "      <td>6.698</td>\n",
       "      <td>4.977</td>\n",
       "      <td>3.202</td>\n",
       "      <td>3.522</td>\n",
       "      <td>4.334</td>\n",
       "      <td>4.129</td>\n",
       "      <td>3.184</td>\n",
       "      <td>3.224</td>\n",
       "      <td>5.149</td>\n",
       "      <td>6.283</td>\n",
       "      <td>8.296</td>\n",
       "      <td>4.793</td>\n",
       "      <td>6.584</td>\n",
       "      <td>4.532</td>\n",
       "      <td>7.484</td>\n",
       "      <td>4.152</td>\n",
       "      <td>4.273</td>\n",
       "      <td>2.629</td>\n",
       "      <td>3.433</td>\n",
       "      <td>3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probs</th>\n",
       "      <td>8.883</td>\n",
       "      <td>5.321</td>\n",
       "      <td>4.738</td>\n",
       "      <td>2.890</td>\n",
       "      <td>3.136</td>\n",
       "      <td>4.003</td>\n",
       "      <td>3.565</td>\n",
       "      <td>3.162</td>\n",
       "      <td>3.758</td>\n",
       "      <td>5.324</td>\n",
       "      <td>4.927</td>\n",
       "      <td>6.049</td>\n",
       "      <td>5.341</td>\n",
       "      <td>6.541</td>\n",
       "      <td>5.037</td>\n",
       "      <td>10.427</td>\n",
       "      <td>3.973</td>\n",
       "      <td>4.224</td>\n",
       "      <td>2.574</td>\n",
       "      <td>3.147</td>\n",
       "      <td>2.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BIKE  DRIVEALONEFREE  DRIVEALONEPAY  DRIVE_COM  DRIVE_EXP  DRIVE_HVY  \\\n",
       "zenith  8.055           5.167          4.631      3.502      3.606      4.266   \n",
       "asim    6.096           6.698          4.977      3.202      3.522      4.334   \n",
       "probs   8.883           5.321          4.738      2.890      3.136      4.003   \n",
       "\n",
       "        DRIVE_LOC  DRIVE_LRF  SHARED2FREE  SHARED2PAY  SHARED3FREE  \\\n",
       "zenith      3.963      3.498        3.895       5.176        4.799   \n",
       "asim        4.129      3.184        3.224       5.149        6.283   \n",
       "probs       3.565      3.162        3.758       5.324        4.927   \n",
       "\n",
       "        SHARED3PAY   TAXI  TNC_SHARED  TNC_SINGLE    WALK  WALK_COM  WALK_EXP  \\\n",
       "zenith       5.851  4.999       6.121       4.668   9.486     4.228     4.125   \n",
       "asim         8.296  4.793       6.584       4.532   7.484     4.152     4.273   \n",
       "probs        6.049  5.341       6.541       5.037  10.427     3.973     4.224   \n",
       "\n",
       "        WALK_HVY  WALK_LOC  WALK_LRF  \n",
       "zenith     2.977     3.671     3.317  \n",
       "asim       2.629     3.433     3.023  \n",
       "probs      2.574     3.147     2.979  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample of 20000\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    display((100.0 * mode_share_comp).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "aece448f-4055-4d2a-b90d-8530caec9cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T00:43:32.971972Z",
     "iopub.status.busy": "2021-09-02T00:43:32.971684Z",
     "iopub.status.idle": "2021-09-02T00:43:33.223345Z",
     "shell.execute_reply": "2021-09-02T00:43:33.222488Z",
     "shell.execute_reply.started": "2021-09-02T00:43:32.971932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trip_id</th>\n",
       "      <th>137248721_z</th>\n",
       "      <th>137248721_a</th>\n",
       "      <th>137248721</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIKE</th>\n",
       "      <td>0.09270</td>\n",
       "      <td>0.05435</td>\n",
       "      <td>0.100331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVEALONEFREE</th>\n",
       "      <td>0.05365</td>\n",
       "      <td>0.05005</td>\n",
       "      <td>0.056642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVEALONEPAY</th>\n",
       "      <td>0.03880</td>\n",
       "      <td>0.03155</td>\n",
       "      <td>0.037305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVE_COM</th>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.02470</td>\n",
       "      <td>0.021171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVE_EXP</th>\n",
       "      <td>0.02880</td>\n",
       "      <td>0.02605</td>\n",
       "      <td>0.021754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVE_HVY</th>\n",
       "      <td>0.07815</td>\n",
       "      <td>0.09970</td>\n",
       "      <td>0.087126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVE_LOC</th>\n",
       "      <td>0.02875</td>\n",
       "      <td>0.02700</td>\n",
       "      <td>0.022622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVE_LRF</th>\n",
       "      <td>0.02780</td>\n",
       "      <td>0.02445</td>\n",
       "      <td>0.023007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARED2FREE</th>\n",
       "      <td>0.04325</td>\n",
       "      <td>0.02300</td>\n",
       "      <td>0.042780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARED2PAY</th>\n",
       "      <td>0.03360</td>\n",
       "      <td>0.01585</td>\n",
       "      <td>0.029576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARED3FREE</th>\n",
       "      <td>0.07365</td>\n",
       "      <td>0.11920</td>\n",
       "      <td>0.086154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARED3PAY</th>\n",
       "      <td>0.03260</td>\n",
       "      <td>0.03960</td>\n",
       "      <td>0.026586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAXI</th>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.036475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNC_SHARED</th>\n",
       "      <td>0.12620</td>\n",
       "      <td>0.18115</td>\n",
       "      <td>0.135171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNC_SINGLE</th>\n",
       "      <td>0.02625</td>\n",
       "      <td>0.03845</td>\n",
       "      <td>0.027650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK</th>\n",
       "      <td>0.07940</td>\n",
       "      <td>0.04825</td>\n",
       "      <td>0.088313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK_COM</th>\n",
       "      <td>0.03185</td>\n",
       "      <td>0.02460</td>\n",
       "      <td>0.026399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK_EXP</th>\n",
       "      <td>0.05705</td>\n",
       "      <td>0.05895</td>\n",
       "      <td>0.064391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK_HVY</th>\n",
       "      <td>0.02520</td>\n",
       "      <td>0.01840</td>\n",
       "      <td>0.020009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK_LOC</th>\n",
       "      <td>0.03455</td>\n",
       "      <td>0.02740</td>\n",
       "      <td>0.028021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK_LRF</th>\n",
       "      <td>0.02395</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.018516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "trip_id         137248721_z  137248721_a  137248721\n",
       "BIKE                0.09270      0.05435   0.100331\n",
       "DRIVEALONEFREE      0.05365      0.05005   0.056642\n",
       "DRIVEALONEPAY       0.03880      0.03155   0.037305\n",
       "DRIVE_COM           0.02870      0.02470   0.021171\n",
       "DRIVE_EXP           0.02880      0.02605   0.021754\n",
       "DRIVE_HVY           0.07815      0.09970   0.087126\n",
       "DRIVE_LOC           0.02875      0.02700   0.022622\n",
       "DRIVE_LRF           0.02780      0.02445   0.023007\n",
       "SHARED2FREE         0.04325      0.02300   0.042780\n",
       "SHARED2PAY          0.03360      0.01585   0.029576\n",
       "SHARED3FREE         0.07365      0.11920   0.086154\n",
       "SHARED3PAY          0.03260      0.03960   0.026586\n",
       "TAXI                0.03510      0.05030   0.036475\n",
       "TNC_SHARED          0.12620      0.18115   0.135171\n",
       "TNC_SINGLE          0.02625      0.03845   0.027650\n",
       "WALK                0.07940      0.04825   0.088313\n",
       "WALK_COM            0.03185      0.02460   0.026399\n",
       "WALK_EXP            0.05705      0.05895   0.064391\n",
       "WALK_HVY            0.02520      0.01840   0.020009\n",
       "WALK_LOC            0.03455      0.02740   0.028021\n",
       "WALK_LRF            0.02395      0.01700   0.018516"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: look at probs per trip, i.e. do not sum across trips\n",
    "trip_id = 137248721\n",
    "\n",
    "counts_zenith.loc[counts_zenith.index == trip_id].T.merge(\n",
    "    counts_asim.loc[counts_asim.index == trip_id].T, suffixes=['_z', '_a'], left_index=True, right_index=True, how='outer').merge(\n",
    "    base_probabilities_cf.loc[base_probabilities_cf.index == trip_id].T, suffixes=['', '_probs'], left_index=True, right_index=True, how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef84f10-d616-40e4-87e5-425499027ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431cee49-40a9-4dc7-93a5-75308fb302dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdc0ff-c510-4878-8672-8365e046442c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}