{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frozen randomness\n",
    "\n",
    "Let's try to draw from nested logit model by drawing error terms. For logit models, this is simple because error terms are independent and therefore we can uniquely invert the CDF and simply draw from that. For nested models, this is not the case. However, we know we can write the probabilities as nested logits and therefore we think we can draw repeatedly like for logit models, taking the nesting structure into account.\n",
    "\n",
    "Let's start with two levels and a model where we know the probabilities, i.e. we fix the utility functions and the nesting scales, like for red bus/blue bus. We then draw like ActivitySim does, and like we want to do.\n",
    "\n",
    "Next, we extend to three levels, where the additional nest error term has not been derived yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T05:31:19.564033Z",
     "iopub.status.busy": "2022-05-01T05:31:19.563663Z",
     "iopub.status.idle": "2022-05-01T05:31:19.824207Z",
     "shell.execute_reply": "2022-05-01T05:31:19.823432Z",
     "shell.execute_reply.started": "2022-05-01T05:31:19.563960Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T05:31:20.023960Z",
     "iopub.status.busy": "2022-05-01T05:31:20.023246Z",
     "iopub.status.idle": "2022-05-01T05:31:20.029538Z",
     "shell.execute_reply": "2022-05-01T05:31:20.028264Z",
     "shell.execute_reply.started": "2022-05-01T05:31:20.023927Z"
    }
   },
   "outputs": [],
   "source": [
    "def logsum(utilities, nest_scale=1.0):\n",
    "    scaled_utils = utilities / nest_scale\n",
    "    max_util = np.max(scaled_utils)\n",
    "    return max_util + np.log(np.sum(np.exp(scaled_utils - max_util)))\n",
    "\n",
    "\n",
    "# total probability of alternative being chosen is product of two terms:\n",
    "# conditional probability of alternative given nest is chosen: exp(util / nest_scale)\n",
    "# marginal probability that any alternative in nest is chosen: exp(nest_scale * logsum)\n",
    "    \n",
    "# If you think about a single case, the probabilities are indicator variables and we take the max of each. This is what Zenith does I think.\n",
    "# Given that these expressions are those of two logits, it seems natural to draw correspondingly.\n",
    "# This must be related to the strict derivation of max() distributions of Hunt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T09:55:14.957470Z",
     "iopub.status.busy": "2022-05-01T09:55:14.957183Z",
     "iopub.status.idle": "2022-05-01T09:55:14.964046Z",
     "shell.execute_reply": "2022-05-01T09:55:14.963056Z",
     "shell.execute_reply.started": "2022-05-01T09:55:14.957441Z"
    }
   },
   "outputs": [],
   "source": [
    "alternatives = {1: \"car\", 2: \"blue bus\", 3: \"red bus\"}\n",
    "\n",
    "utility_spec = {\n",
    "    1: {\"cost\": -1.0, \"asc\": 0.0},\n",
    "    2: {\"cost\": -1.0, \"asc\": 0.2},\n",
    "    3: {\"cost\": -1.5, \"asc\": 0.1},\n",
    "}\n",
    "\n",
    "# blue and red bus are nested together with scale 0.5\n",
    "\n",
    "def utility(x, utility_spec, alternative):\n",
    "    assert alternative in utility_spec.keys()\n",
    "    return utility_spec[alternative][\"cost\"] * x + utility_spec[alternative][\"asc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T09:55:15.467608Z",
     "iopub.status.busy": "2022-05-01T09:55:15.467366Z",
     "iopub.status.idle": "2022-05-01T09:55:15.478279Z",
     "shell.execute_reply": "2022-05-01T09:55:15.476833Z",
     "shell.execute_reply.started": "2022-05-01T09:55:15.467571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4452265282367507 0.5330453677531714 0.02172810401007798\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "cost = 3.0\n",
    "nest_scale = 0.5\n",
    "\n",
    "util_3 = utility(cost, utility_spec, 3)\n",
    "util_2 = utility(cost, utility_spec, 2)\n",
    "logsum_bus = logsum(np.array([util_2, util_3]), nest_scale=nest_scale)\n",
    "nest_util = nest_scale * logsum_bus\n",
    "\n",
    "util_1 = utility(cost, utility_spec, 1)\n",
    "prob_1 = np.exp(util_1) / (np.exp(util_1) + np.exp(nest_util))\n",
    "\n",
    "nest_cond_prob = np.exp(nest_util) / (np.exp(util_1) + np.exp(nest_util))\n",
    "nest_marg_prob_2 = np.exp(util_2 / nest_scale) / (np.exp(util_2 / nest_scale) + np.exp(util_3 / nest_scale))\n",
    "nest_marg_prob_3 = np.exp(util_3 / nest_scale) / (np.exp(util_2 / nest_scale) + np.exp(util_3 / nest_scale))\n",
    "\n",
    "prob_2 = nest_cond_prob * nest_marg_prob_2\n",
    "prob_3 = nest_cond_prob * nest_marg_prob_3\n",
    "\n",
    "print(prob_1, prob_2, prob_3)\n",
    "print(sum([prob_1, prob_2, prob_3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ActivitySim way\n",
    "Kind of pointless here but this is how we choose a single value - draw from U and pick whichever interval it falls into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T09:55:20.523480Z",
     "iopub.status.busy": "2022-05-01T09:55:20.523247Z",
     "iopub.status.idle": "2022-05-01T09:55:21.341578Z",
     "shell.execute_reply": "2022-05-01T09:55:21.340682Z",
     "shell.execute_reply.started": "2022-05-01T09:55:20.523453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed form: [0.4452265282367507, 0.5330453677531714, 0.02172810401007798],\n",
      "simulated: [0.4450967 0.5331544 0.0217489]\n",
      "CPU times: user 969 ms, sys: 78.1 ms, total: 1.05 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "probs = [prob_1, prob_2, prob_3]\n",
    "cum_probs = [0] + list(np.cumsum(probs))\n",
    "\n",
    "num_draws = 10000000\n",
    "\n",
    "# now draw from U and put into arrays, then value count?\n",
    "rng = default_rng(999)\n",
    "rands = rng.uniform(size=num_draws)\n",
    "\n",
    "hits, bins = np.histogram(rands, bins=cum_probs)\n",
    "print(f\"closed form: {probs},\\nsimulated: {hits / num_draws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T09:55:24.027745Z",
     "iopub.status.busy": "2022-05-01T09:55:24.027421Z",
     "iopub.status.idle": "2022-05-01T09:55:24.034035Z",
     "shell.execute_reply": "2022-05-01T09:55:24.031703Z",
     "shell.execute_reply.started": "2022-05-01T09:55:24.027708Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverse_ev1_cdf(x, location=0.0, scale=1.0):\n",
    "    \"quantile function of EV1\"\n",
    "    #return location - (1.0 / scale) * np.log(-np.log(x))\n",
    "    # let's follow https://en.wikipedia.org/wiki/Gumbel_distribution where the scale is proportional to variance (not variance^{-1})\n",
    "    return location - scale * np.log(-np.log(x))\n",
    "\n",
    "# for utilities with full set of ascs location=0. Do we always assume location=0 in estimation anyways?\n",
    "# the scale of the error term is unidentified and therefore set to 1 in most applications, meaning the standard deviation is pi/sqrt(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:38:03.583638Z",
     "iopub.status.busy": "2022-04-17T03:38:03.583273Z",
     "iopub.status.idle": "2022-04-17T03:38:03.588839Z",
     "shell.execute_reply": "2022-04-17T03:38:03.586978Z",
     "shell.execute_reply.started": "2022-04-17T03:38:03.583594Z"
    }
   },
   "source": [
    "## The Zenith way\n",
    "\n",
    "Basically, probabilities are now indicators - choose at the lowest level, then walk up. Choice is product of these. We draw error terms for each alternative, where nest roots are now alternatives too.\n",
    "\n",
    "OR: do we choose a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:02:14.035272Z",
     "iopub.status.busy": "2022-05-01T10:02:14.035014Z",
     "iopub.status.idle": "2022-05-01T10:02:14.040376Z",
     "shell.execute_reply": "2022-05-01T10:02:14.039207Z",
     "shell.execute_reply.started": "2022-05-01T10:02:14.035235Z"
    }
   },
   "outputs": [],
   "source": [
    "util_3 = utility(cost, utility_spec, 3)\n",
    "util_2 = utility(cost, utility_spec, 2)\n",
    "logsum_bus = logsum(np.array([util_2, util_3]), nest_scale=nest_scale)\n",
    "util_1 = utility(cost, utility_spec, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T10:03:23.999857Z",
     "iopub.status.busy": "2022-05-01T10:03:23.999571Z",
     "iopub.status.idle": "2022-05-01T10:03:30.033848Z",
     "shell.execute_reply": "2022-05-01T10:03:30.032689Z",
     "shell.execute_reply.started": "2022-05-01T10:03:23.999816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed form probs: 0.445227, 0.533045, 0.021728\n",
      "  simulated probs: 0.4452013, 0.5330709, 0.0217278\n"
     ]
    }
   ],
   "source": [
    "# conditional error term are given by logit with scale given by nest scale\n",
    "num_draws_dec = 10000000\n",
    "#mu = 1.0 / nest_scale\n",
    "\n",
    "rng_dec = default_rng(9)\n",
    "rands_dec = rng_dec.uniform(size = 2 * num_draws_dec)  # we need one for each alternative if num_draws_dec signifies the total number of choices we want to simulate\n",
    "ev1_lower = inverse_ev1_cdf(rands_dec, scale=nest_scale)\n",
    "\n",
    "lower_utils_2 = util_2 + ev1_lower[num_draws_dec:] \n",
    "lower_utils_3 = util_3 + ev1_lower[:num_draws_dec] \n",
    "\n",
    "#logsum_bus = logsum(np.array([lower_utils_2, lower_utils_3]), nest_scale=nest_scale)\n",
    "ev1_upper = inverse_ev1_cdf(rng_dec.uniform(size=2*num_draws_dec))\n",
    "nest_util = nest_scale * logsum_bus + ev1_upper[num_draws_dec:]\n",
    "\n",
    "full_util_1 = util_1 + ev1_upper[:num_draws_dec]\n",
    "\n",
    "choices = np.array([full_util_1, nest_util]).argmax(axis=0)\n",
    "nest_indexes = np.nonzero(choices == 1)[0]\n",
    "nest_choices = np.array([lower_utils_2[nest_indexes], lower_utils_3[nest_indexes]]).argmax(axis=0)\n",
    "nest_choices += 1\n",
    "choices = np.append(choices[choices == 0], nest_choices)\n",
    "\n",
    "vals, counts = np.unique(choices, return_counts=True)\n",
    "probs_dec = {i+1: counts[i] / num_draws_dec for i in vals}\n",
    "\n",
    "print(f\"closed form probs: {prob_1:.6f}, {prob_2:.6f}, {prob_3:.6f}\")\n",
    "print(f\"  simulated probs: {probs_dec[1]}, {probs_dec[2]}, {probs_dec[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The error term decomposition way -> not working. just use the zenith way and write it as indicators for individuals.\n",
    "\n",
    "We can decompose the error term into one for the nest and one within nests according to Hildebrandt. However, I\n",
    "cannot seem to reproduce the exact probabilities. Why?\n",
    "\n",
    "Looks like one of the location parameters is wrong; 0.125 added to nest makes it right (tested for one set of params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T09:55:25.164028Z",
     "iopub.status.busy": "2022-05-01T09:55:25.163822Z",
     "iopub.status.idle": "2022-05-01T09:55:25.473704Z",
     "shell.execute_reply": "2022-05-01T09:55:25.472525Z",
     "shell.execute_reply.started": "2022-05-01T09:55:25.164005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed form probs: 0.445227, 0.533045, 0.021728\n",
      "  simulated probs: 0.4755317, 0.5039483, 0.02052\n",
      "0.9363, 1.0577, 1.0589\n",
      "CPU times: user 4.12 s, sys: 2.3 s, total: 6.42 s\n",
      "Wall time: 6.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# conditional error term are given by logit with scale given by nest scale\n",
    "num_draws_dec = 10000000\n",
    "\n",
    "mu = 1.0 / nest_scale\n",
    "\n",
    "rng_dec = default_rng(9)\n",
    "\n",
    "rands_dec = rng_dec.uniform(size = 2 * num_draws_dec)  # we need one for each alternative if num_draws_dec signifies the total number of choices we want to simulate\n",
    "ev1_dec = inverse_ev1_cdf(rands_dec, scale=1.0/mu)\n",
    "lower_level_utils_2 = np.repeat(util_2, num_draws_dec) + ev1_dec[num_draws_dec:]\n",
    "lower_level_utils_3 = np.repeat(util_3, num_draws_dec) + ev1_dec[:num_draws_dec]\n",
    "\n",
    "#location_nest = - 1.0 / mu * np.log(2.0 * np.exp(mu * 0.5772))\n",
    "location_nest = - np.log(2.0) / mu\n",
    "#location_nest = (- np.log(2.0) / mu) - ((1.0 - 1.0 / (mu + 1.0)) * 0.57721 * mu / (mu**2 - 1.0))\n",
    "#print(location_nest, - np.log(2.0) / mu)\n",
    "\n",
    "scale_nest = mu / np.sqrt(mu**2 - 1.0)\n",
    "nest_error_terms = inverse_ev1_cdf(rng_dec.uniform(size=num_draws_dec), location=location_nest, scale=1.0/scale_nest)\n",
    "\n",
    "full_utils_2 = lower_level_utils_2 + nest_error_terms\n",
    "full_utils_3 = lower_level_utils_3 + nest_error_terms\n",
    "\n",
    "# what's the distribution of error term for car? it's a degenerate nest, so bottom level is 1\n",
    "# this here agrees with Bhat and Koppelman's mode choice script.\n",
    "full_utils_1 = util_1 + inverse_ev1_cdf(rng_dec.uniform(size=num_draws_dec))\n",
    "\n",
    "choices = np.array([full_utils_1, full_utils_2, full_utils_3]).argmax(axis=0)\n",
    "vals, counts = np.unique(choices, return_counts=True)\n",
    "probs_dec = {i+1: counts[i] / num_draws_dec for i in vals}\n",
    "\n",
    "print(f\"closed form probs: {prob_1:.6f}, {prob_2:.6f}, {prob_3:.6f}\")\n",
    "print(f\"  simulated probs: {probs_dec[1]}, {probs_dec[2]}, {probs_dec[3]}\")\n",
    "print(f\"{prob_1 / probs_dec[1]:.4f}, {prob_2 / probs_dec[2]:.4f}, {prob_3 / probs_dec[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-level\n",
    "\n",
    "and recursive - maybe use Asim structure directly?\n",
    "\n",
    "\n",
    "Could also use larch to apply models, would be great to add there too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}